{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/muhammadbsheikh/workspace/try\n"
     ]
    }
   ],
   "source": [
    "cd /home/muhammadbsheikh/workspace/try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(model,dl):\n",
    "    lbls = []\n",
    "    model.eval()\n",
    "    device = 'cuda:0'\n",
    "    model.cuda(device)\n",
    "    with torch.no_grad():\n",
    "        features = None\n",
    "        for batch in tqdm(dl, disable=True):\n",
    "            \n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            lbls.append(labels)\n",
    "            print(labels)\n",
    "\n",
    "            if features is not None:\n",
    "                features = torch.cat((features, output), 0)\n",
    "\n",
    "            else:\n",
    "                features = output        \n",
    "            \n",
    "\n",
    "    return features.cpu().numpy(),lbls\n",
    "\n",
    "\n",
    "def flatten_list(t):\n",
    "    flat_list = [item for sublist in t for item in sublist]\n",
    "    flat_list = np.array(flat_list)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "0.9.1\n",
      "_CudaDeviceProperties(name='GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11178MB, multi_processor_count=28) None 0\n",
      "Training...\n",
      "[epoch 1,imgs    40] loss: 0.7381561  time: 1.593 s\n",
      "[epoch 1,imgs    80] loss: 0.7364691  time: 0.922 s\n",
      "[epoch 1,imgs   120] loss: 0.7424034  time: 0.923 s\n",
      "[epoch 1,imgs   160] loss: 0.7409665  time: 0.927 s\n",
      "[epoch 1,imgs   200] loss: 0.7348387  time: 0.935 s\n",
      "[epoch 1,imgs   240] loss: 0.7349889  time: 0.923 s\n",
      "[epoch 1,imgs   280] loss: 0.7381642  time: 0.924 s\n",
      "[epoch 1,imgs   320] loss: 0.7404304  time: 0.919 s\n",
      "[epoch 1,imgs   360] loss: 0.7364513  time: 0.918 s\n",
      "[epoch 1,imgs   400] loss: 0.7401215  time: 0.918 s\n",
      "[epoch 1,imgs   440] loss: 0.7385595  time: 0.920 s\n",
      "[epoch 1,imgs   480] loss: 0.7406903  time: 0.922 s\n",
      "[epoch 1,imgs   520] loss: 0.7373325  time: 0.922 s\n",
      "[epoch 1,imgs   560] loss: 0.7337598  time: 0.921 s\n",
      "[epoch 1,imgs   600] loss: 0.7374717  time: 0.922 s\n",
      "[epoch 1,imgs   640] loss: 0.7406570  time: 0.923 s\n",
      "[epoch 1,imgs   680] loss: 0.7323173  time: 0.924 s\n",
      "[epoch 1,imgs   720] loss: 0.7401920  time: 0.924 s\n",
      "[epoch 1,imgs   760] loss: 0.7453750  time: 0.925 s\n",
      "[epoch 1,imgs   800] loss: 0.7428913  time: 0.925 s\n",
      "[epoch 1,imgs   840] loss: 0.7399588  time: 0.923 s\n",
      "[epoch 1,imgs   880] loss: 0.7423523  time: 0.925 s\n",
      "[epoch 1,imgs   920] loss: 0.7386192  time: 0.924 s\n",
      "[epoch 1,imgs   960] loss: 0.7428687  time: 0.953 s\n",
      "[epoch 1,imgs  1000] loss: 0.7397110  time: 0.930 s\n",
      "[epoch 1,imgs  1040] loss: 0.7350355  time: 0.929 s\n",
      "[epoch 1,imgs  1080] loss: 0.7376984  time: 0.931 s\n",
      "[epoch 1,imgs  1120] loss: 0.7417803  time: 0.927 s\n",
      "[epoch 1,imgs  1160] loss: 0.7432144  time: 0.928 s\n",
      "[epoch 1,imgs  1200] loss: 0.7390039  time: 0.936 s\n",
      "[epoch 2,imgs    40] loss: 0.7405421  time: 1.314 s\n",
      "[epoch 2,imgs    80] loss: 0.7369464  time: 0.940 s\n",
      "[epoch 2,imgs   120] loss: 0.7370857  time: 0.938 s\n",
      "[epoch 2,imgs   160] loss: 0.7430515  time: 0.942 s\n",
      "[epoch 2,imgs   200] loss: 0.7410837  time: 0.960 s\n",
      "[epoch 2,imgs   240] loss: 0.7350798  time: 0.935 s\n",
      "[epoch 2,imgs   280] loss: 0.7389713  time: 0.959 s\n",
      "[epoch 2,imgs   320] loss: 0.7376961  time: 0.938 s\n",
      "[epoch 2,imgs   360] loss: 0.7395105  time: 0.942 s\n",
      "[epoch 2,imgs   400] loss: 0.7417200  time: 0.939 s\n",
      "[epoch 2,imgs   440] loss: 0.7457853  time: 0.949 s\n",
      "[epoch 2,imgs   480] loss: 0.7405013  time: 0.939 s\n",
      "[epoch 2,imgs   520] loss: 0.7393371  time: 0.961 s\n",
      "[epoch 2,imgs   560] loss: 0.7384590  time: 0.938 s\n",
      "[epoch 2,imgs   600] loss: 0.7422406  time: 0.937 s\n",
      "[epoch 2,imgs   640] loss: 0.7418383  time: 0.938 s\n",
      "[epoch 2,imgs   680] loss: 0.7385474  time: 0.942 s\n",
      "[epoch 2,imgs   720] loss: 0.7402031  time: 0.939 s\n",
      "[epoch 2,imgs   760] loss: 0.7376972  time: 0.940 s\n",
      "[epoch 2,imgs   800] loss: 0.7372360  time: 0.942 s\n",
      "[epoch 2,imgs   840] loss: 0.7418146  time: 0.940 s\n",
      "[epoch 2,imgs   880] loss: 0.7420382  time: 0.939 s\n",
      "[epoch 2,imgs   920] loss: 0.7325230  time: 0.940 s\n",
      "[epoch 2,imgs   960] loss: 0.7355214  time: 0.944 s\n",
      "[epoch 2,imgs  1000] loss: 0.7366759  time: 0.947 s\n",
      "[epoch 2,imgs  1040] loss: 0.7380834  time: 0.943 s\n",
      "[epoch 2,imgs  1080] loss: 0.7356638  time: 0.943 s\n",
      "[epoch 2,imgs  1120] loss: 0.7372828  time: 0.941 s\n",
      "[epoch 2,imgs  1160] loss: 0.7385178  time: 0.942 s\n",
      "[epoch 2,imgs  1200] loss: 0.7398173  time: 0.945 s\n",
      "[epoch 3,imgs    40] loss: 0.7422521  time: 1.342 s\n",
      "[epoch 3,imgs    80] loss: 0.7397350  time: 0.946 s\n",
      "[epoch 3,imgs   120] loss: 0.7396240  time: 0.946 s\n",
      "[epoch 3,imgs   160] loss: 0.7412108  time: 0.956 s\n",
      "[epoch 3,imgs   200] loss: 0.7397550  time: 0.946 s\n",
      "[epoch 3,imgs   240] loss: 0.7355846  time: 0.945 s\n",
      "[epoch 3,imgs   280] loss: 0.7399337  time: 0.947 s\n",
      "[epoch 3,imgs   320] loss: 0.7375363  time: 0.951 s\n",
      "[epoch 3,imgs   360] loss: 0.7418695  time: 0.946 s\n",
      "[epoch 3,imgs   400] loss: 0.7373457  time: 0.945 s\n",
      "[epoch 3,imgs   440] loss: 0.7354826  time: 0.944 s\n",
      "[epoch 3,imgs   480] loss: 0.7411910  time: 0.946 s\n",
      "[epoch 3,imgs   520] loss: 0.7380780  time: 0.946 s\n",
      "[epoch 3,imgs   560] loss: 0.7387423  time: 0.948 s\n",
      "[epoch 3,imgs   600] loss: 0.7357994  time: 0.951 s\n",
      "[epoch 3,imgs   640] loss: 0.7394191  time: 0.962 s\n",
      "[epoch 3,imgs   680] loss: 0.7333099  time: 0.957 s\n",
      "[epoch 3,imgs   720] loss: 0.7423254  time: 0.956 s\n",
      "[epoch 3,imgs   760] loss: 0.7441334  time: 0.956 s\n",
      "[epoch 3,imgs   800] loss: 0.7369649  time: 0.957 s\n",
      "[epoch 3,imgs   840] loss: 0.7412037  time: 0.957 s\n",
      "[epoch 3,imgs   880] loss: 0.7369737  time: 0.961 s\n",
      "[epoch 3,imgs   920] loss: 0.7391965  time: 0.957 s\n",
      "[epoch 3,imgs   960] loss: 0.7392882  time: 0.959 s\n",
      "[epoch 3,imgs  1000] loss: 0.7424809  time: 0.959 s\n",
      "[epoch 3,imgs  1040] loss: 0.7395955  time: 0.961 s\n",
      "[epoch 3,imgs  1080] loss: 0.7416272  time: 0.962 s\n",
      "[epoch 3,imgs  1120] loss: 0.7392665  time: 0.962 s\n",
      "[epoch 3,imgs  1160] loss: 0.7407117  time: 0.959 s\n",
      "[epoch 3,imgs  1200] loss: 0.7353260  time: 0.959 s\n",
      "[epoch 4,imgs    40] loss: 0.7398140  time: 1.329 s\n",
      "[epoch 4,imgs    80] loss: 0.7412130  time: 0.948 s\n",
      "[epoch 4,imgs   120] loss: 0.7432252  time: 0.950 s\n",
      "[epoch 4,imgs   160] loss: 0.7375736  time: 0.949 s\n",
      "[epoch 4,imgs   200] loss: 0.7373201  time: 0.951 s\n",
      "[epoch 4,imgs   240] loss: 0.7397715  time: 0.949 s\n",
      "[epoch 4,imgs   280] loss: 0.7418935  time: 0.949 s\n",
      "[epoch 4,imgs   320] loss: 0.7426619  time: 0.949 s\n",
      "[epoch 4,imgs   360] loss: 0.7380933  time: 0.950 s\n",
      "[epoch 4,imgs   400] loss: 0.7410294  time: 0.951 s\n",
      "[epoch 4,imgs   440] loss: 0.7381474  time: 0.949 s\n",
      "[epoch 4,imgs   480] loss: 0.7409318  time: 0.949 s\n",
      "[epoch 4,imgs   520] loss: 0.7388307  time: 0.948 s\n",
      "[epoch 4,imgs   560] loss: 0.7397496  time: 0.948 s\n",
      "[epoch 4,imgs   600] loss: 0.7373835  time: 0.949 s\n",
      "[epoch 4,imgs   640] loss: 0.7433210  time: 0.949 s\n",
      "[epoch 4,imgs   680] loss: 0.7391197  time: 0.950 s\n",
      "[epoch 4,imgs   720] loss: 0.7398401  time: 0.950 s\n",
      "[epoch 4,imgs   760] loss: 0.7360939  time: 0.949 s\n",
      "[epoch 4,imgs   800] loss: 0.7422156  time: 0.950 s\n",
      "[epoch 4,imgs   840] loss: 0.7441736  time: 0.950 s\n",
      "[epoch 4,imgs   880] loss: 0.7355957  time: 0.952 s\n",
      "[epoch 4,imgs   920] loss: 0.7396153  time: 0.950 s\n",
      "[epoch 4,imgs   960] loss: 0.7441913  time: 0.951 s\n",
      "[epoch 4,imgs  1000] loss: 0.7389464  time: 0.954 s\n",
      "[epoch 4,imgs  1040] loss: 0.7410501  time: 0.950 s\n",
      "[epoch 4,imgs  1080] loss: 0.7367218  time: 0.948 s\n",
      "[epoch 4,imgs  1120] loss: 0.7402995  time: 0.950 s\n",
      "[epoch 4,imgs  1160] loss: 0.7387620  time: 0.952 s\n",
      "[epoch 4,imgs  1200] loss: 0.7393516  time: 0.950 s\n",
      "[epoch 5,imgs    40] loss: 0.7347004  time: 1.326 s\n",
      "[epoch 5,imgs    80] loss: 0.7411827  time: 0.952 s\n",
      "[epoch 5,imgs   120] loss: 0.7403678  time: 0.951 s\n",
      "[epoch 5,imgs   160] loss: 0.7338269  time: 0.952 s\n",
      "[epoch 5,imgs   200] loss: 0.7409410  time: 0.953 s\n",
      "[epoch 5,imgs   240] loss: 0.7373117  time: 0.951 s\n",
      "[epoch 5,imgs   280] loss: 0.7380530  time: 0.952 s\n",
      "[epoch 5,imgs   320] loss: 0.7397224  time: 0.952 s\n",
      "[epoch 5,imgs   360] loss: 0.7391176  time: 0.952 s\n",
      "[epoch 5,imgs   400] loss: 0.7372990  time: 0.952 s\n",
      "[epoch 5,imgs   440] loss: 0.7350577  time: 0.949 s\n",
      "[epoch 5,imgs   480] loss: 0.7410448  time: 0.951 s\n",
      "[epoch 5,imgs   520] loss: 0.7396239  time: 0.952 s\n",
      "[epoch 5,imgs   560] loss: 0.7403292  time: 0.950 s\n",
      "[epoch 5,imgs   600] loss: 0.7392201  time: 0.950 s\n",
      "[epoch 5,imgs   640] loss: 0.7415664  time: 0.950 s\n",
      "[epoch 5,imgs   680] loss: 0.7364758  time: 0.950 s\n",
      "[epoch 5,imgs   720] loss: 0.7364371  time: 0.952 s\n",
      "[epoch 5,imgs   760] loss: 0.7403927  time: 0.950 s\n",
      "[epoch 5,imgs   800] loss: 0.7378252  time: 0.950 s\n",
      "[epoch 5,imgs   840] loss: 0.7404612  time: 0.950 s\n",
      "[epoch 5,imgs   880] loss: 0.7410201  time: 0.951 s\n",
      "[epoch 5,imgs   920] loss: 0.7407792  time: 0.951 s\n",
      "[epoch 5,imgs   960] loss: 0.7401627  time: 0.951 s\n",
      "[epoch 5,imgs  1000] loss: 0.7401507  time: 0.953 s\n",
      "[epoch 5,imgs  1040] loss: 0.7389494  time: 0.953 s\n",
      "[epoch 5,imgs  1080] loss: 0.7420099  time: 0.954 s\n",
      "[epoch 5,imgs  1120] loss: 0.7438413  time: 0.953 s\n",
      "[epoch 5,imgs  1160] loss: 0.7458336  time: 0.952 s\n",
      "[epoch 5,imgs  1200] loss: 0.7410019  time: 0.953 s\n",
      "[epoch 6,imgs    40] loss: 0.7388957  time: 1.359 s\n",
      "[epoch 6,imgs    80] loss: 0.7378803  time: 0.951 s\n",
      "[epoch 6,imgs   120] loss: 0.7394776  time: 0.949 s\n",
      "[epoch 6,imgs   160] loss: 0.7379104  time: 0.959 s\n",
      "[epoch 6,imgs   200] loss: 0.7374691  time: 0.965 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6,imgs   240] loss: 0.7427058  time: 0.959 s\n",
      "[epoch 6,imgs   280] loss: 0.7382180  time: 0.962 s\n",
      "[epoch 6,imgs   320] loss: 0.7396926  time: 0.965 s\n",
      "[epoch 6,imgs   360] loss: 0.7368746  time: 0.963 s\n",
      "[epoch 6,imgs   400] loss: 0.7423671  time: 0.960 s\n",
      "[epoch 6,imgs   440] loss: 0.7383612  time: 0.960 s\n",
      "[epoch 6,imgs   480] loss: 0.7409030  time: 0.961 s\n",
      "[epoch 6,imgs   520] loss: 0.7410789  time: 0.952 s\n",
      "[epoch 6,imgs   560] loss: 0.7370366  time: 0.956 s\n",
      "[epoch 6,imgs   600] loss: 0.7387341  time: 0.962 s\n",
      "[epoch 6,imgs   640] loss: 0.7365826  time: 0.964 s\n",
      "[epoch 6,imgs   680] loss: 0.7405027  time: 0.966 s\n",
      "[epoch 6,imgs   720] loss: 0.7362674  time: 0.964 s\n",
      "[epoch 6,imgs   760] loss: 0.7363520  time: 0.963 s\n",
      "[epoch 6,imgs   800] loss: 0.7403989  time: 0.961 s\n",
      "[epoch 6,imgs   840] loss: 0.7381018  time: 0.960 s\n",
      "[epoch 6,imgs   880] loss: 0.7383973  time: 0.962 s\n",
      "[epoch 6,imgs   920] loss: 0.7379249  time: 0.960 s\n",
      "[epoch 6,imgs   960] loss: 0.7426349  time: 0.967 s\n",
      "[epoch 6,imgs  1000] loss: 0.7404971  time: 0.963 s\n",
      "[epoch 6,imgs  1040] loss: 0.7426260  time: 0.962 s\n",
      "[epoch 6,imgs  1080] loss: 0.7444496  time: 0.953 s\n",
      "[epoch 6,imgs  1120] loss: 0.7378587  time: 0.953 s\n",
      "[epoch 6,imgs  1160] loss: 0.7370702  time: 0.961 s\n",
      "[epoch 6,imgs  1200] loss: 0.7365775  time: 0.959 s\n",
      "[epoch 7,imgs    40] loss: 0.7381537  time: 1.309 s\n",
      "[epoch 7,imgs    80] loss: 0.7378747  time: 0.951 s\n",
      "[epoch 7,imgs   120] loss: 0.7381306  time: 0.953 s\n",
      "[epoch 7,imgs   160] loss: 0.7383994  time: 0.952 s\n",
      "[epoch 7,imgs   200] loss: 0.7414063  time: 0.954 s\n",
      "[epoch 7,imgs   240] loss: 0.7336100  time: 0.952 s\n",
      "[epoch 7,imgs   280] loss: 0.7389868  time: 0.952 s\n",
      "[epoch 7,imgs   320] loss: 0.7439631  time: 0.952 s\n",
      "[epoch 7,imgs   360] loss: 0.7416789  time: 0.953 s\n",
      "[epoch 7,imgs   400] loss: 0.7431064  time: 0.957 s\n",
      "[epoch 7,imgs   440] loss: 0.7392280  time: 0.952 s\n",
      "[epoch 7,imgs   480] loss: 0.7377006  time: 0.954 s\n",
      "[epoch 7,imgs   520] loss: 0.7347625  time: 0.954 s\n",
      "[epoch 7,imgs   560] loss: 0.7384790  time: 0.953 s\n",
      "[epoch 7,imgs   600] loss: 0.7418116  time: 0.952 s\n",
      "[epoch 7,imgs   640] loss: 0.7387810  time: 0.953 s\n",
      "[epoch 7,imgs   680] loss: 0.7391827  time: 0.952 s\n",
      "[epoch 7,imgs   720] loss: 0.7359402  time: 0.952 s\n",
      "[epoch 7,imgs   760] loss: 0.7396216  time: 0.953 s\n",
      "[epoch 7,imgs   800] loss: 0.7351925  time: 0.957 s\n",
      "[epoch 7,imgs   840] loss: 0.7359729  time: 0.953 s\n",
      "[epoch 7,imgs   880] loss: 0.7389728  time: 0.955 s\n",
      "[epoch 7,imgs   920] loss: 0.7391075  time: 0.952 s\n",
      "[epoch 7,imgs   960] loss: 0.7380104  time: 0.952 s\n",
      "[epoch 7,imgs  1000] loss: 0.7386585  time: 0.951 s\n",
      "[epoch 7,imgs  1040] loss: 0.7367616  time: 0.953 s\n",
      "[epoch 7,imgs  1080] loss: 0.7419999  time: 0.952 s\n",
      "[epoch 7,imgs  1120] loss: 0.7427452  time: 0.952 s\n",
      "[epoch 7,imgs  1160] loss: 0.7415975  time: 0.952 s\n",
      "[epoch 7,imgs  1200] loss: 0.7344403  time: 0.954 s\n",
      "[epoch 8,imgs    40] loss: 0.7423484  time: 1.354 s\n",
      "[epoch 8,imgs    80] loss: 0.7347330  time: 0.952 s\n",
      "[epoch 8,imgs   120] loss: 0.7384958  time: 0.953 s\n",
      "[epoch 8,imgs   160] loss: 0.7373238  time: 0.953 s\n",
      "[epoch 8,imgs   200] loss: 0.7389181  time: 0.951 s\n",
      "[epoch 8,imgs   240] loss: 0.7416211  time: 0.952 s\n",
      "[epoch 8,imgs   280] loss: 0.7379510  time: 0.952 s\n",
      "[epoch 8,imgs   320] loss: 0.7360021  time: 0.961 s\n",
      "[epoch 8,imgs   360] loss: 0.7384967  time: 0.954 s\n",
      "[epoch 8,imgs   400] loss: 0.7369632  time: 0.976 s\n",
      "[epoch 8,imgs   440] loss: 0.7371113  time: 0.979 s\n",
      "[epoch 8,imgs   480] loss: 0.7364702  time: 0.978 s\n",
      "[epoch 8,imgs   520] loss: 0.7403878  time: 0.977 s\n",
      "[epoch 8,imgs   560] loss: 0.7380212  time: 0.975 s\n",
      "[epoch 8,imgs   600] loss: 0.7374558  time: 0.976 s\n",
      "[epoch 8,imgs   640] loss: 0.7403274  time: 0.979 s\n",
      "[epoch 8,imgs   680] loss: 0.7387668  time: 0.981 s\n",
      "[epoch 8,imgs   720] loss: 0.7403895  time: 0.970 s\n",
      "[epoch 8,imgs   760] loss: 0.7395299  time: 0.968 s\n",
      "[epoch 8,imgs   800] loss: 0.7390285  time: 0.966 s\n",
      "[epoch 8,imgs   840] loss: 0.7395683  time: 0.966 s\n",
      "[epoch 8,imgs   880] loss: 0.7375130  time: 0.964 s\n",
      "[epoch 8,imgs   920] loss: 0.7412192  time: 0.967 s\n",
      "[epoch 8,imgs   960] loss: 0.7423564  time: 0.967 s\n",
      "[epoch 8,imgs  1000] loss: 0.7412693  time: 0.969 s\n",
      "[epoch 8,imgs  1040] loss: 0.7390164  time: 0.966 s\n",
      "[epoch 8,imgs  1080] loss: 0.7396658  time: 0.970 s\n",
      "[epoch 8,imgs  1120] loss: 0.7410333  time: 0.969 s\n",
      "[epoch 8,imgs  1160] loss: 0.7385094  time: 0.971 s\n",
      "[epoch 8,imgs  1200] loss: 0.7438945  time: 0.968 s\n",
      "[epoch 9,imgs    40] loss: 0.7422277  time: 1.358 s\n",
      "[epoch 9,imgs    80] loss: 0.7418413  time: 0.964 s\n",
      "[epoch 9,imgs   120] loss: 0.7396384  time: 0.966 s\n",
      "[epoch 9,imgs   160] loss: 0.7399412  time: 0.964 s\n",
      "[epoch 9,imgs   200] loss: 0.7418251  time: 0.967 s\n",
      "[epoch 9,imgs   240] loss: 0.7336947  time: 0.965 s\n",
      "[epoch 9,imgs   280] loss: 0.7394609  time: 0.964 s\n",
      "[epoch 9,imgs   320] loss: 0.7394593  time: 0.968 s\n",
      "[epoch 9,imgs   360] loss: 0.7431467  time: 0.965 s\n",
      "[epoch 9,imgs   400] loss: 0.7448549  time: 0.966 s\n",
      "[epoch 9,imgs   440] loss: 0.7373903  time: 0.965 s\n",
      "[epoch 9,imgs   480] loss: 0.7419957  time: 0.965 s\n",
      "[epoch 9,imgs   520] loss: 0.7414860  time: 0.966 s\n",
      "[epoch 9,imgs   560] loss: 0.7397477  time: 0.967 s\n",
      "[epoch 9,imgs   600] loss: 0.7386754  time: 0.967 s\n",
      "[epoch 9,imgs   640] loss: 0.7365699  time: 0.967 s\n",
      "[epoch 9,imgs   680] loss: 0.7430174  time: 0.965 s\n",
      "[epoch 9,imgs   720] loss: 0.7382082  time: 0.965 s\n",
      "[epoch 9,imgs   760] loss: 0.7400977  time: 0.965 s\n",
      "[epoch 9,imgs   800] loss: 0.7342342  time: 0.966 s\n",
      "[epoch 9,imgs   840] loss: 0.7381274  time: 0.965 s\n",
      "[epoch 9,imgs   880] loss: 0.7385008  time: 0.966 s\n",
      "[epoch 9,imgs   920] loss: 0.7402300  time: 0.969 s\n",
      "[epoch 9,imgs   960] loss: 0.7382710  time: 0.972 s\n",
      "[epoch 9,imgs  1000] loss: 0.7446788  time: 0.968 s\n",
      "[epoch 9,imgs  1040] loss: 0.7393007  time: 0.968 s\n",
      "[epoch 9,imgs  1080] loss: 0.7401010  time: 0.967 s\n",
      "[epoch 9,imgs  1120] loss: 0.7384330  time: 0.968 s\n",
      "[epoch 9,imgs  1160] loss: 0.7409491  time: 0.967 s\n",
      "[epoch 9,imgs  1200] loss: 0.7384265  time: 0.965 s\n",
      "[epoch 10,imgs    40] loss: 0.7390063  time: 1.348 s\n",
      "[epoch 10,imgs    80] loss: 0.7344375  time: 0.956 s\n",
      "[epoch 10,imgs   120] loss: 0.7439758  time: 0.954 s\n",
      "[epoch 10,imgs   160] loss: 0.7427916  time: 0.952 s\n",
      "[epoch 10,imgs   200] loss: 0.7395591  time: 0.954 s\n",
      "[epoch 10,imgs   240] loss: 0.7359877  time: 0.953 s\n",
      "[epoch 10,imgs   280] loss: 0.7361549  time: 0.954 s\n",
      "[epoch 10,imgs   320] loss: 0.7365150  time: 0.954 s\n",
      "[epoch 10,imgs   360] loss: 0.7409799  time: 0.960 s\n",
      "[epoch 10,imgs   400] loss: 0.7400821  time: 0.955 s\n",
      "[epoch 10,imgs   440] loss: 0.7389323  time: 0.954 s\n",
      "[epoch 10,imgs   480] loss: 0.7406868  time: 0.956 s\n",
      "[epoch 10,imgs   520] loss: 0.7393357  time: 0.955 s\n",
      "[epoch 10,imgs   560] loss: 0.7413031  time: 0.961 s\n",
      "[epoch 10,imgs   600] loss: 0.7371721  time: 0.954 s\n",
      "[epoch 10,imgs   640] loss: 0.7421137  time: 0.957 s\n",
      "[epoch 10,imgs   680] loss: 0.7363852  time: 0.957 s\n",
      "[epoch 10,imgs   720] loss: 0.7458875  time: 0.965 s\n",
      "[epoch 10,imgs   760] loss: 0.7389475  time: 0.961 s\n",
      "[epoch 10,imgs   800] loss: 0.7380666  time: 0.958 s\n",
      "[epoch 10,imgs   840] loss: 0.7427287  time: 0.954 s\n",
      "[epoch 10,imgs   880] loss: 0.7364565  time: 0.955 s\n",
      "[epoch 10,imgs   920] loss: 0.7372544  time: 0.957 s\n",
      "[epoch 10,imgs   960] loss: 0.7378933  time: 0.960 s\n",
      "[epoch 10,imgs  1000] loss: 0.7416919  time: 0.959 s\n",
      "[epoch 10,imgs  1040] loss: 0.7433042  time: 0.964 s\n",
      "[epoch 10,imgs  1080] loss: 0.7377775  time: 0.968 s\n",
      "[epoch 10,imgs  1120] loss: 0.7357168  time: 0.963 s\n",
      "[epoch 10,imgs  1160] loss: 0.7375974  time: 0.956 s\n",
      "[epoch 10,imgs  1200] loss: 0.7424585  time: 0.956 s\n",
      "[epoch 11,imgs    40] loss: 0.7463025  time: 1.345 s\n",
      "[epoch 11,imgs    80] loss: 0.7338574  time: 0.957 s\n",
      "[epoch 11,imgs   120] loss: 0.7407324  time: 0.957 s\n",
      "[epoch 11,imgs   160] loss: 0.7401783  time: 0.957 s\n",
      "[epoch 11,imgs   200] loss: 0.7380891  time: 0.956 s\n",
      "[epoch 11,imgs   240] loss: 0.7390708  time: 0.957 s\n",
      "[epoch 11,imgs   280] loss: 0.7400666  time: 0.958 s\n",
      "[epoch 11,imgs   320] loss: 0.7369146  time: 0.964 s\n",
      "[epoch 11,imgs   360] loss: 0.7391069  time: 0.957 s\n",
      "[epoch 11,imgs   400] loss: 0.7356161  time: 0.957 s\n",
      "[epoch 11,imgs   440] loss: 0.7389172  time: 0.957 s\n",
      "[epoch 11,imgs   480] loss: 0.7397223  time: 0.957 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11,imgs   520] loss: 0.7391607  time: 0.959 s\n",
      "[epoch 11,imgs   560] loss: 0.7387155  time: 0.956 s\n",
      "[epoch 11,imgs   600] loss: 0.7394482  time: 0.957 s\n",
      "[epoch 11,imgs   640] loss: 0.7372785  time: 0.958 s\n",
      "[epoch 11,imgs   680] loss: 0.7372288  time: 0.958 s\n",
      "[epoch 11,imgs   720] loss: 0.7386693  time: 0.967 s\n",
      "[epoch 11,imgs   760] loss: 0.7373679  time: 0.957 s\n",
      "[epoch 11,imgs   800] loss: 0.7412215  time: 0.963 s\n",
      "[epoch 11,imgs   840] loss: 0.7405621  time: 0.966 s\n",
      "[epoch 11,imgs   880] loss: 0.7365792  time: 0.965 s\n",
      "[epoch 11,imgs   920] loss: 0.7388884  time: 0.961 s\n",
      "[epoch 11,imgs   960] loss: 0.7410824  time: 0.958 s\n",
      "[epoch 11,imgs  1000] loss: 0.7400840  time: 0.957 s\n",
      "[epoch 11,imgs  1040] loss: 0.7399296  time: 0.958 s\n",
      "[epoch 11,imgs  1080] loss: 0.7431235  time: 0.960 s\n",
      "[epoch 11,imgs  1120] loss: 0.7386593  time: 0.960 s\n",
      "[epoch 11,imgs  1160] loss: 0.7426770  time: 0.961 s\n",
      "[epoch 11,imgs  1200] loss: 0.7393665  time: 0.960 s\n",
      "[epoch 12,imgs    40] loss: 0.7406815  time: 1.349 s\n",
      "[epoch 12,imgs    80] loss: 0.7397040  time: 0.957 s\n",
      "[epoch 12,imgs   120] loss: 0.7382175  time: 0.958 s\n",
      "[epoch 12,imgs   160] loss: 0.7366027  time: 0.961 s\n",
      "[epoch 12,imgs   200] loss: 0.7422622  time: 0.959 s\n",
      "[epoch 12,imgs   240] loss: 0.7382811  time: 0.958 s\n",
      "[epoch 12,imgs   280] loss: 0.7401263  time: 0.956 s\n",
      "[epoch 12,imgs   320] loss: 0.7394323  time: 0.957 s\n",
      "[epoch 12,imgs   360] loss: 0.7429832  time: 0.955 s\n",
      "[epoch 12,imgs   400] loss: 0.7393907  time: 0.956 s\n",
      "[epoch 12,imgs   440] loss: 0.7409084  time: 0.955 s\n",
      "[epoch 12,imgs   480] loss: 0.7385404  time: 0.955 s\n",
      "[epoch 12,imgs   520] loss: 0.7384666  time: 0.954 s\n",
      "[epoch 12,imgs   560] loss: 0.7366726  time: 0.954 s\n",
      "[epoch 12,imgs   600] loss: 0.7374727  time: 0.957 s\n",
      "[epoch 12,imgs   640] loss: 0.7395440  time: 0.961 s\n",
      "[epoch 12,imgs   680] loss: 0.7375856  time: 0.970 s\n",
      "[epoch 12,imgs   720] loss: 0.7371859  time: 0.966 s\n",
      "[epoch 12,imgs   760] loss: 0.7384423  time: 0.959 s\n",
      "[epoch 12,imgs   800] loss: 0.7345502  time: 0.955 s\n",
      "[epoch 12,imgs   840] loss: 0.7376975  time: 0.956 s\n",
      "[epoch 12,imgs   880] loss: 0.7363219  time: 0.956 s\n",
      "[epoch 12,imgs   920] loss: 0.7392873  time: 0.955 s\n",
      "[epoch 12,imgs   960] loss: 0.7388290  time: 0.956 s\n",
      "[epoch 12,imgs  1000] loss: 0.7393290  time: 0.958 s\n",
      "[epoch 12,imgs  1040] loss: 0.7374533  time: 0.957 s\n",
      "[epoch 12,imgs  1080] loss: 0.7373288  time: 0.956 s\n",
      "[epoch 12,imgs  1120] loss: 0.7387848  time: 0.957 s\n",
      "[epoch 12,imgs  1160] loss: 0.7386134  time: 0.957 s\n",
      "[epoch 12,imgs  1200] loss: 0.7384551  time: 0.956 s\n",
      "[epoch 13,imgs    40] loss: 0.7383235  time: 1.342 s\n",
      "[epoch 13,imgs    80] loss: 0.7412314  time: 0.956 s\n",
      "[epoch 13,imgs   120] loss: 0.7405003  time: 0.957 s\n",
      "[epoch 13,imgs   160] loss: 0.7365905  time: 0.955 s\n",
      "[epoch 13,imgs   200] loss: 0.7370670  time: 0.955 s\n",
      "[epoch 13,imgs   240] loss: 0.7406704  time: 0.955 s\n",
      "[epoch 13,imgs   280] loss: 0.7350638  time: 0.954 s\n",
      "[epoch 13,imgs   320] loss: 0.7389601  time: 0.956 s\n",
      "[epoch 13,imgs   360] loss: 0.7354572  time: 0.956 s\n",
      "[epoch 13,imgs   400] loss: 0.7377366  time: 0.955 s\n",
      "[epoch 13,imgs   440] loss: 0.7399809  time: 0.955 s\n",
      "[epoch 13,imgs   480] loss: 0.7385702  time: 0.955 s\n",
      "[epoch 13,imgs   520] loss: 0.7415725  time: 0.965 s\n",
      "[epoch 13,imgs   560] loss: 0.7407021  time: 0.964 s\n",
      "[epoch 13,imgs   600] loss: 0.7393556  time: 0.964 s\n",
      "[epoch 13,imgs   640] loss: 0.7408021  time: 0.957 s\n",
      "[epoch 13,imgs   680] loss: 0.7384334  time: 0.956 s\n",
      "[epoch 13,imgs   720] loss: 0.7391570  time: 0.957 s\n",
      "[epoch 13,imgs   760] loss: 0.7402735  time: 0.956 s\n",
      "[epoch 13,imgs   800] loss: 0.7370612  time: 0.957 s\n",
      "[epoch 13,imgs   840] loss: 0.7390154  time: 0.955 s\n",
      "[epoch 13,imgs   880] loss: 0.7383906  time: 0.959 s\n",
      "[epoch 13,imgs   920] loss: 0.7370017  time: 0.956 s\n",
      "[epoch 13,imgs   960] loss: 0.7379928  time: 0.956 s\n",
      "[epoch 13,imgs  1000] loss: 0.7412198  time: 0.955 s\n",
      "[epoch 13,imgs  1040] loss: 0.7340201  time: 0.955 s\n",
      "[epoch 13,imgs  1080] loss: 0.7423511  time: 0.955 s\n",
      "[epoch 13,imgs  1120] loss: 0.7363325  time: 0.964 s\n",
      "[epoch 13,imgs  1160] loss: 0.7390715  time: 0.969 s\n",
      "[epoch 13,imgs  1200] loss: 0.7379124  time: 0.966 s\n",
      "[epoch 14,imgs    40] loss: 0.7364949  time: 1.305 s\n",
      "[epoch 14,imgs    80] loss: 0.7356570  time: 0.959 s\n",
      "[epoch 14,imgs   120] loss: 0.7412099  time: 0.956 s\n",
      "[epoch 14,imgs   160] loss: 0.7365227  time: 0.956 s\n",
      "[epoch 14,imgs   200] loss: 0.7436591  time: 0.954 s\n",
      "[epoch 14,imgs   240] loss: 0.7420197  time: 0.958 s\n",
      "[epoch 14,imgs   280] loss: 0.7370524  time: 0.955 s\n",
      "[epoch 14,imgs   320] loss: 0.7399650  time: 0.955 s\n",
      "[epoch 14,imgs   360] loss: 0.7367378  time: 0.956 s\n",
      "[epoch 14,imgs   400] loss: 0.7389265  time: 0.955 s\n",
      "[epoch 14,imgs   440] loss: 0.7405703  time: 0.955 s\n",
      "[epoch 14,imgs   480] loss: 0.7345734  time: 0.955 s\n",
      "[epoch 14,imgs   520] loss: 0.7375596  time: 0.956 s\n",
      "[epoch 14,imgs   560] loss: 0.7401236  time: 0.963 s\n",
      "[epoch 14,imgs   600] loss: 0.7376491  time: 0.969 s\n",
      "[epoch 14,imgs   640] loss: 0.7406235  time: 0.968 s\n",
      "[epoch 14,imgs   680] loss: 0.7369798  time: 0.958 s\n",
      "[epoch 14,imgs   720] loss: 0.7377972  time: 0.956 s\n",
      "[epoch 14,imgs   760] loss: 0.7386971  time: 0.956 s\n",
      "[epoch 14,imgs   800] loss: 0.7396996  time: 0.957 s\n",
      "[epoch 14,imgs   840] loss: 0.7387652  time: 0.958 s\n",
      "[epoch 14,imgs   880] loss: 0.7419932  time: 0.957 s\n",
      "[epoch 14,imgs   920] loss: 0.7391211  time: 0.957 s\n",
      "[epoch 14,imgs   960] loss: 0.7445577  time: 0.958 s\n",
      "[epoch 14,imgs  1000] loss: 0.7363022  time: 0.958 s\n",
      "[epoch 14,imgs  1040] loss: 0.7405756  time: 0.958 s\n",
      "[epoch 14,imgs  1080] loss: 0.7366574  time: 0.957 s\n",
      "[epoch 14,imgs  1120] loss: 0.7396437  time: 0.957 s\n",
      "[epoch 14,imgs  1160] loss: 0.7384639  time: 0.957 s\n",
      "[epoch 14,imgs  1200] loss: 0.7377737  time: 0.956 s\n",
      "[epoch 15,imgs    40] loss: 0.7411723  time: 1.358 s\n",
      "[epoch 15,imgs    80] loss: 0.7379637  time: 0.965 s\n",
      "[epoch 15,imgs   120] loss: 0.7414784  time: 0.954 s\n",
      "[epoch 15,imgs   160] loss: 0.7435728  time: 0.957 s\n",
      "[epoch 15,imgs   200] loss: 0.7404956  time: 0.956 s\n",
      "[epoch 15,imgs   240] loss: 0.7411667  time: 0.958 s\n",
      "[epoch 15,imgs   280] loss: 0.7356877  time: 0.957 s\n",
      "[epoch 15,imgs   320] loss: 0.7399480  time: 0.955 s\n",
      "[epoch 15,imgs   360] loss: 0.7389899  time: 0.956 s\n",
      "[epoch 15,imgs   400] loss: 0.7404276  time: 0.956 s\n",
      "[epoch 15,imgs   440] loss: 0.7359623  time: 0.956 s\n",
      "[epoch 15,imgs   480] loss: 0.7374339  time: 0.956 s\n",
      "[epoch 15,imgs   520] loss: 0.7406150  time: 0.955 s\n",
      "[epoch 15,imgs   560] loss: 0.7391813  time: 0.956 s\n",
      "[epoch 15,imgs   600] loss: 0.7377648  time: 0.956 s\n",
      "[epoch 15,imgs   640] loss: 0.7359446  time: 0.956 s\n",
      "[epoch 15,imgs   680] loss: 0.7429469  time: 0.957 s\n",
      "[epoch 15,imgs   720] loss: 0.7415485  time: 0.958 s\n",
      "[epoch 15,imgs   760] loss: 0.7410053  time: 0.956 s\n",
      "[epoch 15,imgs   800] loss: 0.7367209  time: 0.957 s\n",
      "[epoch 15,imgs   840] loss: 0.7359999  time: 0.957 s\n",
      "[epoch 15,imgs   880] loss: 0.7390527  time: 0.956 s\n",
      "[epoch 15,imgs   920] loss: 0.7357306  time: 0.956 s\n",
      "[epoch 15,imgs   960] loss: 0.7406161  time: 0.954 s\n",
      "[epoch 15,imgs  1000] loss: 0.7374657  time: 0.955 s\n",
      "[epoch 15,imgs  1040] loss: 0.7407362  time: 0.957 s\n",
      "[epoch 15,imgs  1080] loss: 0.7342625  time: 0.956 s\n",
      "[epoch 15,imgs  1120] loss: 0.7382873  time: 0.955 s\n",
      "[epoch 15,imgs  1160] loss: 0.7399030  time: 0.957 s\n",
      "[epoch 15,imgs  1200] loss: 0.7362683  time: 0.954 s\n",
      "[epoch 16,imgs    40] loss: 0.7372817  time: 1.337 s\n",
      "[epoch 16,imgs    80] loss: 0.7389140  time: 0.957 s\n",
      "[epoch 16,imgs   120] loss: 0.7363977  time: 0.956 s\n",
      "[epoch 16,imgs   160] loss: 0.7381629  time: 0.957 s\n",
      "[epoch 16,imgs   200] loss: 0.7425026  time: 0.956 s\n",
      "[epoch 16,imgs   240] loss: 0.7440112  time: 0.956 s\n",
      "[epoch 16,imgs   280] loss: 0.7380736  time: 0.956 s\n",
      "[epoch 16,imgs   320] loss: 0.7404028  time: 0.956 s\n",
      "[epoch 16,imgs   360] loss: 0.7357066  time: 0.955 s\n",
      "[epoch 16,imgs   400] loss: 0.7386467  time: 0.954 s\n",
      "[epoch 16,imgs   440] loss: 0.7385044  time: 0.962 s\n",
      "[epoch 16,imgs   480] loss: 0.7385854  time: 0.963 s\n",
      "[epoch 16,imgs   520] loss: 0.7406995  time: 0.961 s\n",
      "[epoch 16,imgs   560] loss: 0.7394315  time: 0.967 s\n",
      "[epoch 16,imgs   600] loss: 0.7413906  time: 0.957 s\n",
      "[epoch 16,imgs   640] loss: 0.7406968  time: 0.956 s\n",
      "[epoch 16,imgs   680] loss: 0.7369463  time: 0.956 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16,imgs   720] loss: 0.7407792  time: 0.956 s\n",
      "[epoch 16,imgs   760] loss: 0.7387714  time: 0.956 s\n",
      "[epoch 16,imgs   800] loss: 0.7405117  time: 0.957 s\n",
      "[epoch 16,imgs   840] loss: 0.7371438  time: 0.956 s\n",
      "[epoch 16,imgs   880] loss: 0.7347716  time: 0.955 s\n",
      "[epoch 16,imgs   920] loss: 0.7373636  time: 0.957 s\n",
      "[epoch 16,imgs   960] loss: 0.7389492  time: 0.957 s\n",
      "[epoch 16,imgs  1000] loss: 0.7403759  time: 0.957 s\n",
      "[epoch 16,imgs  1040] loss: 0.7394132  time: 0.957 s\n",
      "[epoch 16,imgs  1080] loss: 0.7358475  time: 0.955 s\n",
      "[epoch 16,imgs  1120] loss: 0.7397929  time: 0.957 s\n",
      "[epoch 16,imgs  1160] loss: 0.7413535  time: 0.958 s\n",
      "[epoch 16,imgs  1200] loss: 0.7364906  time: 0.957 s\n",
      "[epoch 17,imgs    40] loss: 0.7379495  time: 1.370 s\n",
      "[epoch 17,imgs    80] loss: 0.7357008  time: 0.965 s\n",
      "[epoch 17,imgs   120] loss: 0.7391927  time: 0.965 s\n",
      "[epoch 17,imgs   160] loss: 0.7412997  time: 0.963 s\n",
      "[epoch 17,imgs   200] loss: 0.7385875  time: 0.969 s\n",
      "[epoch 17,imgs   240] loss: 0.7416677  time: 0.967 s\n",
      "[epoch 17,imgs   280] loss: 0.7410167  time: 0.966 s\n",
      "[epoch 17,imgs   320] loss: 0.7409432  time: 0.954 s\n",
      "[epoch 17,imgs   360] loss: 0.7351395  time: 0.968 s\n",
      "[epoch 17,imgs   400] loss: 0.7412883  time: 0.957 s\n",
      "[epoch 17,imgs   440] loss: 0.7388268  time: 0.953 s\n",
      "[epoch 17,imgs   480] loss: 0.7412080  time: 0.965 s\n",
      "[epoch 17,imgs   520] loss: 0.7363259  time: 0.953 s\n",
      "[epoch 17,imgs   560] loss: 0.7378196  time: 0.963 s\n",
      "[epoch 17,imgs   600] loss: 0.7360743  time: 0.969 s\n",
      "[epoch 17,imgs   640] loss: 0.7396903  time: 0.966 s\n",
      "[epoch 17,imgs   680] loss: 0.7424276  time: 0.956 s\n",
      "[epoch 17,imgs   720] loss: 0.7364907  time: 0.954 s\n",
      "[epoch 17,imgs   760] loss: 0.7448551  time: 0.958 s\n",
      "[epoch 17,imgs   800] loss: 0.7393124  time: 0.962 s\n",
      "[epoch 17,imgs   840] loss: 0.7417272  time: 0.965 s\n",
      "[epoch 17,imgs   880] loss: 0.7465320  time: 0.963 s\n",
      "[epoch 17,imgs   920] loss: 0.7346877  time: 0.960 s\n",
      "[epoch 17,imgs   960] loss: 0.7379552  time: 0.956 s\n",
      "[epoch 17,imgs  1000] loss: 0.7418798  time: 0.958 s\n",
      "[epoch 17,imgs  1040] loss: 0.7357767  time: 0.956 s\n",
      "[epoch 17,imgs  1080] loss: 0.7407040  time: 0.956 s\n",
      "[epoch 17,imgs  1120] loss: 0.7377313  time: 0.955 s\n",
      "[epoch 17,imgs  1160] loss: 0.7404445  time: 0.972 s\n",
      "[epoch 17,imgs  1200] loss: 0.7414184  time: 0.952 s\n",
      "[epoch 18,imgs    40] loss: 0.7389669  time: 1.310 s\n",
      "[epoch 18,imgs    80] loss: 0.7405140  time: 0.958 s\n",
      "[epoch 18,imgs   120] loss: 0.7355770  time: 0.957 s\n",
      "[epoch 18,imgs   160] loss: 0.7376120  time: 0.957 s\n",
      "[epoch 18,imgs   200] loss: 0.7383893  time: 0.963 s\n",
      "[epoch 18,imgs   240] loss: 0.7394190  time: 0.961 s\n",
      "[epoch 18,imgs   280] loss: 0.7430580  time: 0.956 s\n",
      "[epoch 18,imgs   320] loss: 0.7426647  time: 0.956 s\n",
      "[epoch 18,imgs   360] loss: 0.7413189  time: 0.956 s\n",
      "[epoch 18,imgs   400] loss: 0.7396594  time: 0.956 s\n",
      "[epoch 18,imgs   440] loss: 0.7449485  time: 0.956 s\n",
      "[epoch 18,imgs   480] loss: 0.7408694  time: 0.955 s\n",
      "[epoch 18,imgs   520] loss: 0.7386432  time: 0.955 s\n",
      "[epoch 18,imgs   560] loss: 0.7364429  time: 0.956 s\n",
      "[epoch 18,imgs   600] loss: 0.7434091  time: 0.957 s\n",
      "[epoch 18,imgs   640] loss: 0.7384325  time: 0.956 s\n",
      "[epoch 18,imgs   680] loss: 0.7401674  time: 0.959 s\n",
      "[epoch 18,imgs   720] loss: 0.7405080  time: 0.956 s\n",
      "[epoch 18,imgs   760] loss: 0.7402924  time: 0.958 s\n",
      "[epoch 18,imgs   800] loss: 0.7362274  time: 0.956 s\n",
      "[epoch 18,imgs   840] loss: 0.7380441  time: 0.955 s\n",
      "[epoch 18,imgs   880] loss: 0.7429652  time: 0.957 s\n",
      "[epoch 18,imgs   920] loss: 0.7393685  time: 0.955 s\n",
      "[epoch 18,imgs   960] loss: 0.7371130  time: 0.956 s\n",
      "[epoch 18,imgs  1000] loss: 0.7368567  time: 0.955 s\n",
      "[epoch 18,imgs  1040] loss: 0.7376630  time: 0.956 s\n",
      "[epoch 18,imgs  1080] loss: 0.7435345  time: 0.956 s\n",
      "[epoch 18,imgs  1120] loss: 0.7409475  time: 0.958 s\n",
      "[epoch 18,imgs  1160] loss: 0.7368914  time: 0.957 s\n",
      "[epoch 18,imgs  1200] loss: 0.7350800  time: 0.956 s\n",
      "[epoch 19,imgs    40] loss: 0.7393227  time: 1.332 s\n",
      "[epoch 19,imgs    80] loss: 0.7345544  time: 0.958 s\n",
      "[epoch 19,imgs   120] loss: 0.7387936  time: 0.957 s\n",
      "[epoch 19,imgs   160] loss: 0.7403442  time: 0.956 s\n",
      "[epoch 19,imgs   200] loss: 0.7389819  time: 0.960 s\n",
      "[epoch 19,imgs   240] loss: 0.7413109  time: 0.956 s\n",
      "[epoch 19,imgs   280] loss: 0.7399699  time: 0.957 s\n",
      "[epoch 19,imgs   320] loss: 0.7397751  time: 0.958 s\n",
      "[epoch 19,imgs   360] loss: 0.7414701  time: 0.956 s\n",
      "[epoch 19,imgs   400] loss: 0.7401436  time: 0.958 s\n",
      "[epoch 19,imgs   440] loss: 0.7364287  time: 0.956 s\n",
      "[epoch 19,imgs   480] loss: 0.7429721  time: 0.956 s\n",
      "[epoch 19,imgs   520] loss: 0.7396098  time: 0.958 s\n",
      "[epoch 19,imgs   560] loss: 0.7373723  time: 0.956 s\n",
      "[epoch 19,imgs   600] loss: 0.7392691  time: 0.956 s\n",
      "[epoch 19,imgs   640] loss: 0.7399386  time: 0.957 s\n",
      "[epoch 19,imgs   680] loss: 0.7390908  time: 0.959 s\n",
      "[epoch 19,imgs   720] loss: 0.7397222  time: 0.958 s\n",
      "[epoch 19,imgs   760] loss: 0.7374397  time: 0.957 s\n",
      "[epoch 19,imgs   800] loss: 0.7410982  time: 0.956 s\n",
      "[epoch 19,imgs   840] loss: 0.7406467  time: 0.957 s\n",
      "[epoch 19,imgs   880] loss: 0.7383756  time: 0.957 s\n",
      "[epoch 19,imgs   920] loss: 0.7403636  time: 0.956 s\n",
      "[epoch 19,imgs   960] loss: 0.7396058  time: 0.956 s\n",
      "[epoch 19,imgs  1000] loss: 0.7407749  time: 0.957 s\n",
      "[epoch 19,imgs  1040] loss: 0.7379702  time: 0.957 s\n",
      "[epoch 19,imgs  1080] loss: 0.7389282  time: 0.957 s\n",
      "[epoch 19,imgs  1120] loss: 0.7365056  time: 0.956 s\n",
      "[epoch 19,imgs  1160] loss: 0.7391601  time: 0.960 s\n",
      "[epoch 19,imgs  1200] loss: 0.7378186  time: 0.957 s\n",
      "[epoch 20,imgs    40] loss: 0.7415854  time: 1.341 s\n",
      "[epoch 20,imgs    80] loss: 0.7430114  time: 0.960 s\n",
      "[epoch 20,imgs   120] loss: 0.7398436  time: 0.958 s\n",
      "[epoch 20,imgs   160] loss: 0.7380355  time: 0.959 s\n",
      "[epoch 20,imgs   200] loss: 0.7389001  time: 0.957 s\n",
      "[epoch 20,imgs   240] loss: 0.7402284  time: 0.958 s\n",
      "[epoch 20,imgs   280] loss: 0.7388407  time: 0.958 s\n",
      "[epoch 20,imgs   320] loss: 0.7408481  time: 0.966 s\n",
      "[epoch 20,imgs   360] loss: 0.7417759  time: 0.956 s\n",
      "[epoch 20,imgs   400] loss: 0.7416331  time: 0.968 s\n",
      "[epoch 20,imgs   440] loss: 0.7409915  time: 0.956 s\n",
      "[epoch 20,imgs   480] loss: 0.7400241  time: 0.961 s\n",
      "[epoch 20,imgs   520] loss: 0.7423537  time: 0.975 s\n",
      "[epoch 20,imgs   560] loss: 0.7340102  time: 0.959 s\n",
      "[epoch 20,imgs   600] loss: 0.7413406  time: 0.956 s\n",
      "[epoch 20,imgs   640] loss: 0.7339451  time: 0.958 s\n",
      "[epoch 20,imgs   680] loss: 0.7371273  time: 0.956 s\n",
      "[epoch 20,imgs   720] loss: 0.7396735  time: 0.969 s\n",
      "[epoch 20,imgs   760] loss: 0.7402906  time: 0.979 s\n",
      "[epoch 20,imgs   800] loss: 0.7370355  time: 0.971 s\n",
      "[epoch 20,imgs   840] loss: 0.7426611  time: 0.968 s\n",
      "[epoch 20,imgs   880] loss: 0.7417304  time: 0.969 s\n",
      "[epoch 20,imgs   920] loss: 0.7395871  time: 0.968 s\n",
      "[epoch 20,imgs   960] loss: 0.7339154  time: 0.968 s\n",
      "[epoch 20,imgs  1000] loss: 0.7369974  time: 0.968 s\n",
      "[epoch 20,imgs  1040] loss: 0.7414171  time: 0.968 s\n",
      "[epoch 20,imgs  1080] loss: 0.7388358  time: 0.967 s\n",
      "[epoch 20,imgs  1120] loss: 0.7381099  time: 0.967 s\n",
      "[epoch 20,imgs  1160] loss: 0.7423349  time: 0.967 s\n",
      "[epoch 20,imgs  1200] loss: 0.7364388  time: 0.970 s\n",
      "[epoch 21,imgs    40] loss: 0.7398803  time: 1.356 s\n",
      "[epoch 21,imgs    80] loss: 0.7387309  time: 0.956 s\n",
      "[epoch 21,imgs   120] loss: 0.7410132  time: 0.955 s\n",
      "[epoch 21,imgs   160] loss: 0.7390245  time: 0.955 s\n",
      "[epoch 21,imgs   200] loss: 0.7352834  time: 0.955 s\n",
      "[epoch 21,imgs   240] loss: 0.7378623  time: 0.955 s\n",
      "[epoch 21,imgs   280] loss: 0.7416726  time: 0.955 s\n",
      "[epoch 21,imgs   320] loss: 0.7397560  time: 0.958 s\n",
      "[epoch 21,imgs   360] loss: 0.7404022  time: 0.957 s\n",
      "[epoch 21,imgs   400] loss: 0.7396960  time: 0.955 s\n",
      "[epoch 21,imgs   440] loss: 0.7419789  time: 0.958 s\n",
      "[epoch 21,imgs   480] loss: 0.7373911  time: 0.955 s\n",
      "[epoch 21,imgs   520] loss: 0.7416437  time: 0.954 s\n",
      "[epoch 21,imgs   560] loss: 0.7398396  time: 0.955 s\n",
      "[epoch 21,imgs   600] loss: 0.7408864  time: 0.956 s\n",
      "[epoch 21,imgs   640] loss: 0.7399464  time: 0.955 s\n",
      "[epoch 21,imgs   680] loss: 0.7393690  time: 0.955 s\n",
      "[epoch 21,imgs   720] loss: 0.7334790  time: 0.958 s\n",
      "[epoch 21,imgs   760] loss: 0.7355759  time: 0.957 s\n",
      "[epoch 21,imgs   800] loss: 0.7413263  time: 0.957 s\n",
      "[epoch 21,imgs   840] loss: 0.7359830  time: 0.957 s\n",
      "[epoch 21,imgs   880] loss: 0.7367979  time: 0.955 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21,imgs   920] loss: 0.7381100  time: 0.956 s\n",
      "[epoch 21,imgs   960] loss: 0.7391832  time: 0.957 s\n",
      "[epoch 21,imgs  1000] loss: 0.7363527  time: 0.956 s\n",
      "[epoch 21,imgs  1040] loss: 0.7396860  time: 0.956 s\n",
      "[epoch 21,imgs  1080] loss: 0.7356641  time: 0.956 s\n",
      "[epoch 21,imgs  1120] loss: 0.7372336  time: 0.961 s\n",
      "[epoch 21,imgs  1160] loss: 0.7331828  time: 0.957 s\n",
      "[epoch 21,imgs  1200] loss: 0.7390982  time: 0.959 s\n",
      "[epoch 22,imgs    40] loss: 0.7395834  time: 1.316 s\n",
      "[epoch 22,imgs    80] loss: 0.7420052  time: 0.956 s\n",
      "[epoch 22,imgs   120] loss: 0.7402399  time: 0.958 s\n",
      "[epoch 22,imgs   160] loss: 0.7419688  time: 0.958 s\n",
      "[epoch 22,imgs   200] loss: 0.7424991  time: 0.956 s\n",
      "[epoch 22,imgs   240] loss: 0.7418255  time: 0.956 s\n",
      "[epoch 22,imgs   280] loss: 0.7414982  time: 0.955 s\n",
      "[epoch 22,imgs   320] loss: 0.7381527  time: 0.955 s\n",
      "[epoch 22,imgs   360] loss: 0.7385570  time: 0.955 s\n",
      "[epoch 22,imgs   400] loss: 0.7389138  time: 0.955 s\n",
      "[epoch 22,imgs   440] loss: 0.7403369  time: 0.957 s\n",
      "[epoch 22,imgs   480] loss: 0.7391108  time: 0.955 s\n",
      "[epoch 22,imgs   520] loss: 0.7399022  time: 0.955 s\n",
      "[epoch 22,imgs   560] loss: 0.7337829  time: 0.954 s\n",
      "[epoch 22,imgs   600] loss: 0.7415252  time: 0.957 s\n",
      "[epoch 22,imgs   640] loss: 0.7352340  time: 0.955 s\n",
      "[epoch 22,imgs   680] loss: 0.7395560  time: 0.955 s\n",
      "[epoch 22,imgs   720] loss: 0.7404293  time: 0.956 s\n",
      "[epoch 22,imgs   760] loss: 0.7404209  time: 0.958 s\n",
      "[epoch 22,imgs   800] loss: 0.7407128  time: 0.956 s\n",
      "[epoch 22,imgs   840] loss: 0.7417759  time: 0.953 s\n",
      "[epoch 22,imgs   880] loss: 0.7378898  time: 0.955 s\n",
      "[epoch 22,imgs   920] loss: 0.7399442  time: 0.959 s\n",
      "[epoch 22,imgs   960] loss: 0.7388179  time: 0.956 s\n",
      "[epoch 22,imgs  1000] loss: 0.7350053  time: 0.955 s\n",
      "[epoch 22,imgs  1040] loss: 0.7381473  time: 0.958 s\n",
      "[epoch 22,imgs  1080] loss: 0.7412148  time: 0.955 s\n",
      "[epoch 22,imgs  1120] loss: 0.7367209  time: 0.957 s\n",
      "[epoch 22,imgs  1160] loss: 0.7423170  time: 0.956 s\n",
      "[epoch 22,imgs  1200] loss: 0.7407851  time: 0.955 s\n",
      "[epoch 23,imgs    40] loss: 0.7406253  time: 1.331 s\n",
      "[epoch 23,imgs    80] loss: 0.7419896  time: 0.956 s\n",
      "[epoch 23,imgs   120] loss: 0.7375618  time: 0.956 s\n",
      "[epoch 23,imgs   160] loss: 0.7411530  time: 0.955 s\n",
      "[epoch 23,imgs   200] loss: 0.7414237  time: 0.954 s\n",
      "[epoch 23,imgs   240] loss: 0.7448480  time: 0.957 s\n",
      "[epoch 23,imgs   280] loss: 0.7410327  time: 0.956 s\n",
      "[epoch 23,imgs   320] loss: 0.7372743  time: 0.958 s\n",
      "[epoch 23,imgs   360] loss: 0.7403374  time: 0.955 s\n",
      "[epoch 23,imgs   400] loss: 0.7360553  time: 0.955 s\n",
      "[epoch 23,imgs   440] loss: 0.7387262  time: 0.957 s\n",
      "[epoch 23,imgs   480] loss: 0.7413055  time: 0.956 s\n",
      "[epoch 23,imgs   520] loss: 0.7346688  time: 0.955 s\n",
      "[epoch 23,imgs   560] loss: 0.7343833  time: 0.954 s\n",
      "[epoch 23,imgs   600] loss: 0.7384158  time: 0.960 s\n",
      "[epoch 23,imgs   640] loss: 0.7369162  time: 0.957 s\n",
      "[epoch 23,imgs   680] loss: 0.7376643  time: 0.956 s\n",
      "[epoch 23,imgs   720] loss: 0.7389627  time: 0.956 s\n",
      "[epoch 23,imgs   760] loss: 0.7408157  time: 0.957 s\n",
      "[epoch 23,imgs   800] loss: 0.7376850  time: 0.958 s\n",
      "[epoch 23,imgs   840] loss: 0.7395431  time: 0.958 s\n",
      "[epoch 23,imgs   880] loss: 0.7398565  time: 0.957 s\n",
      "[epoch 23,imgs   920] loss: 0.7399361  time: 0.957 s\n",
      "[epoch 23,imgs   960] loss: 0.7363783  time: 0.957 s\n",
      "[epoch 23,imgs  1000] loss: 0.7386334  time: 0.956 s\n",
      "[epoch 23,imgs  1040] loss: 0.7400954  time: 0.958 s\n",
      "[epoch 23,imgs  1080] loss: 0.7434624  time: 0.956 s\n",
      "[epoch 23,imgs  1120] loss: 0.7376338  time: 0.956 s\n",
      "[epoch 23,imgs  1160] loss: 0.7409772  time: 0.956 s\n",
      "[epoch 23,imgs  1200] loss: 0.7376015  time: 0.956 s\n",
      "[epoch 24,imgs    40] loss: 0.7429189  time: 1.354 s\n",
      "[epoch 24,imgs    80] loss: 0.7401966  time: 0.959 s\n",
      "[epoch 24,imgs   120] loss: 0.7383172  time: 0.958 s\n",
      "[epoch 24,imgs   160] loss: 0.7392387  time: 0.957 s\n",
      "[epoch 24,imgs   200] loss: 0.7366155  time: 0.957 s\n",
      "[epoch 24,imgs   240] loss: 0.7424031  time: 0.957 s\n",
      "[epoch 24,imgs   280] loss: 0.7422453  time: 0.957 s\n",
      "[epoch 24,imgs   320] loss: 0.7388353  time: 0.955 s\n",
      "[epoch 24,imgs   360] loss: 0.7356105  time: 0.955 s\n",
      "[epoch 24,imgs   400] loss: 0.7386451  time: 0.956 s\n",
      "[epoch 24,imgs   440] loss: 0.7433333  time: 0.957 s\n",
      "[epoch 24,imgs   480] loss: 0.7405551  time: 0.954 s\n",
      "[epoch 24,imgs   520] loss: 0.7385669  time: 0.957 s\n",
      "[epoch 24,imgs   560] loss: 0.7374653  time: 0.955 s\n",
      "[epoch 24,imgs   600] loss: 0.7420250  time: 0.955 s\n",
      "[epoch 24,imgs   640] loss: 0.7395477  time: 0.955 s\n",
      "[epoch 24,imgs   680] loss: 0.7405280  time: 0.957 s\n",
      "[epoch 24,imgs   720] loss: 0.7416286  time: 0.957 s\n",
      "[epoch 24,imgs   760] loss: 0.7333518  time: 0.956 s\n",
      "[epoch 24,imgs   800] loss: 0.7421568  time: 0.957 s\n",
      "[epoch 24,imgs   840] loss: 0.7398086  time: 0.956 s\n",
      "[epoch 24,imgs   880] loss: 0.7384187  time: 0.954 s\n",
      "[epoch 24,imgs   920] loss: 0.7443165  time: 0.955 s\n",
      "[epoch 24,imgs   960] loss: 0.7393958  time: 0.955 s\n",
      "[epoch 24,imgs  1000] loss: 0.7416368  time: 0.958 s\n",
      "[epoch 24,imgs  1040] loss: 0.7406499  time: 0.956 s\n",
      "[epoch 24,imgs  1080] loss: 0.7375514  time: 0.957 s\n",
      "[epoch 24,imgs  1120] loss: 0.7411373  time: 0.956 s\n",
      "[epoch 24,imgs  1160] loss: 0.7381748  time: 0.957 s\n",
      "[epoch 24,imgs  1200] loss: 0.7386559  time: 0.955 s\n",
      "[epoch 25,imgs    40] loss: 0.7387947  time: 1.349 s\n",
      "[epoch 25,imgs    80] loss: 0.7375282  time: 0.957 s\n",
      "[epoch 25,imgs   120] loss: 0.7358667  time: 0.957 s\n",
      "[epoch 25,imgs   160] loss: 0.7408312  time: 0.953 s\n",
      "[epoch 25,imgs   200] loss: 0.7389704  time: 0.955 s\n",
      "[epoch 25,imgs   240] loss: 0.7423062  time: 0.953 s\n",
      "[epoch 25,imgs   280] loss: 0.7392148  time: 0.953 s\n",
      "[epoch 25,imgs   320] loss: 0.7434403  time: 0.954 s\n",
      "[epoch 25,imgs   360] loss: 0.7352965  time: 0.953 s\n",
      "[epoch 25,imgs   400] loss: 0.7416851  time: 0.956 s\n",
      "[epoch 25,imgs   440] loss: 0.7405906  time: 0.954 s\n",
      "[epoch 25,imgs   480] loss: 0.7388003  time: 0.955 s\n",
      "[epoch 25,imgs   520] loss: 0.7375660  time: 0.954 s\n",
      "[epoch 25,imgs   560] loss: 0.7400729  time: 0.957 s\n",
      "[epoch 25,imgs   600] loss: 0.7391273  time: 0.956 s\n",
      "[epoch 25,imgs   640] loss: 0.7372513  time: 0.955 s\n",
      "[epoch 25,imgs   680] loss: 0.7366679  time: 0.956 s\n",
      "[epoch 25,imgs   720] loss: 0.7429661  time: 0.955 s\n",
      "[epoch 25,imgs   760] loss: 0.7364088  time: 0.955 s\n",
      "[epoch 25,imgs   800] loss: 0.7385514  time: 0.955 s\n",
      "[epoch 25,imgs   840] loss: 0.7374667  time: 0.955 s\n",
      "[epoch 25,imgs   880] loss: 0.7387293  time: 0.954 s\n",
      "[epoch 25,imgs   920] loss: 0.7430592  time: 0.956 s\n",
      "[epoch 25,imgs   960] loss: 0.7416485  time: 0.956 s\n",
      "[epoch 25,imgs  1000] loss: 0.7384195  time: 0.955 s\n",
      "[epoch 25,imgs  1040] loss: 0.7378727  time: 0.957 s\n",
      "[epoch 25,imgs  1080] loss: 0.7360532  time: 0.956 s\n",
      "[epoch 25,imgs  1120] loss: 0.7392821  time: 0.956 s\n",
      "[epoch 25,imgs  1160] loss: 0.7399096  time: 0.954 s\n",
      "[epoch 25,imgs  1200] loss: 0.7383732  time: 0.954 s\n",
      "[epoch 26,imgs    40] loss: 0.7421857  time: 1.349 s\n",
      "[epoch 26,imgs    80] loss: 0.7382706  time: 0.955 s\n",
      "[epoch 26,imgs   120] loss: 0.7339153  time: 0.954 s\n",
      "[epoch 26,imgs   160] loss: 0.7421993  time: 0.954 s\n",
      "[epoch 26,imgs   200] loss: 0.7393526  time: 0.955 s\n",
      "[epoch 26,imgs   240] loss: 0.7375336  time: 0.960 s\n",
      "[epoch 26,imgs   280] loss: 0.7394064  time: 0.956 s\n",
      "[epoch 26,imgs   320] loss: 0.7434019  time: 0.956 s\n",
      "[epoch 26,imgs   360] loss: 0.7413445  time: 0.956 s\n",
      "[epoch 26,imgs   400] loss: 0.7394019  time: 0.956 s\n",
      "[epoch 26,imgs   440] loss: 0.7399914  time: 0.956 s\n",
      "[epoch 26,imgs   480] loss: 0.7374079  time: 0.956 s\n",
      "[epoch 26,imgs   520] loss: 0.7396396  time: 0.957 s\n",
      "[epoch 26,imgs   560] loss: 0.7381902  time: 0.956 s\n",
      "[epoch 26,imgs   600] loss: 0.7366911  time: 0.955 s\n",
      "[epoch 26,imgs   640] loss: 0.7463409  time: 0.957 s\n",
      "[epoch 26,imgs   680] loss: 0.7417887  time: 0.956 s\n",
      "[epoch 26,imgs   720] loss: 0.7343001  time: 0.956 s\n",
      "[epoch 26,imgs   760] loss: 0.7369793  time: 0.956 s\n",
      "[epoch 26,imgs   800] loss: 0.7400631  time: 0.958 s\n",
      "[epoch 26,imgs   840] loss: 0.7396066  time: 0.956 s\n",
      "[epoch 26,imgs   880] loss: 0.7404981  time: 0.956 s\n",
      "[epoch 26,imgs   920] loss: 0.7353885  time: 0.956 s\n",
      "[epoch 26,imgs   960] loss: 0.7363307  time: 0.956 s\n",
      "[epoch 26,imgs  1000] loss: 0.7407620  time: 0.956 s\n",
      "[epoch 26,imgs  1040] loss: 0.7390517  time: 0.955 s\n",
      "[epoch 26,imgs  1080] loss: 0.7438700  time: 0.955 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26,imgs  1120] loss: 0.7420881  time: 0.955 s\n",
      "[epoch 26,imgs  1160] loss: 0.7379802  time: 0.956 s\n",
      "[epoch 26,imgs  1200] loss: 0.7388468  time: 0.955 s\n",
      "[epoch 27,imgs    40] loss: 0.7387665  time: 1.350 s\n",
      "[epoch 27,imgs    80] loss: 0.7408392  time: 0.957 s\n",
      "[epoch 27,imgs   120] loss: 0.7400576  time: 0.957 s\n",
      "[epoch 27,imgs   160] loss: 0.7409999  time: 0.957 s\n",
      "[epoch 27,imgs   200] loss: 0.7411951  time: 0.957 s\n",
      "[epoch 27,imgs   240] loss: 0.7403467  time: 0.957 s\n",
      "[epoch 27,imgs   280] loss: 0.7401760  time: 0.957 s\n",
      "[epoch 27,imgs   320] loss: 0.7369797  time: 0.961 s\n",
      "[epoch 27,imgs   360] loss: 0.7363713  time: 0.958 s\n",
      "[epoch 27,imgs   400] loss: 0.7361084  time: 0.956 s\n",
      "[epoch 27,imgs   440] loss: 0.7375872  time: 0.955 s\n",
      "[epoch 27,imgs   480] loss: 0.7432178  time: 0.957 s\n",
      "[epoch 27,imgs   520] loss: 0.7399637  time: 0.957 s\n",
      "[epoch 27,imgs   560] loss: 0.7422707  time: 0.957 s\n",
      "[epoch 27,imgs   600] loss: 0.7418870  time: 0.958 s\n",
      "[epoch 27,imgs   640] loss: 0.7401510  time: 0.957 s\n",
      "[epoch 27,imgs   680] loss: 0.7378470  time: 0.957 s\n",
      "[epoch 27,imgs   720] loss: 0.7396055  time: 0.957 s\n",
      "[epoch 27,imgs   760] loss: 0.7412502  time: 0.958 s\n",
      "[epoch 27,imgs   800] loss: 0.7415088  time: 0.956 s\n",
      "[epoch 27,imgs   840] loss: 0.7420224  time: 0.955 s\n",
      "[epoch 27,imgs   880] loss: 0.7361777  time: 0.955 s\n",
      "[epoch 27,imgs   920] loss: 0.7382260  time: 0.957 s\n",
      "[epoch 27,imgs   960] loss: 0.7409636  time: 0.956 s\n",
      "[epoch 27,imgs  1000] loss: 0.7417853  time: 0.957 s\n",
      "[epoch 27,imgs  1040] loss: 0.7374169  time: 0.957 s\n",
      "[epoch 27,imgs  1080] loss: 0.7381925  time: 0.957 s\n",
      "[epoch 27,imgs  1120] loss: 0.7383541  time: 0.956 s\n",
      "[epoch 27,imgs  1160] loss: 0.7426530  time: 0.957 s\n",
      "[epoch 27,imgs  1200] loss: 0.7430335  time: 0.956 s\n",
      "[epoch 28,imgs    40] loss: 0.7401643  time: 1.334 s\n",
      "[epoch 28,imgs    80] loss: 0.7404951  time: 0.959 s\n",
      "[epoch 28,imgs   120] loss: 0.7422968  time: 0.956 s\n",
      "[epoch 28,imgs   160] loss: 0.7372512  time: 0.956 s\n",
      "[epoch 28,imgs   200] loss: 0.7405029  time: 0.956 s\n",
      "[epoch 28,imgs   240] loss: 0.7357409  time: 0.957 s\n",
      "[epoch 28,imgs   280] loss: 0.7359792  time: 0.957 s\n",
      "[epoch 28,imgs   320] loss: 0.7354328  time: 0.956 s\n",
      "[epoch 28,imgs   360] loss: 0.7397876  time: 0.956 s\n",
      "[epoch 28,imgs   400] loss: 0.7370784  time: 0.956 s\n",
      "[epoch 28,imgs   440] loss: 0.7403303  time: 0.956 s\n",
      "[epoch 28,imgs   480] loss: 0.7410043  time: 0.957 s\n",
      "[epoch 28,imgs   520] loss: 0.7414504  time: 0.957 s\n",
      "[epoch 28,imgs   560] loss: 0.7372895  time: 0.957 s\n",
      "[epoch 28,imgs   600] loss: 0.7342809  time: 0.959 s\n",
      "[epoch 28,imgs   640] loss: 0.7384195  time: 0.958 s\n",
      "[epoch 28,imgs   680] loss: 0.7411519  time: 0.956 s\n",
      "[epoch 28,imgs   720] loss: 0.7378407  time: 0.957 s\n",
      "[epoch 28,imgs   760] loss: 0.7413467  time: 0.956 s\n",
      "[epoch 28,imgs   800] loss: 0.7408623  time: 0.956 s\n",
      "[epoch 28,imgs   840] loss: 0.7404728  time: 0.956 s\n",
      "[epoch 28,imgs   880] loss: 0.7379201  time: 0.957 s\n",
      "[epoch 28,imgs   920] loss: 0.7371475  time: 0.954 s\n",
      "[epoch 28,imgs   960] loss: 0.7414453  time: 0.956 s\n",
      "[epoch 28,imgs  1000] loss: 0.7383265  time: 0.957 s\n",
      "[epoch 28,imgs  1040] loss: 0.7400996  time: 0.958 s\n",
      "[epoch 28,imgs  1080] loss: 0.7374493  time: 0.958 s\n",
      "[epoch 28,imgs  1120] loss: 0.7346838  time: 0.957 s\n",
      "[epoch 28,imgs  1160] loss: 0.7380083  time: 0.957 s\n",
      "[epoch 28,imgs  1200] loss: 0.7368463  time: 0.956 s\n",
      "[epoch 29,imgs    40] loss: 0.7376155  time: 1.340 s\n",
      "[epoch 29,imgs    80] loss: 0.7332131  time: 0.958 s\n",
      "[epoch 29,imgs   120] loss: 0.7377041  time: 0.969 s\n",
      "[epoch 29,imgs   160] loss: 0.7427853  time: 0.967 s\n",
      "[epoch 29,imgs   200] loss: 0.7394443  time: 0.966 s\n",
      "[epoch 29,imgs   240] loss: 0.7356757  time: 0.957 s\n",
      "[epoch 29,imgs   280] loss: 0.7421443  time: 0.972 s\n",
      "[epoch 29,imgs   320] loss: 0.7397290  time: 0.967 s\n",
      "[epoch 29,imgs   360] loss: 0.7413641  time: 0.965 s\n",
      "[epoch 29,imgs   400] loss: 0.7383358  time: 0.965 s\n",
      "[epoch 29,imgs   440] loss: 0.7375538  time: 0.966 s\n",
      "[epoch 29,imgs   480] loss: 0.7407042  time: 0.955 s\n",
      "[epoch 29,imgs   520] loss: 0.7381942  time: 0.955 s\n",
      "[epoch 29,imgs   560] loss: 0.7446281  time: 0.957 s\n",
      "[epoch 29,imgs   600] loss: 0.7360085  time: 0.955 s\n",
      "[epoch 29,imgs   640] loss: 0.7436494  time: 0.956 s\n",
      "[epoch 29,imgs   680] loss: 0.7342998  time: 0.955 s\n",
      "[epoch 29,imgs   720] loss: 0.7360676  time: 0.954 s\n",
      "[epoch 29,imgs   760] loss: 0.7410696  time: 0.976 s\n",
      "[epoch 29,imgs   800] loss: 0.7374340  time: 0.967 s\n",
      "[epoch 29,imgs   840] loss: 0.7366074  time: 0.968 s\n",
      "[epoch 29,imgs   880] loss: 0.7383620  time: 0.967 s\n",
      "[epoch 29,imgs   920] loss: 0.7371397  time: 0.966 s\n",
      "[epoch 29,imgs   960] loss: 0.7395814  time: 0.966 s\n",
      "[epoch 29,imgs  1000] loss: 0.7372884  time: 0.966 s\n",
      "[epoch 29,imgs  1040] loss: 0.7382854  time: 0.967 s\n",
      "[epoch 29,imgs  1080] loss: 0.7383330  time: 0.970 s\n",
      "[epoch 29,imgs  1120] loss: 0.7395627  time: 0.966 s\n",
      "[epoch 29,imgs  1160] loss: 0.7400591  time: 0.966 s\n",
      "[epoch 29,imgs  1200] loss: 0.7358881  time: 0.958 s\n",
      "[epoch 30,imgs    40] loss: 0.7438613  time: 1.362 s\n",
      "[epoch 30,imgs    80] loss: 0.7335788  time: 0.958 s\n",
      "[epoch 30,imgs   120] loss: 0.7398456  time: 0.957 s\n",
      "[epoch 30,imgs   160] loss: 0.7344202  time: 0.961 s\n",
      "[epoch 30,imgs   200] loss: 0.7371445  time: 0.957 s\n",
      "[epoch 30,imgs   240] loss: 0.7346539  time: 0.956 s\n",
      "[epoch 30,imgs   280] loss: 0.7383130  time: 0.957 s\n",
      "[epoch 30,imgs   320] loss: 0.7367630  time: 0.955 s\n",
      "[epoch 30,imgs   360] loss: 0.7404169  time: 0.955 s\n",
      "[epoch 30,imgs   400] loss: 0.7382172  time: 0.957 s\n",
      "[epoch 30,imgs   440] loss: 0.7390588  time: 0.956 s\n",
      "[epoch 30,imgs   480] loss: 0.7371069  time: 0.956 s\n",
      "[epoch 30,imgs   520] loss: 0.7368634  time: 0.955 s\n",
      "[epoch 30,imgs   560] loss: 0.7433606  time: 0.956 s\n",
      "[epoch 30,imgs   600] loss: 0.7375826  time: 0.955 s\n",
      "[epoch 30,imgs   640] loss: 0.7386413  time: 0.955 s\n",
      "[epoch 30,imgs   680] loss: 0.7382423  time: 0.956 s\n",
      "[epoch 30,imgs   720] loss: 0.7404848  time: 0.958 s\n",
      "[epoch 30,imgs   760] loss: 0.7386980  time: 0.955 s\n",
      "[epoch 30,imgs   800] loss: 0.7415250  time: 0.958 s\n",
      "[epoch 30,imgs   840] loss: 0.7426497  time: 0.955 s\n",
      "[epoch 30,imgs   880] loss: 0.7369225  time: 0.955 s\n",
      "[epoch 30,imgs   920] loss: 0.7382369  time: 0.956 s\n",
      "[epoch 30,imgs   960] loss: 0.7399067  time: 0.956 s\n",
      "[epoch 30,imgs  1000] loss: 0.7377799  time: 0.956 s\n",
      "[epoch 30,imgs  1040] loss: 0.7427022  time: 0.956 s\n",
      "[epoch 30,imgs  1080] loss: 0.7421124  time: 0.956 s\n",
      "[epoch 30,imgs  1120] loss: 0.7413369  time: 0.957 s\n",
      "[epoch 30,imgs  1160] loss: 0.7415326  time: 0.956 s\n",
      "[epoch 30,imgs  1200] loss: 0.7372908  time: 0.958 s\n",
      "[epoch 31,imgs    40] loss: 0.7355958  time: 1.339 s\n",
      "[epoch 31,imgs    80] loss: 0.7373533  time: 0.958 s\n",
      "[epoch 31,imgs   120] loss: 0.7362065  time: 0.955 s\n",
      "[epoch 31,imgs   160] loss: 0.7430661  time: 0.954 s\n",
      "[epoch 31,imgs   200] loss: 0.7391427  time: 0.964 s\n",
      "[epoch 31,imgs   240] loss: 0.7406173  time: 0.958 s\n",
      "[epoch 31,imgs   280] loss: 0.7393810  time: 0.956 s\n",
      "[epoch 31,imgs   320] loss: 0.7413609  time: 0.966 s\n",
      "[epoch 31,imgs   360] loss: 0.7389753  time: 0.967 s\n",
      "[epoch 31,imgs   400] loss: 0.7407355  time: 0.966 s\n",
      "[epoch 31,imgs   440] loss: 0.7355577  time: 0.967 s\n",
      "[epoch 31,imgs   480] loss: 0.7430437  time: 0.959 s\n",
      "[epoch 31,imgs   520] loss: 0.7356906  time: 0.962 s\n",
      "[epoch 31,imgs   560] loss: 0.7393546  time: 0.957 s\n",
      "[epoch 31,imgs   600] loss: 0.7362142  time: 0.974 s\n",
      "[epoch 31,imgs   640] loss: 0.7410862  time: 0.976 s\n",
      "[epoch 31,imgs   680] loss: 0.7345971  time: 0.975 s\n",
      "[epoch 31,imgs   720] loss: 0.7385705  time: 0.963 s\n",
      "[epoch 31,imgs   760] loss: 0.7420446  time: 0.962 s\n",
      "[epoch 31,imgs   800] loss: 0.7392330  time: 0.962 s\n",
      "[epoch 31,imgs   840] loss: 0.7404224  time: 0.962 s\n",
      "[epoch 31,imgs   880] loss: 0.7389017  time: 0.961 s\n",
      "[epoch 31,imgs   920] loss: 0.7367213  time: 0.965 s\n",
      "[epoch 31,imgs   960] loss: 0.7395310  time: 0.962 s\n",
      "[epoch 31,imgs  1000] loss: 0.7389080  time: 0.964 s\n",
      "[epoch 31,imgs  1040] loss: 0.7407514  time: 0.965 s\n",
      "[epoch 31,imgs  1080] loss: 0.7359859  time: 0.963 s\n",
      "[epoch 31,imgs  1120] loss: 0.7412241  time: 0.960 s\n",
      "[epoch 31,imgs  1160] loss: 0.7358587  time: 0.962 s\n",
      "[epoch 31,imgs  1200] loss: 0.7376762  time: 0.961 s\n",
      "[epoch 32,imgs    40] loss: 0.7406987  time: 1.347 s\n",
      "[epoch 32,imgs    80] loss: 0.7420475  time: 0.962 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32,imgs   120] loss: 0.7390469  time: 0.963 s\n",
      "[epoch 32,imgs   160] loss: 0.7396974  time: 0.964 s\n",
      "[epoch 32,imgs   200] loss: 0.7342786  time: 0.963 s\n",
      "[epoch 32,imgs   240] loss: 0.7405462  time: 0.959 s\n",
      "[epoch 32,imgs   280] loss: 0.7365317  time: 0.957 s\n",
      "[epoch 32,imgs   320] loss: 0.7403030  time: 0.956 s\n",
      "[epoch 32,imgs   360] loss: 0.7402851  time: 0.955 s\n",
      "[epoch 32,imgs   400] loss: 0.7384974  time: 0.955 s\n",
      "[epoch 32,imgs   440] loss: 0.7422297  time: 0.955 s\n",
      "[epoch 32,imgs   480] loss: 0.7405952  time: 0.957 s\n",
      "[epoch 32,imgs   520] loss: 0.7393884  time: 0.955 s\n",
      "[epoch 32,imgs   560] loss: 0.7371914  time: 0.954 s\n",
      "[epoch 32,imgs   600] loss: 0.7386957  time: 0.966 s\n",
      "[epoch 32,imgs   640] loss: 0.7393897  time: 0.967 s\n",
      "[epoch 32,imgs   680] loss: 0.7438903  time: 0.967 s\n",
      "[epoch 32,imgs   720] loss: 0.7407685  time: 0.969 s\n",
      "[epoch 32,imgs   760] loss: 0.7428078  time: 0.967 s\n",
      "[epoch 32,imgs   800] loss: 0.7414647  time: 0.969 s\n",
      "[epoch 32,imgs   840] loss: 0.7393061  time: 0.966 s\n",
      "[epoch 32,imgs   880] loss: 0.7407887  time: 0.968 s\n",
      "[epoch 32,imgs   920] loss: 0.7414309  time: 0.966 s\n",
      "[epoch 32,imgs   960] loss: 0.7383503  time: 0.972 s\n",
      "[epoch 32,imgs  1000] loss: 0.7383665  time: 0.967 s\n",
      "[epoch 32,imgs  1040] loss: 0.7376254  time: 0.968 s\n",
      "[epoch 32,imgs  1080] loss: 0.7326220  time: 0.967 s\n",
      "[epoch 32,imgs  1120] loss: 0.7360691  time: 0.967 s\n",
      "[epoch 32,imgs  1160] loss: 0.7315860  time: 0.976 s\n",
      "[epoch 32,imgs  1200] loss: 0.7371885  time: 0.972 s\n",
      "[epoch 33,imgs    40] loss: 0.7397409  time: 1.354 s\n",
      "[epoch 33,imgs    80] loss: 0.7402934  time: 0.959 s\n",
      "[epoch 33,imgs   120] loss: 0.7425009  time: 0.961 s\n",
      "[epoch 33,imgs   160] loss: 0.7393976  time: 0.968 s\n",
      "[epoch 33,imgs   200] loss: 0.7383012  time: 0.957 s\n",
      "[epoch 33,imgs   240] loss: 0.7395778  time: 0.956 s\n",
      "[epoch 33,imgs   280] loss: 0.7406395  time: 0.965 s\n",
      "[epoch 33,imgs   320] loss: 0.7422996  time: 0.968 s\n",
      "[epoch 33,imgs   360] loss: 0.7352253  time: 0.959 s\n",
      "[epoch 33,imgs   400] loss: 0.7396211  time: 0.958 s\n",
      "[epoch 33,imgs   440] loss: 0.7381155  time: 0.961 s\n",
      "[epoch 33,imgs   480] loss: 0.7378443  time: 0.958 s\n",
      "[epoch 33,imgs   520] loss: 0.7383220  time: 0.959 s\n",
      "[epoch 33,imgs   560] loss: 0.7449793  time: 0.959 s\n",
      "[epoch 33,imgs   600] loss: 0.7378285  time: 0.963 s\n",
      "[epoch 33,imgs   640] loss: 0.7411318  time: 0.964 s\n",
      "[epoch 33,imgs   680] loss: 0.7434196  time: 0.961 s\n",
      "[epoch 33,imgs   720] loss: 0.7384784  time: 0.956 s\n",
      "[epoch 33,imgs   760] loss: 0.7428875  time: 0.957 s\n",
      "[epoch 33,imgs   800] loss: 0.7405480  time: 0.954 s\n",
      "[epoch 33,imgs   840] loss: 0.7414288  time: 0.957 s\n",
      "[epoch 33,imgs   880] loss: 0.7361217  time: 0.958 s\n",
      "[epoch 33,imgs   920] loss: 0.7393317  time: 0.962 s\n",
      "[epoch 33,imgs   960] loss: 0.7391633  time: 0.955 s\n",
      "[epoch 33,imgs  1000] loss: 0.7370486  time: 0.968 s\n",
      "[epoch 33,imgs  1040] loss: 0.7409706  time: 0.969 s\n",
      "[epoch 33,imgs  1080] loss: 0.7396244  time: 0.969 s\n",
      "[epoch 33,imgs  1120] loss: 0.7375979  time: 0.967 s\n",
      "[epoch 33,imgs  1160] loss: 0.7368265  time: 0.973 s\n",
      "[epoch 33,imgs  1200] loss: 0.7362524  time: 0.965 s\n",
      "[epoch 34,imgs    40] loss: 0.7355626  time: 1.312 s\n",
      "[epoch 34,imgs    80] loss: 0.7389959  time: 0.958 s\n",
      "[epoch 34,imgs   120] loss: 0.7417314  time: 0.957 s\n",
      "[epoch 34,imgs   160] loss: 0.7422481  time: 0.956 s\n",
      "[epoch 34,imgs   200] loss: 0.7350653  time: 0.958 s\n",
      "[epoch 34,imgs   240] loss: 0.7433709  time: 0.957 s\n",
      "[epoch 34,imgs   280] loss: 0.7393996  time: 0.956 s\n",
      "[epoch 34,imgs   320] loss: 0.7361056  time: 0.955 s\n",
      "[epoch 34,imgs   360] loss: 0.7401910  time: 0.957 s\n",
      "[epoch 34,imgs   400] loss: 0.7407906  time: 0.956 s\n",
      "[epoch 34,imgs   440] loss: 0.7411838  time: 0.957 s\n",
      "[epoch 34,imgs   480] loss: 0.7390102  time: 0.961 s\n",
      "[epoch 34,imgs   520] loss: 0.7348141  time: 0.955 s\n",
      "[epoch 34,imgs   560] loss: 0.7390688  time: 0.957 s\n",
      "[epoch 34,imgs   600] loss: 0.7420228  time: 0.956 s\n",
      "[epoch 34,imgs   640] loss: 0.7406015  time: 0.957 s\n",
      "[epoch 34,imgs   680] loss: 0.7368161  time: 0.956 s\n",
      "[epoch 34,imgs   720] loss: 0.7432466  time: 0.957 s\n",
      "[epoch 34,imgs   760] loss: 0.7370157  time: 0.957 s\n",
      "[epoch 34,imgs   800] loss: 0.7390306  time: 0.957 s\n",
      "[epoch 34,imgs   840] loss: 0.7389445  time: 0.956 s\n",
      "[epoch 34,imgs   880] loss: 0.7361573  time: 0.955 s\n",
      "[epoch 34,imgs   920] loss: 0.7423720  time: 0.955 s\n",
      "[epoch 34,imgs   960] loss: 0.7378802  time: 0.956 s\n",
      "[epoch 34,imgs  1000] loss: 0.7409372  time: 0.957 s\n",
      "[epoch 34,imgs  1040] loss: 0.7371039  time: 0.956 s\n",
      "[epoch 34,imgs  1080] loss: 0.7387646  time: 0.960 s\n",
      "[epoch 34,imgs  1120] loss: 0.7433722  time: 0.959 s\n",
      "[epoch 34,imgs  1160] loss: 0.7344186  time: 0.956 s\n",
      "[epoch 34,imgs  1200] loss: 0.7341828  time: 0.956 s\n",
      "[epoch 35,imgs    40] loss: 0.7428900  time: 1.349 s\n",
      "[epoch 35,imgs    80] loss: 0.7421092  time: 0.959 s\n",
      "[epoch 35,imgs   120] loss: 0.7425560  time: 0.957 s\n",
      "[epoch 35,imgs   160] loss: 0.7358940  time: 0.959 s\n",
      "[epoch 35,imgs   200] loss: 0.7347612  time: 0.959 s\n",
      "[epoch 35,imgs   240] loss: 0.7383100  time: 0.957 s\n",
      "[epoch 35,imgs   280] loss: 0.7380222  time: 0.955 s\n",
      "[epoch 35,imgs   320] loss: 0.7416200  time: 0.956 s\n",
      "[epoch 35,imgs   360] loss: 0.7397199  time: 0.957 s\n",
      "[epoch 35,imgs   400] loss: 0.7402083  time: 0.956 s\n",
      "[epoch 35,imgs   440] loss: 0.7452325  time: 0.959 s\n",
      "[epoch 35,imgs   480] loss: 0.7336858  time: 0.957 s\n",
      "[epoch 35,imgs   520] loss: 0.7423436  time: 0.957 s\n",
      "[epoch 35,imgs   560] loss: 0.7375777  time: 0.957 s\n",
      "[epoch 35,imgs   600] loss: 0.7421287  time: 0.957 s\n",
      "[epoch 35,imgs   640] loss: 0.7397079  time: 0.958 s\n",
      "[epoch 35,imgs   680] loss: 0.7391724  time: 0.958 s\n",
      "[epoch 35,imgs   720] loss: 0.7371752  time: 0.957 s\n",
      "[epoch 35,imgs   760] loss: 0.7370433  time: 0.957 s\n",
      "[epoch 35,imgs   800] loss: 0.7342404  time: 0.957 s\n",
      "[epoch 35,imgs   840] loss: 0.7406588  time: 0.959 s\n",
      "[epoch 35,imgs   880] loss: 0.7402689  time: 0.960 s\n",
      "[epoch 35,imgs   920] loss: 0.7399226  time: 0.957 s\n",
      "[epoch 35,imgs   960] loss: 0.7377167  time: 0.957 s\n",
      "[epoch 35,imgs  1000] loss: 0.7369511  time: 0.956 s\n",
      "[epoch 35,imgs  1040] loss: 0.7380309  time: 0.956 s\n",
      "[epoch 35,imgs  1080] loss: 0.7385742  time: 0.955 s\n",
      "[epoch 35,imgs  1120] loss: 0.7379916  time: 0.957 s\n",
      "[epoch 35,imgs  1160] loss: 0.7370121  time: 0.957 s\n",
      "[epoch 35,imgs  1200] loss: 0.7420855  time: 0.954 s\n",
      "[epoch 36,imgs    40] loss: 0.7391919  time: 1.354 s\n",
      "[epoch 36,imgs    80] loss: 0.7342145  time: 0.958 s\n",
      "[epoch 36,imgs   120] loss: 0.7392504  time: 0.957 s\n",
      "[epoch 36,imgs   160] loss: 0.7451570  time: 0.958 s\n",
      "[epoch 36,imgs   200] loss: 0.7385667  time: 0.956 s\n",
      "[epoch 36,imgs   240] loss: 0.7394993  time: 0.957 s\n",
      "[epoch 36,imgs   280] loss: 0.7397850  time: 0.961 s\n",
      "[epoch 36,imgs   320] loss: 0.7343581  time: 0.957 s\n",
      "[epoch 36,imgs   360] loss: 0.7361642  time: 0.956 s\n",
      "[epoch 36,imgs   400] loss: 0.7368249  time: 0.957 s\n",
      "[epoch 36,imgs   440] loss: 0.7405027  time: 0.956 s\n",
      "[epoch 36,imgs   480] loss: 0.7396600  time: 0.958 s\n",
      "[epoch 36,imgs   520] loss: 0.7406927  time: 0.957 s\n",
      "[epoch 36,imgs   560] loss: 0.7403995  time: 0.958 s\n",
      "[epoch 36,imgs   600] loss: 0.7403276  time: 0.956 s\n",
      "[epoch 36,imgs   640] loss: 0.7398124  time: 0.957 s\n",
      "[epoch 36,imgs   680] loss: 0.7381870  time: 0.958 s\n",
      "[epoch 36,imgs   720] loss: 0.7422346  time: 0.958 s\n",
      "[epoch 36,imgs   760] loss: 0.7395421  time: 0.957 s\n",
      "[epoch 36,imgs   800] loss: 0.7445593  time: 0.957 s\n",
      "[epoch 36,imgs   840] loss: 0.7335671  time: 0.958 s\n",
      "[epoch 36,imgs   880] loss: 0.7363176  time: 0.960 s\n",
      "[epoch 36,imgs   920] loss: 0.7367503  time: 0.957 s\n",
      "[epoch 36,imgs   960] loss: 0.7366720  time: 0.959 s\n",
      "[epoch 36,imgs  1000] loss: 0.7412416  time: 0.957 s\n",
      "[epoch 36,imgs  1040] loss: 0.7410684  time: 0.957 s\n",
      "[epoch 36,imgs  1080] loss: 0.7366500  time: 0.961 s\n",
      "[epoch 36,imgs  1120] loss: 0.7396649  time: 0.957 s\n",
      "[epoch 36,imgs  1160] loss: 0.7406992  time: 0.958 s\n",
      "[epoch 36,imgs  1200] loss: 0.7379727  time: 0.957 s\n",
      "[epoch 37,imgs    40] loss: 0.7404330  time: 1.354 s\n",
      "[epoch 37,imgs    80] loss: 0.7373903  time: 0.968 s\n",
      "[epoch 37,imgs   120] loss: 0.7390028  time: 0.968 s\n",
      "[epoch 37,imgs   160] loss: 0.7399894  time: 0.968 s\n",
      "[epoch 37,imgs   200] loss: 0.7441949  time: 0.956 s\n",
      "[epoch 37,imgs   240] loss: 0.7386667  time: 0.956 s\n",
      "[epoch 37,imgs   280] loss: 0.7370904  time: 0.958 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37,imgs   320] loss: 0.7400664  time: 0.956 s\n",
      "[epoch 37,imgs   360] loss: 0.7389529  time: 0.955 s\n",
      "[epoch 37,imgs   400] loss: 0.7389228  time: 0.957 s\n",
      "[epoch 37,imgs   440] loss: 0.7395627  time: 0.957 s\n",
      "[epoch 37,imgs   480] loss: 0.7403718  time: 0.960 s\n",
      "[epoch 37,imgs   520] loss: 0.7433820  time: 0.957 s\n",
      "[epoch 37,imgs   560] loss: 0.7398202  time: 0.957 s\n",
      "[epoch 37,imgs   600] loss: 0.7371663  time: 0.957 s\n",
      "[epoch 37,imgs   640] loss: 0.7413022  time: 0.956 s\n",
      "[epoch 37,imgs   680] loss: 0.7361115  time: 0.957 s\n",
      "[epoch 37,imgs   720] loss: 0.7368009  time: 0.961 s\n",
      "[epoch 37,imgs   760] loss: 0.7376317  time: 0.957 s\n",
      "[epoch 37,imgs   800] loss: 0.7376165  time: 0.958 s\n",
      "[epoch 37,imgs   840] loss: 0.7425718  time: 0.957 s\n",
      "[epoch 37,imgs   880] loss: 0.7367364  time: 0.957 s\n",
      "[epoch 37,imgs   920] loss: 0.7398816  time: 0.956 s\n",
      "[epoch 37,imgs   960] loss: 0.7407656  time: 0.959 s\n",
      "[epoch 37,imgs  1000] loss: 0.7377582  time: 0.959 s\n",
      "[epoch 37,imgs  1040] loss: 0.7410080  time: 0.960 s\n",
      "[epoch 37,imgs  1080] loss: 0.7375420  time: 0.958 s\n",
      "[epoch 37,imgs  1120] loss: 0.7377049  time: 0.958 s\n",
      "[epoch 37,imgs  1160] loss: 0.7351756  time: 0.958 s\n",
      "[epoch 37,imgs  1200] loss: 0.7372017  time: 0.957 s\n",
      "[epoch 38,imgs    40] loss: 0.7404426  time: 1.320 s\n",
      "[epoch 38,imgs    80] loss: 0.7397589  time: 0.955 s\n",
      "[epoch 38,imgs   120] loss: 0.7391290  time: 0.970 s\n",
      "[epoch 38,imgs   160] loss: 0.7367871  time: 0.960 s\n",
      "[epoch 38,imgs   200] loss: 0.7388129  time: 0.955 s\n",
      "[epoch 38,imgs   240] loss: 0.7418295  time: 0.958 s\n",
      "[epoch 38,imgs   280] loss: 0.7361193  time: 0.954 s\n",
      "[epoch 38,imgs   320] loss: 0.7408140  time: 0.954 s\n",
      "[epoch 38,imgs   360] loss: 0.7402276  time: 0.956 s\n",
      "[epoch 38,imgs   400] loss: 0.7390628  time: 0.959 s\n",
      "[epoch 38,imgs   440] loss: 0.7351811  time: 0.956 s\n",
      "[epoch 38,imgs   480] loss: 0.7434717  time: 0.954 s\n",
      "[epoch 38,imgs   520] loss: 0.7393841  time: 0.954 s\n",
      "[epoch 38,imgs   560] loss: 0.7365957  time: 0.955 s\n",
      "[epoch 38,imgs   600] loss: 0.7406728  time: 0.966 s\n",
      "[epoch 38,imgs   640] loss: 0.7381317  time: 0.967 s\n",
      "[epoch 38,imgs   680] loss: 0.7399336  time: 0.965 s\n",
      "[epoch 38,imgs   720] loss: 0.7431919  time: 0.969 s\n",
      "[epoch 38,imgs   760] loss: 0.7363927  time: 0.966 s\n",
      "[epoch 38,imgs   800] loss: 0.7395639  time: 0.955 s\n",
      "[epoch 38,imgs   840] loss: 0.7416511  time: 0.951 s\n",
      "[epoch 38,imgs   880] loss: 0.7357774  time: 0.953 s\n",
      "[epoch 38,imgs   920] loss: 0.7346836  time: 0.967 s\n",
      "[epoch 38,imgs   960] loss: 0.7308481  time: 0.966 s\n",
      "[epoch 38,imgs  1000] loss: 0.7445474  time: 0.955 s\n",
      "[epoch 38,imgs  1040] loss: 0.7347925  time: 0.959 s\n",
      "[epoch 38,imgs  1080] loss: 0.7385135  time: 0.956 s\n",
      "[epoch 38,imgs  1120] loss: 0.7411034  time: 0.956 s\n",
      "[epoch 38,imgs  1160] loss: 0.7348966  time: 0.957 s\n",
      "[epoch 38,imgs  1200] loss: 0.7378322  time: 0.952 s\n",
      "[epoch 39,imgs    40] loss: 0.7385374  time: 1.385 s\n",
      "[epoch 39,imgs    80] loss: 0.7356536  time: 0.969 s\n",
      "[epoch 39,imgs   120] loss: 0.7354350  time: 0.968 s\n",
      "[epoch 39,imgs   160] loss: 0.7398342  time: 0.966 s\n",
      "[epoch 39,imgs   200] loss: 0.7432515  time: 0.967 s\n",
      "[epoch 39,imgs   240] loss: 0.7406425  time: 0.968 s\n",
      "[epoch 39,imgs   280] loss: 0.7405493  time: 0.966 s\n",
      "[epoch 39,imgs   320] loss: 0.7396973  time: 0.967 s\n",
      "[epoch 39,imgs   360] loss: 0.7401302  time: 0.966 s\n",
      "[epoch 39,imgs   400] loss: 0.7386400  time: 0.966 s\n",
      "[epoch 39,imgs   440] loss: 0.7389718  time: 0.973 s\n",
      "[epoch 39,imgs   480] loss: 0.7391898  time: 0.966 s\n",
      "[epoch 39,imgs   520] loss: 0.7378960  time: 0.967 s\n",
      "[epoch 39,imgs   560] loss: 0.7411274  time: 0.966 s\n",
      "[epoch 39,imgs   600] loss: 0.7365289  time: 0.967 s\n",
      "[epoch 39,imgs   640] loss: 0.7337433  time: 0.967 s\n",
      "[epoch 39,imgs   680] loss: 0.7383144  time: 0.966 s\n",
      "[epoch 39,imgs   720] loss: 0.7430359  time: 0.966 s\n",
      "[epoch 39,imgs   760] loss: 0.7386770  time: 0.966 s\n",
      "[epoch 39,imgs   800] loss: 0.7385481  time: 0.964 s\n",
      "[epoch 39,imgs   840] loss: 0.7373137  time: 0.966 s\n",
      "[epoch 39,imgs   880] loss: 0.7380413  time: 0.965 s\n",
      "[epoch 39,imgs   920] loss: 0.7379982  time: 0.969 s\n",
      "[epoch 39,imgs   960] loss: 0.7378875  time: 0.968 s\n",
      "[epoch 39,imgs  1000] loss: 0.7339715  time: 0.968 s\n",
      "[epoch 39,imgs  1040] loss: 0.7381462  time: 0.965 s\n",
      "[epoch 39,imgs  1080] loss: 0.7434173  time: 0.966 s\n",
      "[epoch 39,imgs  1120] loss: 0.7402235  time: 0.965 s\n",
      "[epoch 39,imgs  1160] loss: 0.7396799  time: 0.966 s\n",
      "[epoch 39,imgs  1200] loss: 0.7391701  time: 0.965 s\n",
      "[epoch 40,imgs    40] loss: 0.7356622  time: 1.360 s\n",
      "[epoch 40,imgs    80] loss: 0.7360178  time: 0.968 s\n",
      "[epoch 40,imgs   120] loss: 0.7371347  time: 0.968 s\n",
      "[epoch 40,imgs   160] loss: 0.7382530  time: 0.970 s\n",
      "[epoch 40,imgs   200] loss: 0.7402117  time: 0.967 s\n",
      "[epoch 40,imgs   240] loss: 0.7406914  time: 0.969 s\n",
      "[epoch 40,imgs   280] loss: 0.7390274  time: 0.966 s\n",
      "[epoch 40,imgs   320] loss: 0.7384134  time: 0.966 s\n",
      "[epoch 40,imgs   360] loss: 0.7399290  time: 0.968 s\n",
      "[epoch 40,imgs   400] loss: 0.7404739  time: 0.967 s\n",
      "[epoch 40,imgs   440] loss: 0.7404332  time: 0.967 s\n",
      "[epoch 40,imgs   480] loss: 0.7406440  time: 0.966 s\n",
      "[epoch 40,imgs   520] loss: 0.7348677  time: 0.968 s\n",
      "[epoch 40,imgs   560] loss: 0.7365962  time: 0.968 s\n",
      "[epoch 40,imgs   600] loss: 0.7402960  time: 0.967 s\n",
      "[epoch 40,imgs   640] loss: 0.7387177  time: 0.973 s\n",
      "[epoch 40,imgs   680] loss: 0.7359557  time: 0.967 s\n",
      "[epoch 40,imgs   720] loss: 0.7348543  time: 0.971 s\n",
      "[epoch 40,imgs   760] loss: 0.7346631  time: 0.970 s\n",
      "[epoch 40,imgs   800] loss: 0.7421615  time: 0.968 s\n",
      "[epoch 40,imgs   840] loss: 0.7384339  time: 0.969 s\n",
      "[epoch 40,imgs   880] loss: 0.7395981  time: 0.969 s\n",
      "[epoch 40,imgs   920] loss: 0.7372747  time: 0.970 s\n",
      "[epoch 40,imgs   960] loss: 0.7436013  time: 0.968 s\n",
      "[epoch 40,imgs  1000] loss: 0.7403588  time: 0.968 s\n",
      "[epoch 40,imgs  1040] loss: 0.7398375  time: 0.968 s\n",
      "[epoch 40,imgs  1080] loss: 0.7405759  time: 0.969 s\n",
      "[epoch 40,imgs  1120] loss: 0.7410299  time: 0.970 s\n",
      "[epoch 40,imgs  1160] loss: 0.7387016  time: 0.967 s\n",
      "[epoch 40,imgs  1200] loss: 0.7382461  time: 0.968 s\n",
      "[epoch 41,imgs    40] loss: 0.7456291  time: 1.355 s\n",
      "[epoch 41,imgs    80] loss: 0.7428926  time: 0.957 s\n",
      "[epoch 41,imgs   120] loss: 0.7367013  time: 0.955 s\n",
      "[epoch 41,imgs   160] loss: 0.7409003  time: 0.955 s\n",
      "[epoch 41,imgs   200] loss: 0.7354733  time: 0.955 s\n",
      "[epoch 41,imgs   240] loss: 0.7444914  time: 0.954 s\n",
      "[epoch 41,imgs   280] loss: 0.7376859  time: 0.953 s\n",
      "[epoch 41,imgs   320] loss: 0.7421502  time: 0.956 s\n",
      "[epoch 41,imgs   360] loss: 0.7388756  time: 0.959 s\n",
      "[epoch 41,imgs   400] loss: 0.7357113  time: 0.959 s\n",
      "[epoch 41,imgs   440] loss: 0.7396306  time: 0.959 s\n",
      "[epoch 41,imgs   480] loss: 0.7402670  time: 0.957 s\n",
      "[epoch 41,imgs   520] loss: 0.7363065  time: 0.956 s\n",
      "[epoch 41,imgs   560] loss: 0.7355143  time: 0.955 s\n",
      "[epoch 41,imgs   600] loss: 0.7390124  time: 0.954 s\n",
      "[epoch 41,imgs   640] loss: 0.7388183  time: 0.955 s\n",
      "[epoch 41,imgs   680] loss: 0.7386824  time: 0.962 s\n",
      "[epoch 41,imgs   720] loss: 0.7417889  time: 0.956 s\n",
      "[epoch 41,imgs   760] loss: 0.7386349  time: 0.955 s\n",
      "[epoch 41,imgs   800] loss: 0.7384856  time: 0.955 s\n",
      "[epoch 41,imgs   840] loss: 0.7445622  time: 0.954 s\n",
      "[epoch 41,imgs   880] loss: 0.7340885  time: 0.957 s\n",
      "[epoch 41,imgs   920] loss: 0.7353275  time: 0.955 s\n",
      "[epoch 41,imgs   960] loss: 0.7383246  time: 0.957 s\n",
      "[epoch 41,imgs  1000] loss: 0.7401651  time: 0.955 s\n",
      "[epoch 41,imgs  1040] loss: 0.7396596  time: 0.954 s\n",
      "[epoch 41,imgs  1080] loss: 0.7374364  time: 0.954 s\n",
      "[epoch 41,imgs  1120] loss: 0.7415101  time: 0.958 s\n",
      "[epoch 41,imgs  1160] loss: 0.7412022  time: 0.955 s\n",
      "[epoch 41,imgs  1200] loss: 0.7416478  time: 0.955 s\n",
      "[epoch 42,imgs    40] loss: 0.7390878  time: 1.377 s\n",
      "[epoch 42,imgs    80] loss: 0.7349088  time: 0.954 s\n",
      "[epoch 42,imgs   120] loss: 0.7387859  time: 0.954 s\n",
      "[epoch 42,imgs   160] loss: 0.7376803  time: 0.954 s\n",
      "[epoch 42,imgs   200] loss: 0.7398486  time: 0.955 s\n",
      "[epoch 42,imgs   240] loss: 0.7371348  time: 0.956 s\n",
      "[epoch 42,imgs   280] loss: 0.7400634  time: 0.954 s\n",
      "[epoch 42,imgs   320] loss: 0.7369689  time: 0.959 s\n",
      "[epoch 42,imgs   360] loss: 0.7378440  time: 0.956 s\n",
      "[epoch 42,imgs   400] loss: 0.7431718  time: 0.958 s\n",
      "[epoch 42,imgs   440] loss: 0.7418188  time: 0.955 s\n",
      "[epoch 42,imgs   480] loss: 0.7386822  time: 0.957 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 42,imgs   520] loss: 0.7374334  time: 0.955 s\n",
      "[epoch 42,imgs   560] loss: 0.7391650  time: 0.956 s\n",
      "[epoch 42,imgs   600] loss: 0.7355472  time: 0.955 s\n",
      "[epoch 42,imgs   640] loss: 0.7428397  time: 0.956 s\n",
      "[epoch 42,imgs   680] loss: 0.7394159  time: 0.956 s\n",
      "[epoch 42,imgs   720] loss: 0.7386909  time: 0.956 s\n",
      "[epoch 42,imgs   760] loss: 0.7410465  time: 0.956 s\n",
      "[epoch 42,imgs   800] loss: 0.7401605  time: 0.956 s\n",
      "[epoch 42,imgs   840] loss: 0.7386052  time: 0.955 s\n",
      "[epoch 42,imgs   880] loss: 0.7397508  time: 0.957 s\n",
      "[epoch 42,imgs   920] loss: 0.7409611  time: 0.957 s\n",
      "[epoch 42,imgs   960] loss: 0.7398036  time: 0.957 s\n",
      "[epoch 42,imgs  1000] loss: 0.7433316  time: 0.955 s\n",
      "[epoch 42,imgs  1040] loss: 0.7402530  time: 0.956 s\n",
      "[epoch 42,imgs  1080] loss: 0.7372399  time: 0.956 s\n",
      "[epoch 42,imgs  1120] loss: 0.7410086  time: 0.956 s\n",
      "[epoch 42,imgs  1160] loss: 0.7353939  time: 0.956 s\n",
      "[epoch 42,imgs  1200] loss: 0.7374893  time: 0.956 s\n",
      "[epoch 43,imgs    40] loss: 0.7387017  time: 1.342 s\n",
      "[epoch 43,imgs    80] loss: 0.7373282  time: 0.957 s\n",
      "[epoch 43,imgs   120] loss: 0.7396326  time: 0.954 s\n",
      "[epoch 43,imgs   160] loss: 0.7355958  time: 0.955 s\n",
      "[epoch 43,imgs   200] loss: 0.7365554  time: 0.954 s\n",
      "[epoch 43,imgs   240] loss: 0.7352935  time: 0.953 s\n",
      "[epoch 43,imgs   280] loss: 0.7344375  time: 0.955 s\n",
      "[epoch 43,imgs   320] loss: 0.7382144  time: 0.955 s\n",
      "[epoch 43,imgs   360] loss: 0.7410534  time: 0.959 s\n",
      "[epoch 43,imgs   400] loss: 0.7401625  time: 0.954 s\n",
      "[epoch 43,imgs   440] loss: 0.7377194  time: 0.956 s\n",
      "[epoch 43,imgs   480] loss: 0.7376143  time: 0.953 s\n",
      "[epoch 43,imgs   520] loss: 0.7380756  time: 0.954 s\n",
      "[epoch 43,imgs   560] loss: 0.7418718  time: 0.954 s\n",
      "[epoch 43,imgs   600] loss: 0.7396489  time: 0.955 s\n",
      "[epoch 43,imgs   640] loss: 0.7404118  time: 0.959 s\n",
      "[epoch 43,imgs   680] loss: 0.7386751  time: 0.954 s\n",
      "[epoch 43,imgs   720] loss: 0.7362977  time: 0.959 s\n",
      "[epoch 43,imgs   760] loss: 0.7373537  time: 0.956 s\n",
      "[epoch 43,imgs   800] loss: 0.7415869  time: 0.957 s\n",
      "[epoch 43,imgs   840] loss: 0.7387481  time: 0.957 s\n",
      "[epoch 43,imgs   880] loss: 0.7393393  time: 0.956 s\n",
      "[epoch 43,imgs   920] loss: 0.7355042  time: 0.955 s\n",
      "[epoch 43,imgs   960] loss: 0.7386107  time: 0.954 s\n",
      "[epoch 43,imgs  1000] loss: 0.7406170  time: 0.954 s\n",
      "[epoch 43,imgs  1040] loss: 0.7369350  time: 0.958 s\n",
      "[epoch 43,imgs  1080] loss: 0.7433335  time: 0.956 s\n",
      "[epoch 43,imgs  1120] loss: 0.7417501  time: 0.954 s\n",
      "[epoch 43,imgs  1160] loss: 0.7375943  time: 0.956 s\n",
      "[epoch 43,imgs  1200] loss: 0.7371882  time: 0.958 s\n",
      "[epoch 44,imgs    40] loss: 0.7407200  time: 1.335 s\n",
      "[epoch 44,imgs    80] loss: 0.7400243  time: 0.958 s\n",
      "[epoch 44,imgs   120] loss: 0.7413360  time: 0.958 s\n",
      "[epoch 44,imgs   160] loss: 0.7397733  time: 0.956 s\n",
      "[epoch 44,imgs   200] loss: 0.7389672  time: 0.954 s\n",
      "[epoch 44,imgs   240] loss: 0.7365609  time: 0.956 s\n",
      "[epoch 44,imgs   280] loss: 0.7413235  time: 0.956 s\n",
      "[epoch 44,imgs   320] loss: 0.7380118  time: 0.958 s\n",
      "[epoch 44,imgs   360] loss: 0.7402915  time: 0.956 s\n",
      "[epoch 44,imgs   400] loss: 0.7367733  time: 0.957 s\n",
      "[epoch 44,imgs   440] loss: 0.7359135  time: 0.955 s\n",
      "[epoch 44,imgs   480] loss: 0.7413185  time: 0.954 s\n",
      "[epoch 44,imgs   520] loss: 0.7456691  time: 0.954 s\n",
      "[epoch 44,imgs   560] loss: 0.7373579  time: 0.955 s\n",
      "[epoch 44,imgs   600] loss: 0.7370328  time: 0.955 s\n",
      "[epoch 44,imgs   640] loss: 0.7429917  time: 0.956 s\n",
      "[epoch 44,imgs   680] loss: 0.7405941  time: 0.954 s\n",
      "[epoch 44,imgs   720] loss: 0.7420338  time: 0.953 s\n",
      "[epoch 44,imgs   760] loss: 0.7388758  time: 0.955 s\n",
      "[epoch 44,imgs   800] loss: 0.7417661  time: 0.960 s\n",
      "[epoch 44,imgs   840] loss: 0.7383422  time: 0.957 s\n",
      "[epoch 44,imgs   880] loss: 0.7372668  time: 0.960 s\n",
      "[epoch 44,imgs   920] loss: 0.7380959  time: 0.954 s\n",
      "[epoch 44,imgs   960] loss: 0.7336785  time: 0.955 s\n",
      "[epoch 44,imgs  1000] loss: 0.7394540  time: 0.954 s\n",
      "[epoch 44,imgs  1040] loss: 0.7391849  time: 0.955 s\n",
      "[epoch 44,imgs  1080] loss: 0.7429268  time: 0.955 s\n",
      "[epoch 44,imgs  1120] loss: 0.7405200  time: 0.955 s\n",
      "[epoch 44,imgs  1160] loss: 0.7400083  time: 0.954 s\n",
      "[epoch 44,imgs  1200] loss: 0.7412798  time: 0.954 s\n",
      "[epoch 45,imgs    40] loss: 0.7398908  time: 1.340 s\n",
      "[epoch 45,imgs    80] loss: 0.7364791  time: 0.961 s\n",
      "[epoch 45,imgs   120] loss: 0.7414383  time: 0.958 s\n",
      "[epoch 45,imgs   160] loss: 0.7432401  time: 0.957 s\n",
      "[epoch 45,imgs   200] loss: 0.7409722  time: 0.956 s\n",
      "[epoch 45,imgs   240] loss: 0.7354963  time: 0.957 s\n",
      "[epoch 45,imgs   280] loss: 0.7393845  time: 0.956 s\n",
      "[epoch 45,imgs   320] loss: 0.7431093  time: 0.957 s\n",
      "[epoch 45,imgs   360] loss: 0.7401668  time: 0.957 s\n",
      "[epoch 45,imgs   400] loss: 0.7429759  time: 0.956 s\n",
      "[epoch 45,imgs   440] loss: 0.7400433  time: 0.956 s\n",
      "[epoch 45,imgs   480] loss: 0.7385714  time: 0.957 s\n",
      "[epoch 45,imgs   520] loss: 0.7357374  time: 0.957 s\n",
      "[epoch 45,imgs   560] loss: 0.7405930  time: 0.959 s\n",
      "[epoch 45,imgs   600] loss: 0.7401436  time: 0.960 s\n",
      "[epoch 45,imgs   640] loss: 0.7353848  time: 0.958 s\n",
      "[epoch 45,imgs   680] loss: 0.7407889  time: 0.959 s\n",
      "[epoch 45,imgs   720] loss: 0.7388892  time: 0.958 s\n",
      "[epoch 45,imgs   760] loss: 0.7378800  time: 0.960 s\n",
      "[epoch 45,imgs   800] loss: 0.7375301  time: 0.956 s\n",
      "[epoch 45,imgs   840] loss: 0.7386433  time: 0.957 s\n",
      "[epoch 45,imgs   880] loss: 0.7398121  time: 0.957 s\n",
      "[epoch 45,imgs   920] loss: 0.7342919  time: 0.958 s\n",
      "[epoch 45,imgs   960] loss: 0.7407930  time: 0.957 s\n",
      "[epoch 45,imgs  1000] loss: 0.7393920  time: 0.958 s\n",
      "[epoch 45,imgs  1040] loss: 0.7402261  time: 0.958 s\n",
      "[epoch 45,imgs  1080] loss: 0.7411149  time: 0.960 s\n",
      "[epoch 45,imgs  1120] loss: 0.7431053  time: 0.960 s\n",
      "[epoch 45,imgs  1160] loss: 0.7446050  time: 0.958 s\n",
      "[epoch 45,imgs  1200] loss: 0.7406225  time: 0.957 s\n",
      "[epoch 46,imgs    40] loss: 0.7370093  time: 1.338 s\n",
      "[epoch 46,imgs    80] loss: 0.7402991  time: 0.957 s\n",
      "[epoch 46,imgs   120] loss: 0.7401040  time: 0.958 s\n",
      "[epoch 46,imgs   160] loss: 0.7375069  time: 0.958 s\n",
      "[epoch 46,imgs   200] loss: 0.7368777  time: 0.955 s\n",
      "[epoch 46,imgs   240] loss: 0.7373966  time: 0.952 s\n",
      "[epoch 46,imgs   280] loss: 0.7397299  time: 0.953 s\n",
      "[epoch 46,imgs   320] loss: 0.7406736  time: 0.954 s\n",
      "[epoch 46,imgs   360] loss: 0.7402087  time: 0.953 s\n",
      "[epoch 46,imgs   400] loss: 0.7399652  time: 0.957 s\n",
      "[epoch 46,imgs   440] loss: 0.7389644  time: 0.956 s\n",
      "[epoch 46,imgs   480] loss: 0.7357217  time: 0.956 s\n",
      "[epoch 46,imgs   520] loss: 0.7421700  time: 0.966 s\n",
      "[epoch 46,imgs   560] loss: 0.7391901  time: 0.955 s\n",
      "[epoch 46,imgs   600] loss: 0.7351369  time: 0.965 s\n",
      "[epoch 46,imgs   640] loss: 0.7393935  time: 0.958 s\n",
      "[epoch 46,imgs   680] loss: 0.7445028  time: 0.972 s\n",
      "[epoch 46,imgs   720] loss: 0.7369709  time: 0.958 s\n",
      "[epoch 46,imgs   760] loss: 0.7403879  time: 0.957 s\n",
      "[epoch 46,imgs   800] loss: 0.7429840  time: 0.955 s\n",
      "[epoch 46,imgs   840] loss: 0.7395025  time: 0.954 s\n",
      "[epoch 46,imgs   880] loss: 0.7379004  time: 0.953 s\n",
      "[epoch 46,imgs   920] loss: 0.7385308  time: 0.953 s\n",
      "[epoch 46,imgs   960] loss: 0.7437221  time: 0.952 s\n",
      "[epoch 46,imgs  1000] loss: 0.7381389  time: 0.953 s\n",
      "[epoch 46,imgs  1040] loss: 0.7413742  time: 0.980 s\n",
      "[epoch 46,imgs  1080] loss: 0.7406381  time: 0.956 s\n",
      "[epoch 46,imgs  1120] loss: 0.7428042  time: 0.954 s\n",
      "[epoch 46,imgs  1160] loss: 0.7384582  time: 0.953 s\n",
      "[epoch 46,imgs  1200] loss: 0.7368042  time: 0.968 s\n",
      "[epoch 47,imgs    40] loss: 0.7408178  time: 1.362 s\n",
      "[epoch 47,imgs    80] loss: 0.7415670  time: 0.957 s\n",
      "[epoch 47,imgs   120] loss: 0.7342302  time: 0.960 s\n",
      "[epoch 47,imgs   160] loss: 0.7386688  time: 0.956 s\n",
      "[epoch 47,imgs   200] loss: 0.7378854  time: 0.955 s\n",
      "[epoch 47,imgs   240] loss: 0.7400003  time: 0.956 s\n",
      "[epoch 47,imgs   280] loss: 0.7359088  time: 0.957 s\n",
      "[epoch 47,imgs   320] loss: 0.7368103  time: 0.957 s\n",
      "[epoch 47,imgs   360] loss: 0.7391340  time: 0.955 s\n",
      "[epoch 47,imgs   400] loss: 0.7320893  time: 0.958 s\n",
      "[epoch 47,imgs   440] loss: 0.7412977  time: 0.958 s\n",
      "[epoch 47,imgs   480] loss: 0.7399811  time: 0.957 s\n",
      "[epoch 47,imgs   520] loss: 0.7396494  time: 0.956 s\n",
      "[epoch 47,imgs   560] loss: 0.7401614  time: 0.955 s\n",
      "[epoch 47,imgs   600] loss: 0.7402015  time: 0.955 s\n",
      "[epoch 47,imgs   640] loss: 0.7372323  time: 0.955 s\n",
      "[epoch 47,imgs   680] loss: 0.7425399  time: 0.955 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47,imgs   720] loss: 0.7390330  time: 0.955 s\n",
      "[epoch 47,imgs   760] loss: 0.7409202  time: 0.956 s\n",
      "[epoch 47,imgs   800] loss: 0.7360151  time: 0.958 s\n",
      "[epoch 47,imgs   840] loss: 0.7405095  time: 0.959 s\n",
      "[epoch 47,imgs   880] loss: 0.7408772  time: 0.958 s\n",
      "[epoch 47,imgs   920] loss: 0.7388411  time: 0.956 s\n",
      "[epoch 47,imgs   960] loss: 0.7374313  time: 0.956 s\n",
      "[epoch 47,imgs  1000] loss: 0.7350830  time: 0.956 s\n",
      "[epoch 47,imgs  1040] loss: 0.7433221  time: 0.957 s\n",
      "[epoch 47,imgs  1080] loss: 0.7337685  time: 0.956 s\n",
      "[epoch 47,imgs  1120] loss: 0.7383883  time: 0.956 s\n",
      "[epoch 47,imgs  1160] loss: 0.7371183  time: 0.957 s\n",
      "[epoch 47,imgs  1200] loss: 0.7381940  time: 0.955 s\n",
      "[epoch 48,imgs    40] loss: 0.7431664  time: 1.345 s\n",
      "[epoch 48,imgs    80] loss: 0.7399502  time: 0.956 s\n",
      "[epoch 48,imgs   120] loss: 0.7417892  time: 0.954 s\n",
      "[epoch 48,imgs   160] loss: 0.7371144  time: 0.955 s\n",
      "[epoch 48,imgs   200] loss: 0.7383887  time: 0.955 s\n",
      "[epoch 48,imgs   240] loss: 0.7429112  time: 0.955 s\n",
      "[epoch 48,imgs   280] loss: 0.7391239  time: 0.955 s\n",
      "[epoch 48,imgs   320] loss: 0.7424529  time: 0.955 s\n",
      "[epoch 48,imgs   360] loss: 0.7406944  time: 0.955 s\n",
      "[epoch 48,imgs   400] loss: 0.7368586  time: 0.955 s\n",
      "[epoch 48,imgs   440] loss: 0.7372980  time: 0.954 s\n",
      "[epoch 48,imgs   480] loss: 0.7387115  time: 0.954 s\n",
      "[epoch 48,imgs   520] loss: 0.7416058  time: 0.955 s\n",
      "[epoch 48,imgs   560] loss: 0.7372575  time: 0.954 s\n",
      "[epoch 48,imgs   600] loss: 0.7411399  time: 0.954 s\n",
      "[epoch 48,imgs   640] loss: 0.7342726  time: 0.956 s\n",
      "[epoch 48,imgs   680] loss: 0.7399783  time: 0.955 s\n",
      "[epoch 48,imgs   720] loss: 0.7367216  time: 0.956 s\n",
      "[epoch 48,imgs   760] loss: 0.7387981  time: 0.954 s\n",
      "[epoch 48,imgs   800] loss: 0.7403447  time: 0.955 s\n",
      "[epoch 48,imgs   840] loss: 0.7364856  time: 0.956 s\n",
      "[epoch 48,imgs   880] loss: 0.7370207  time: 0.957 s\n",
      "[epoch 48,imgs   920] loss: 0.7384179  time: 0.958 s\n",
      "[epoch 48,imgs   960] loss: 0.7420025  time: 0.957 s\n",
      "[epoch 48,imgs  1000] loss: 0.7406096  time: 0.959 s\n",
      "[epoch 48,imgs  1040] loss: 0.7435144  time: 0.955 s\n",
      "[epoch 48,imgs  1080] loss: 0.7378987  time: 0.956 s\n",
      "[epoch 48,imgs  1120] loss: 0.7364706  time: 0.956 s\n",
      "[epoch 48,imgs  1160] loss: 0.7393682  time: 0.956 s\n",
      "[epoch 48,imgs  1200] loss: 0.7333252  time: 0.954 s\n",
      "[epoch 49,imgs    40] loss: 0.7423194  time: 1.337 s\n",
      "[epoch 49,imgs    80] loss: 0.7344682  time: 0.956 s\n",
      "[epoch 49,imgs   120] loss: 0.7371282  time: 0.958 s\n",
      "[epoch 49,imgs   160] loss: 0.7393731  time: 0.959 s\n",
      "[epoch 49,imgs   200] loss: 0.7373942  time: 0.959 s\n",
      "[epoch 49,imgs   240] loss: 0.7396563  time: 0.958 s\n",
      "[epoch 49,imgs   280] loss: 0.7364439  time: 0.958 s\n",
      "[epoch 49,imgs   320] loss: 0.7415376  time: 0.962 s\n",
      "[epoch 49,imgs   360] loss: 0.7369663  time: 0.958 s\n",
      "[epoch 49,imgs   400] loss: 0.7343298  time: 0.958 s\n",
      "[epoch 49,imgs   440] loss: 0.7382605  time: 0.959 s\n",
      "[epoch 49,imgs   480] loss: 0.7401597  time: 0.959 s\n",
      "[epoch 49,imgs   520] loss: 0.7384611  time: 0.958 s\n",
      "[epoch 49,imgs   560] loss: 0.7400061  time: 0.958 s\n",
      "[epoch 49,imgs   600] loss: 0.7372623  time: 0.958 s\n",
      "[epoch 49,imgs   640] loss: 0.7391203  time: 0.961 s\n",
      "[epoch 49,imgs   680] loss: 0.7424796  time: 0.957 s\n",
      "[epoch 49,imgs   720] loss: 0.7379127  time: 0.958 s\n",
      "[epoch 49,imgs   760] loss: 0.7416155  time: 0.957 s\n",
      "[epoch 49,imgs   800] loss: 0.7390698  time: 0.958 s\n",
      "[epoch 49,imgs   840] loss: 0.7432083  time: 0.959 s\n",
      "[epoch 49,imgs   880] loss: 0.7378017  time: 0.960 s\n",
      "[epoch 49,imgs   920] loss: 0.7419923  time: 0.956 s\n",
      "[epoch 49,imgs   960] loss: 0.7402323  time: 0.957 s\n",
      "[epoch 49,imgs  1000] loss: 0.7417260  time: 0.957 s\n",
      "[epoch 49,imgs  1040] loss: 0.7374215  time: 0.957 s\n",
      "[epoch 49,imgs  1080] loss: 0.7435312  time: 0.957 s\n",
      "[epoch 49,imgs  1120] loss: 0.7371089  time: 0.958 s\n",
      "[epoch 49,imgs  1160] loss: 0.7446331  time: 0.956 s\n",
      "[epoch 49,imgs  1200] loss: 0.7386159  time: 0.959 s\n",
      "[epoch 50,imgs    40] loss: 0.7364199  time: 1.372 s\n",
      "[epoch 50,imgs    80] loss: 0.7407187  time: 0.961 s\n",
      "[epoch 50,imgs   120] loss: 0.7335150  time: 0.956 s\n",
      "[epoch 50,imgs   160] loss: 0.7390645  time: 0.955 s\n",
      "[epoch 50,imgs   200] loss: 0.7391204  time: 0.957 s\n",
      "[epoch 50,imgs   240] loss: 0.7376636  time: 0.957 s\n",
      "[epoch 50,imgs   280] loss: 0.7411914  time: 0.957 s\n",
      "[epoch 50,imgs   320] loss: 0.7397641  time: 0.958 s\n",
      "[epoch 50,imgs   360] loss: 0.7337797  time: 0.957 s\n",
      "[epoch 50,imgs   400] loss: 0.7395056  time: 0.958 s\n",
      "[epoch 50,imgs   440] loss: 0.7402277  time: 0.957 s\n",
      "[epoch 50,imgs   480] loss: 0.7387934  time: 0.957 s\n",
      "[epoch 50,imgs   520] loss: 0.7395514  time: 0.959 s\n",
      "[epoch 50,imgs   560] loss: 0.7382590  time: 0.957 s\n",
      "[epoch 50,imgs   600] loss: 0.7337724  time: 0.957 s\n",
      "[epoch 50,imgs   640] loss: 0.7374746  time: 0.956 s\n",
      "[epoch 50,imgs   680] loss: 0.7342513  time: 0.957 s\n",
      "[epoch 50,imgs   720] loss: 0.7347237  time: 0.958 s\n",
      "[epoch 50,imgs   760] loss: 0.7378587  time: 0.957 s\n",
      "[epoch 50,imgs   800] loss: 0.7436315  time: 0.957 s\n",
      "[epoch 50,imgs   840] loss: 0.7424415  time: 0.956 s\n",
      "[epoch 50,imgs   880] loss: 0.7377447  time: 0.956 s\n",
      "[epoch 50,imgs   920] loss: 0.7400271  time: 0.957 s\n",
      "[epoch 50,imgs   960] loss: 0.7387308  time: 0.957 s\n",
      "[epoch 50,imgs  1000] loss: 0.7439699  time: 0.958 s\n",
      "[epoch 50,imgs  1040] loss: 0.7355699  time: 0.956 s\n",
      "[epoch 50,imgs  1080] loss: 0.7391753  time: 0.958 s\n",
      "[epoch 50,imgs  1120] loss: 0.7349682  time: 0.958 s\n",
      "[epoch 50,imgs  1160] loss: 0.7399846  time: 0.958 s\n",
      "[epoch 50,imgs  1200] loss: 0.7410241  time: 0.955 s\n",
      "[epoch 51,imgs    40] loss: 0.7385726  time: 1.349 s\n",
      "[epoch 51,imgs    80] loss: 0.7404181  time: 0.956 s\n",
      "[epoch 51,imgs   120] loss: 0.7387149  time: 0.956 s\n",
      "[epoch 51,imgs   160] loss: 0.7327291  time: 0.955 s\n",
      "[epoch 51,imgs   200] loss: 0.7382631  time: 0.956 s\n",
      "[epoch 51,imgs   240] loss: 0.7333615  time: 0.957 s\n",
      "[epoch 51,imgs   280] loss: 0.7405292  time: 0.957 s\n",
      "[epoch 51,imgs   320] loss: 0.7398908  time: 0.959 s\n",
      "[epoch 51,imgs   360] loss: 0.7352694  time: 0.961 s\n",
      "[epoch 51,imgs   400] loss: 0.7457041  time: 0.957 s\n",
      "[epoch 51,imgs   440] loss: 0.7400191  time: 0.957 s\n",
      "[epoch 51,imgs   480] loss: 0.7443856  time: 0.956 s\n",
      "[epoch 51,imgs   520] loss: 0.7407756  time: 0.955 s\n",
      "[epoch 51,imgs   560] loss: 0.7439200  time: 0.955 s\n",
      "[epoch 51,imgs   600] loss: 0.7415580  time: 0.956 s\n",
      "[epoch 51,imgs   640] loss: 0.7358505  time: 0.955 s\n",
      "[epoch 51,imgs   680] loss: 0.7416941  time: 0.954 s\n",
      "[epoch 51,imgs   720] loss: 0.7377889  time: 0.956 s\n",
      "[epoch 51,imgs   760] loss: 0.7352278  time: 0.956 s\n",
      "[epoch 51,imgs   800] loss: 0.7386251  time: 0.959 s\n",
      "[epoch 51,imgs   840] loss: 0.7383732  time: 0.957 s\n",
      "[epoch 51,imgs   880] loss: 0.7445048  time: 0.955 s\n",
      "[epoch 51,imgs   920] loss: 0.7376713  time: 0.956 s\n",
      "[epoch 51,imgs   960] loss: 0.7401245  time: 0.956 s\n",
      "[epoch 51,imgs  1000] loss: 0.7390865  time: 0.955 s\n",
      "[epoch 51,imgs  1040] loss: 0.7347928  time: 0.956 s\n",
      "[epoch 51,imgs  1080] loss: 0.7406363  time: 0.955 s\n",
      "[epoch 51,imgs  1120] loss: 0.7336612  time: 0.956 s\n",
      "[epoch 51,imgs  1160] loss: 0.7429951  time: 0.955 s\n",
      "[epoch 51,imgs  1200] loss: 0.7388239  time: 0.955 s\n",
      "[epoch 52,imgs    40] loss: 0.7372181  time: 1.345 s\n",
      "[epoch 52,imgs    80] loss: 0.7374461  time: 0.958 s\n",
      "[epoch 52,imgs   120] loss: 0.7418461  time: 0.957 s\n",
      "[epoch 52,imgs   160] loss: 0.7398871  time: 0.958 s\n",
      "[epoch 52,imgs   200] loss: 0.7443103  time: 0.957 s\n",
      "[epoch 52,imgs   240] loss: 0.7420992  time: 0.959 s\n",
      "[epoch 52,imgs   280] loss: 0.7415766  time: 0.957 s\n",
      "[epoch 52,imgs   320] loss: 0.7393380  time: 0.957 s\n",
      "[epoch 52,imgs   360] loss: 0.7431067  time: 0.958 s\n",
      "[epoch 52,imgs   400] loss: 0.7409331  time: 0.956 s\n",
      "[epoch 52,imgs   440] loss: 0.7316437  time: 0.958 s\n",
      "[epoch 52,imgs   480] loss: 0.7428725  time: 0.958 s\n",
      "[epoch 52,imgs   520] loss: 0.7348930  time: 0.957 s\n",
      "[epoch 52,imgs   560] loss: 0.7399250  time: 0.957 s\n",
      "[epoch 52,imgs   600] loss: 0.7412329  time: 0.957 s\n",
      "[epoch 52,imgs   640] loss: 0.7418718  time: 0.957 s\n",
      "[epoch 52,imgs   680] loss: 0.7386715  time: 0.958 s\n",
      "[epoch 52,imgs   720] loss: 0.7410995  time: 0.958 s\n",
      "[epoch 52,imgs   760] loss: 0.7390527  time: 0.957 s\n",
      "[epoch 52,imgs   800] loss: 0.7391865  time: 0.957 s\n",
      "[epoch 52,imgs   840] loss: 0.7401409  time: 0.959 s\n",
      "[epoch 52,imgs   880] loss: 0.7388561  time: 0.958 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 52,imgs   920] loss: 0.7394522  time: 0.959 s\n",
      "[epoch 52,imgs   960] loss: 0.7394080  time: 0.958 s\n",
      "[epoch 52,imgs  1000] loss: 0.7395017  time: 0.957 s\n",
      "[epoch 52,imgs  1040] loss: 0.7361182  time: 0.958 s\n",
      "[epoch 52,imgs  1080] loss: 0.7428353  time: 0.956 s\n",
      "[epoch 52,imgs  1120] loss: 0.7391454  time: 0.957 s\n",
      "[epoch 52,imgs  1160] loss: 0.7385240  time: 0.957 s\n",
      "[epoch 52,imgs  1200] loss: 0.7397110  time: 0.959 s\n",
      "[epoch 53,imgs    40] loss: 0.7374780  time: 1.345 s\n",
      "[epoch 53,imgs    80] loss: 0.7417347  time: 0.958 s\n",
      "[epoch 53,imgs   120] loss: 0.7413322  time: 0.957 s\n",
      "[epoch 53,imgs   160] loss: 0.7353290  time: 0.957 s\n",
      "[epoch 53,imgs   200] loss: 0.7378083  time: 0.957 s\n",
      "[epoch 53,imgs   240] loss: 0.7361988  time: 0.956 s\n",
      "[epoch 53,imgs   280] loss: 0.7360075  time: 0.956 s\n",
      "[epoch 53,imgs   320] loss: 0.7407575  time: 0.960 s\n",
      "[epoch 53,imgs   360] loss: 0.7435837  time: 0.957 s\n",
      "[epoch 53,imgs   400] loss: 0.7416176  time: 0.954 s\n",
      "[epoch 53,imgs   440] loss: 0.7370093  time: 0.956 s\n",
      "[epoch 53,imgs   480] loss: 0.7419235  time: 0.957 s\n",
      "[epoch 53,imgs   520] loss: 0.7432635  time: 0.956 s\n",
      "[epoch 53,imgs   560] loss: 0.7391808  time: 0.957 s\n",
      "[epoch 53,imgs   600] loss: 0.7399413  time: 0.956 s\n",
      "[epoch 53,imgs   640] loss: 0.7349795  time: 0.957 s\n",
      "[epoch 53,imgs   680] loss: 0.7385336  time: 0.957 s\n",
      "[epoch 53,imgs   720] loss: 0.7397772  time: 0.958 s\n",
      "[epoch 53,imgs   760] loss: 0.7359545  time: 0.958 s\n",
      "[epoch 53,imgs   800] loss: 0.7413167  time: 0.958 s\n",
      "[epoch 53,imgs   840] loss: 0.7378960  time: 0.957 s\n",
      "[epoch 53,imgs   880] loss: 0.7356949  time: 0.960 s\n",
      "[epoch 53,imgs   920] loss: 0.7340609  time: 0.959 s\n",
      "[epoch 53,imgs   960] loss: 0.7427559  time: 0.959 s\n",
      "[epoch 53,imgs  1000] loss: 0.7396922  time: 0.960 s\n",
      "[epoch 53,imgs  1040] loss: 0.7368422  time: 0.958 s\n",
      "[epoch 53,imgs  1080] loss: 0.7377129  time: 0.957 s\n",
      "[epoch 53,imgs  1120] loss: 0.7400495  time: 0.959 s\n",
      "[epoch 53,imgs  1160] loss: 0.7386131  time: 0.958 s\n",
      "[epoch 53,imgs  1200] loss: 0.7447259  time: 0.959 s\n",
      "[epoch 54,imgs    40] loss: 0.7420799  time: 1.334 s\n",
      "[epoch 54,imgs    80] loss: 0.7349281  time: 0.957 s\n",
      "[epoch 54,imgs   120] loss: 0.7381677  time: 0.957 s\n",
      "[epoch 54,imgs   160] loss: 0.7384289  time: 0.957 s\n",
      "[epoch 54,imgs   200] loss: 0.7385624  time: 0.956 s\n",
      "[epoch 54,imgs   240] loss: 0.7401065  time: 0.957 s\n",
      "[epoch 54,imgs   280] loss: 0.7396736  time: 0.956 s\n",
      "[epoch 54,imgs   320] loss: 0.7384829  time: 0.959 s\n",
      "[epoch 54,imgs   360] loss: 0.7411014  time: 0.958 s\n",
      "[epoch 54,imgs   400] loss: 0.7373222  time: 0.960 s\n",
      "[epoch 54,imgs   440] loss: 0.7382236  time: 0.956 s\n",
      "[epoch 54,imgs   480] loss: 0.7362537  time: 0.956 s\n",
      "[epoch 54,imgs   520] loss: 0.7383859  time: 0.954 s\n",
      "[epoch 54,imgs   560] loss: 0.7397987  time: 0.956 s\n",
      "[epoch 54,imgs   600] loss: 0.7396820  time: 0.956 s\n",
      "[epoch 54,imgs   640] loss: 0.7381819  time: 0.956 s\n",
      "[epoch 54,imgs   680] loss: 0.7418944  time: 0.955 s\n",
      "[epoch 54,imgs   720] loss: 0.7364486  time: 0.956 s\n",
      "[epoch 54,imgs   760] loss: 0.7392390  time: 0.957 s\n",
      "[epoch 54,imgs   800] loss: 0.7401742  time: 0.957 s\n",
      "[epoch 54,imgs   840] loss: 0.7366526  time: 0.957 s\n",
      "[epoch 54,imgs   880] loss: 0.7433037  time: 0.958 s\n",
      "[epoch 54,imgs   920] loss: 0.7391189  time: 0.958 s\n",
      "[epoch 54,imgs   960] loss: 0.7412940  time: 0.957 s\n",
      "[epoch 54,imgs  1000] loss: 0.7380445  time: 0.957 s\n",
      "[epoch 54,imgs  1040] loss: 0.7378713  time: 0.957 s\n",
      "[epoch 54,imgs  1080] loss: 0.7392754  time: 0.956 s\n",
      "[epoch 54,imgs  1120] loss: 0.7370037  time: 0.960 s\n",
      "[epoch 54,imgs  1160] loss: 0.7373827  time: 0.958 s\n",
      "[epoch 54,imgs  1200] loss: 0.7388638  time: 0.958 s\n",
      "[epoch 55,imgs    40] loss: 0.7349375  time: 1.329 s\n",
      "[epoch 55,imgs    80] loss: 0.7374489  time: 0.959 s\n",
      "[epoch 55,imgs   120] loss: 0.7358388  time: 0.960 s\n",
      "[epoch 55,imgs   160] loss: 0.7379456  time: 0.962 s\n",
      "[epoch 55,imgs   200] loss: 0.7415434  time: 0.960 s\n",
      "[epoch 55,imgs   240] loss: 0.7365164  time: 0.958 s\n",
      "[epoch 55,imgs   280] loss: 0.7408789  time: 0.958 s\n",
      "[epoch 55,imgs   320] loss: 0.7452906  time: 0.958 s\n",
      "[epoch 55,imgs   360] loss: 0.7393196  time: 0.957 s\n",
      "[epoch 55,imgs   400] loss: 0.7454907  time: 0.960 s\n",
      "[epoch 55,imgs   440] loss: 0.7419385  time: 0.958 s\n",
      "[epoch 55,imgs   480] loss: 0.7400525  time: 0.957 s\n",
      "[epoch 55,imgs   520] loss: 0.7433922  time: 0.959 s\n",
      "[epoch 55,imgs   560] loss: 0.7402782  time: 0.957 s\n",
      "[epoch 55,imgs   600] loss: 0.7402976  time: 0.959 s\n",
      "[epoch 55,imgs   640] loss: 0.7388736  time: 0.958 s\n",
      "[epoch 55,imgs   680] loss: 0.7412063  time: 0.956 s\n",
      "[epoch 55,imgs   720] loss: 0.7402208  time: 0.957 s\n",
      "[epoch 55,imgs   760] loss: 0.7396141  time: 0.956 s\n",
      "[epoch 55,imgs   800] loss: 0.7382644  time: 0.957 s\n",
      "[epoch 55,imgs   840] loss: 0.7400290  time: 0.958 s\n",
      "[epoch 55,imgs   880] loss: 0.7377222  time: 0.956 s\n",
      "[epoch 55,imgs   920] loss: 0.7440915  time: 0.959 s\n",
      "[epoch 55,imgs   960] loss: 0.7423254  time: 0.959 s\n",
      "[epoch 55,imgs  1000] loss: 0.7390924  time: 0.957 s\n",
      "[epoch 55,imgs  1040] loss: 0.7415405  time: 0.958 s\n",
      "[epoch 55,imgs  1080] loss: 0.7347056  time: 0.958 s\n",
      "[epoch 55,imgs  1120] loss: 0.7374358  time: 0.957 s\n",
      "[epoch 55,imgs  1160] loss: 0.7327935  time: 0.957 s\n",
      "[epoch 55,imgs  1200] loss: 0.7437723  time: 0.954 s\n",
      "[epoch 56,imgs    40] loss: 0.7401556  time: 1.348 s\n",
      "[epoch 56,imgs    80] loss: 0.7392505  time: 0.959 s\n",
      "[epoch 56,imgs   120] loss: 0.7406753  time: 0.958 s\n",
      "[epoch 56,imgs   160] loss: 0.7356769  time: 0.956 s\n",
      "[epoch 56,imgs   200] loss: 0.7375214  time: 0.958 s\n",
      "[epoch 56,imgs   240] loss: 0.7381603  time: 0.957 s\n",
      "[epoch 56,imgs   280] loss: 0.7384990  time: 0.958 s\n",
      "[epoch 56,imgs   320] loss: 0.7361875  time: 0.957 s\n",
      "[epoch 56,imgs   360] loss: 0.7379178  time: 0.956 s\n",
      "[epoch 56,imgs   400] loss: 0.7401240  time: 0.956 s\n",
      "[epoch 56,imgs   440] loss: 0.7394376  time: 0.958 s\n",
      "[epoch 56,imgs   480] loss: 0.7386696  time: 0.956 s\n",
      "[epoch 56,imgs   520] loss: 0.7382823  time: 0.955 s\n",
      "[epoch 56,imgs   560] loss: 0.7413276  time: 0.955 s\n",
      "[epoch 56,imgs   600] loss: 0.7392986  time: 0.958 s\n",
      "[epoch 56,imgs   640] loss: 0.7391179  time: 0.957 s\n",
      "[epoch 56,imgs   680] loss: 0.7388141  time: 0.956 s\n",
      "[epoch 56,imgs   720] loss: 0.7402385  time: 0.956 s\n",
      "[epoch 56,imgs   760] loss: 0.7410194  time: 0.958 s\n",
      "[epoch 56,imgs   800] loss: 0.7399023  time: 0.957 s\n",
      "[epoch 56,imgs   840] loss: 0.7373710  time: 0.957 s\n",
      "[epoch 56,imgs   880] loss: 0.7381949  time: 0.957 s\n",
      "[epoch 56,imgs   920] loss: 0.7387285  time: 0.957 s\n",
      "[epoch 56,imgs   960] loss: 0.7418616  time: 0.957 s\n",
      "[epoch 56,imgs  1000] loss: 0.7352710  time: 0.958 s\n",
      "[epoch 56,imgs  1040] loss: 0.7414785  time: 0.970 s\n",
      "[epoch 56,imgs  1080] loss: 0.7366050  time: 0.959 s\n",
      "[epoch 56,imgs  1120] loss: 0.7371292  time: 0.960 s\n",
      "[epoch 56,imgs  1160] loss: 0.7384499  time: 0.958 s\n",
      "[epoch 56,imgs  1200] loss: 0.7403628  time: 0.957 s\n",
      "[epoch 57,imgs    40] loss: 0.7437328  time: 1.339 s\n",
      "[epoch 57,imgs    80] loss: 0.7384407  time: 0.956 s\n",
      "[epoch 57,imgs   120] loss: 0.7406903  time: 0.959 s\n",
      "[epoch 57,imgs   160] loss: 0.7403952  time: 0.958 s\n",
      "[epoch 57,imgs   200] loss: 0.7322600  time: 0.961 s\n",
      "[epoch 57,imgs   240] loss: 0.7377086  time: 0.962 s\n",
      "[epoch 57,imgs   280] loss: 0.7412875  time: 0.964 s\n",
      "[epoch 57,imgs   320] loss: 0.7398892  time: 0.962 s\n",
      "[epoch 57,imgs   360] loss: 0.7344508  time: 0.960 s\n",
      "[epoch 57,imgs   400] loss: 0.7445887  time: 0.959 s\n",
      "[epoch 57,imgs   440] loss: 0.7365444  time: 0.959 s\n",
      "[epoch 57,imgs   480] loss: 0.7363003  time: 0.959 s\n",
      "[epoch 57,imgs   520] loss: 0.7384924  time: 0.962 s\n",
      "[epoch 57,imgs   560] loss: 0.7356299  time: 0.960 s\n",
      "[epoch 57,imgs   600] loss: 0.7427432  time: 0.960 s\n",
      "[epoch 57,imgs   640] loss: 0.7416271  time: 0.961 s\n",
      "[epoch 57,imgs   680] loss: 0.7367816  time: 0.961 s\n",
      "[epoch 57,imgs   720] loss: 0.7386355  time: 0.962 s\n",
      "[epoch 57,imgs   760] loss: 0.7388698  time: 0.961 s\n",
      "[epoch 57,imgs   800] loss: 0.7407300  time: 0.958 s\n",
      "[epoch 57,imgs   840] loss: 0.7423849  time: 0.963 s\n",
      "[epoch 57,imgs   880] loss: 0.7387121  time: 0.960 s\n",
      "[epoch 57,imgs   920] loss: 0.7372765  time: 0.959 s\n",
      "[epoch 57,imgs   960] loss: 0.7327764  time: 0.961 s\n",
      "[epoch 57,imgs  1000] loss: 0.7399291  time: 0.961 s\n",
      "[epoch 57,imgs  1040] loss: 0.7373458  time: 0.957 s\n",
      "[epoch 57,imgs  1080] loss: 0.7391010  time: 0.959 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 57,imgs  1120] loss: 0.7375628  time: 0.959 s\n",
      "[epoch 57,imgs  1160] loss: 0.7412940  time: 0.960 s\n",
      "[epoch 57,imgs  1200] loss: 0.7369132  time: 0.958 s\n",
      "[epoch 58,imgs    40] loss: 0.7411276  time: 1.359 s\n",
      "[epoch 58,imgs    80] loss: 0.7408227  time: 0.961 s\n",
      "[epoch 58,imgs   120] loss: 0.7411598  time: 0.955 s\n",
      "[epoch 58,imgs   160] loss: 0.7370255  time: 0.956 s\n",
      "[epoch 58,imgs   200] loss: 0.7359678  time: 0.955 s\n",
      "[epoch 58,imgs   240] loss: 0.7398127  time: 0.955 s\n",
      "[epoch 58,imgs   280] loss: 0.7386993  time: 0.954 s\n",
      "[epoch 58,imgs   320] loss: 0.7383450  time: 0.961 s\n",
      "[epoch 58,imgs   360] loss: 0.7360585  time: 0.953 s\n",
      "[epoch 58,imgs   400] loss: 0.7369435  time: 0.954 s\n",
      "[epoch 58,imgs   440] loss: 0.7398252  time: 0.952 s\n",
      "[epoch 58,imgs   480] loss: 0.7375010  time: 0.952 s\n",
      "[epoch 58,imgs   520] loss: 0.7369009  time: 0.953 s\n",
      "[epoch 58,imgs   560] loss: 0.7382792  time: 0.956 s\n",
      "[epoch 58,imgs   600] loss: 0.7374447  time: 0.953 s\n",
      "[epoch 58,imgs   640] loss: 0.7387606  time: 0.953 s\n",
      "[epoch 58,imgs   680] loss: 0.7401870  time: 0.950 s\n",
      "[epoch 58,imgs   720] loss: 0.7383375  time: 0.953 s\n",
      "[epoch 58,imgs   760] loss: 0.7404440  time: 0.953 s\n",
      "[epoch 58,imgs   800] loss: 0.7405267  time: 0.953 s\n",
      "[epoch 58,imgs   840] loss: 0.7411414  time: 0.953 s\n",
      "[epoch 58,imgs   880] loss: 0.7434315  time: 0.952 s\n",
      "[epoch 58,imgs   920] loss: 0.7423476  time: 0.953 s\n",
      "[epoch 58,imgs   960] loss: 0.7409718  time: 0.955 s\n",
      "[epoch 58,imgs  1000] loss: 0.7366073  time: 0.955 s\n",
      "[epoch 58,imgs  1040] loss: 0.7393342  time: 0.955 s\n",
      "[epoch 58,imgs  1080] loss: 0.7409723  time: 0.954 s\n",
      "[epoch 58,imgs  1120] loss: 0.7342936  time: 0.956 s\n",
      "[epoch 58,imgs  1160] loss: 0.7419868  time: 0.954 s\n",
      "[epoch 58,imgs  1200] loss: 0.7403365  time: 0.953 s\n",
      "[epoch 59,imgs    40] loss: 0.7414088  time: 1.391 s\n",
      "[epoch 59,imgs    80] loss: 0.7413608  time: 0.970 s\n",
      "[epoch 59,imgs   120] loss: 0.7357429  time: 0.979 s\n",
      "[epoch 59,imgs   160] loss: 0.7390422  time: 0.968 s\n",
      "[epoch 59,imgs   200] loss: 0.7449676  time: 0.967 s\n",
      "[epoch 59,imgs   240] loss: 0.7351432  time: 0.965 s\n",
      "[epoch 59,imgs   280] loss: 0.7372729  time: 0.967 s\n",
      "[epoch 59,imgs   320] loss: 0.7383822  time: 0.966 s\n",
      "[epoch 59,imgs   360] loss: 0.7404650  time: 0.974 s\n",
      "[epoch 59,imgs   400] loss: 0.7412276  time: 0.966 s\n",
      "[epoch 59,imgs   440] loss: 0.7396867  time: 0.970 s\n",
      "[epoch 59,imgs   480] loss: 0.7404906  time: 0.965 s\n",
      "[epoch 59,imgs   520] loss: 0.7451342  time: 0.966 s\n",
      "[epoch 59,imgs   560] loss: 0.7354532  time: 0.964 s\n",
      "[epoch 59,imgs   600] loss: 0.7377895  time: 0.967 s\n",
      "[epoch 59,imgs   640] loss: 0.7368959  time: 0.967 s\n",
      "[epoch 59,imgs   680] loss: 0.7395156  time: 0.965 s\n",
      "[epoch 59,imgs   720] loss: 0.7407359  time: 0.969 s\n",
      "[epoch 59,imgs   760] loss: 0.7396798  time: 0.970 s\n",
      "[epoch 59,imgs   800] loss: 0.7369382  time: 0.967 s\n",
      "[epoch 59,imgs   840] loss: 0.7432707  time: 0.967 s\n",
      "[epoch 59,imgs   880] loss: 0.7419706  time: 0.967 s\n",
      "[epoch 59,imgs   920] loss: 0.7388874  time: 0.966 s\n",
      "[epoch 59,imgs   960] loss: 0.7405538  time: 0.965 s\n",
      "[epoch 59,imgs  1000] loss: 0.7364156  time: 0.966 s\n",
      "[epoch 59,imgs  1040] loss: 0.7388243  time: 0.968 s\n",
      "[epoch 59,imgs  1080] loss: 0.7403074  time: 0.966 s\n",
      "[epoch 59,imgs  1120] loss: 0.7383015  time: 0.969 s\n",
      "[epoch 59,imgs  1160] loss: 0.7389106  time: 0.966 s\n",
      "[epoch 59,imgs  1200] loss: 0.7404636  time: 0.963 s\n",
      "[epoch 60,imgs    40] loss: 0.7329164  time: 1.339 s\n",
      "[epoch 60,imgs    80] loss: 0.7377113  time: 0.966 s\n",
      "[epoch 60,imgs   120] loss: 0.7421644  time: 0.958 s\n",
      "[epoch 60,imgs   160] loss: 0.7348590  time: 0.958 s\n",
      "[epoch 60,imgs   200] loss: 0.7409461  time: 0.958 s\n",
      "[epoch 60,imgs   240] loss: 0.7409844  time: 0.959 s\n",
      "[epoch 60,imgs   280] loss: 0.7354683  time: 0.958 s\n",
      "[epoch 60,imgs   320] loss: 0.7431688  time: 0.960 s\n",
      "[epoch 60,imgs   360] loss: 0.7389826  time: 0.957 s\n",
      "[epoch 60,imgs   400] loss: 0.7419685  time: 0.958 s\n",
      "[epoch 60,imgs   440] loss: 0.7370092  time: 0.959 s\n",
      "[epoch 60,imgs   480] loss: 0.7375317  time: 0.958 s\n",
      "[epoch 60,imgs   520] loss: 0.7378540  time: 0.957 s\n",
      "[epoch 60,imgs   560] loss: 0.7400866  time: 0.961 s\n",
      "[epoch 60,imgs   600] loss: 0.7336915  time: 0.958 s\n",
      "[epoch 60,imgs   640] loss: 0.7401633  time: 0.957 s\n",
      "[epoch 60,imgs   680] loss: 0.7387028  time: 0.956 s\n",
      "[epoch 60,imgs   720] loss: 0.7456563  time: 0.958 s\n",
      "[epoch 60,imgs   760] loss: 0.7377380  time: 0.957 s\n",
      "[epoch 60,imgs   800] loss: 0.7439941  time: 0.957 s\n",
      "[epoch 60,imgs   840] loss: 0.7391159  time: 0.958 s\n",
      "[epoch 60,imgs   880] loss: 0.7367241  time: 0.959 s\n",
      "[epoch 60,imgs   920] loss: 0.7382538  time: 0.957 s\n",
      "[epoch 60,imgs   960] loss: 0.7401938  time: 0.958 s\n",
      "[epoch 60,imgs  1000] loss: 0.7424102  time: 0.957 s\n",
      "[epoch 60,imgs  1040] loss: 0.7418518  time: 0.957 s\n",
      "[epoch 60,imgs  1080] loss: 0.7387901  time: 0.958 s\n",
      "[epoch 60,imgs  1120] loss: 0.7423773  time: 0.957 s\n",
      "[epoch 60,imgs  1160] loss: 0.7399404  time: 0.957 s\n",
      "[epoch 60,imgs  1200] loss: 0.7379497  time: 0.956 s\n",
      "Extracting Features...\n",
      "tensor([26, 31, 13,  2,  9,  0, 43,  8, 15, 31, 27, 30, 46, 45, 36, 26])\n",
      "tensor([49, 33, 27, 42, 45, 31, 40,  8, 46, 46, 36,  5, 13, 16,  3, 45])\n",
      "tensor([ 9, 30, 43, 18, 37, 17,  2, 35,  5, 37, 38, 41, 16, 39, 16, 14])\n",
      "tensor([28, 43, 37, 33, 45, 49, 25,  9, 18, 47, 42, 16, 44, 26, 16, 48])\n",
      "tensor([15,  0, 17, 35,  4, 22,  5, 32, 10,  1, 31, 43, 16, 14, 31, 14])\n",
      "tensor([44,  8,  3, 10,  3, 10, 43, 14, 37, 48, 24, 40,  3, 26,  1,  8])\n",
      "tensor([ 3, 43,  9, 17, 23, 16, 47,  0, 48, 44, 11, 22, 40, 20, 13, 19])\n",
      "tensor([12, 29, 38, 39, 28, 13, 47, 34, 34, 44, 45, 49, 15, 33, 35,  8])\n",
      "tensor([11, 48, 35,  9, 35, 24, 20, 40, 31, 11, 23, 12, 18,  3, 31, 34])\n",
      "tensor([ 9, 32, 22, 22,  5, 33, 10, 23, 13, 12,  6,  1, 25, 26, 42, 36])\n",
      "tensor([ 5,  5, 16, 32, 14, 39, 18, 47, 21, 10, 32, 28,  8, 27, 34, 14])\n",
      "tensor([44, 14, 42, 39, 22, 42,  5, 18, 23, 30, 22, 31, 34, 21,  4, 35])\n",
      "tensor([49, 34, 29, 27, 14, 16, 20, 24,  1, 15, 39, 45, 25, 30, 35,  6])\n",
      "tensor([42,  2, 11, 20,  9, 11, 10, 15, 27, 11, 15, 18, 47, 42, 26,  5])\n",
      "tensor([42,  3, 16, 22,  8, 27,  7, 34, 28, 36,  6, 42, 12, 40, 15, 22])\n",
      "tensor([32, 20,  9,  7, 43,  9, 14, 27, 20, 18, 10, 48, 45, 43, 35, 49])\n",
      "tensor([ 4, 41, 19, 26, 17, 15, 28, 12, 10, 44, 43, 16, 38, 36,  8, 21])\n",
      "tensor([27, 26, 39, 21, 28, 11, 22, 45, 36, 35, 27, 29,  2, 49, 38, 25])\n",
      "tensor([ 9,  1, 23, 22, 25, 42, 30, 45, 17, 23, 44, 26, 19, 34,  1, 23])\n",
      "tensor([ 6, 32, 33, 23, 22, 10, 10, 39,  9, 10, 16, 45, 11, 15, 16, 12])\n",
      "tensor([44,  0, 17, 39, 48, 28,  6, 32, 46, 39, 46, 38, 44,  4, 32,  8])\n",
      "tensor([ 8, 32, 13,  3, 11, 41, 27, 10,  5, 42,  0, 44, 37, 11, 22, 39])\n",
      "tensor([13, 41, 30, 21,  3, 15, 32, 23, 31, 23, 43, 14,  7,  5, 40,  9])\n",
      "tensor([48, 29,  4,  5, 26,  5, 43,  4, 15, 41, 46, 38, 34, 12, 19, 16])\n",
      "tensor([39, 30, 11, 12, 11, 11, 36, 45, 32, 14, 27, 48, 33,  6,  9, 12])\n",
      "tensor([ 7, 27, 25, 18, 21,  9, 39,  8, 39, 17, 38, 44, 33, 27,  2, 27])\n",
      "tensor([33,  2,  0, 25, 32, 19, 16, 35,  7, 33, 27, 15,  1, 34, 30, 35])\n",
      "tensor([37, 41, 32, 35,  6,  5, 42, 38, 16,  3, 26, 45, 11, 47, 38, 30])\n",
      "tensor([42, 25, 22,  5, 35, 42, 32, 36, 24, 33, 44, 28, 15, 22, 47, 36])\n",
      "tensor([ 9, 12, 45, 43, 36, 21, 10, 22, 28, 49, 23, 39, 45, 24, 23,  7])\n",
      "tensor([45, 39,  8, 23, 19, 33, 24, 17, 34, 16, 46, 36, 23, 19, 34, 49])\n",
      "tensor([21, 13, 46, 35, 24, 41, 23,  2, 31, 45, 26, 27,  5, 30, 49, 26])\n",
      "tensor([18, 27, 37, 49, 14, 29,  1, 47, 31, 11, 42, 30, 21, 45, 29, 29])\n",
      "tensor([31, 13, 45, 20, 21, 42, 43, 48, 22, 30, 25, 46, 46, 49,  5, 26])\n",
      "tensor([12,  2,  6,  1, 34, 37,  9,  4, 44,  4, 38, 27, 48,  0, 24, 49])\n",
      "tensor([45, 26,  3, 49,  0,  0, 43, 15, 22, 21, 38, 42, 41, 19,  3, 49])\n",
      "tensor([46, 22, 47, 38, 13,  3, 34, 41, 17, 22, 33, 10,  8,  5, 28, 18])\n",
      "tensor([ 4, 47, 26,  8, 41,  2, 33, 15, 36, 45, 31,  2, 17, 46, 21,  2])\n",
      "tensor([31, 16, 12, 31, 27,  7, 19, 43, 48, 34, 12, 36,  2, 23, 47,  6])\n",
      "tensor([ 1, 13,  5,  2, 45, 23, 32, 20,  5, 11, 27, 38,  5,  5, 40, 34])\n",
      "tensor([27, 34, 37, 16,  9,  0, 41, 12, 45, 12, 26, 44,  0, 25, 18, 15])\n",
      "tensor([ 5,  2, 11, 36, 11, 18, 23, 49, 19,  7, 27, 23,  7,  6, 17, 33])\n",
      "tensor([47, 10, 22,  6, 33, 26, 18, 43, 29, 21, 12, 15, 26, 10, 24, 33])\n",
      "tensor([45, 27, 42, 25, 33, 36,  0, 24, 38, 38, 32, 20, 32, 43, 32, 10])\n",
      "tensor([34, 12, 48, 42, 23, 34, 44, 21, 48, 18,  8, 36, 33, 47, 43,  5])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([23,  7, 49, 28,  9, 37, 16,  0, 26,  2, 25, 21, 32, 11, 23,  3])\n",
      "tensor([40, 41,  1, 19, 35, 32, 19, 25,  5, 42, 17, 18,  6, 12, 48, 39])\n",
      "tensor([21, 44, 20, 27,  9, 44, 43, 21, 18, 17, 29,  3, 27, 33,  3,  7])\n",
      "tensor([ 2, 40,  5,  7, 40,  6, 34, 14,  1, 14, 26, 36, 45, 27, 15, 18])\n",
      "tensor([12, 41, 23, 25, 31,  1, 11, 27, 30, 30, 40, 45, 27, 45, 26,  7])\n",
      "tensor([38,  6, 41,  7, 41, 13,  1,  7, 22, 49, 11, 29, 20,  7, 48, 16])\n",
      "tensor([ 1, 16,  5, 45, 20, 17, 24, 13, 41, 48, 11,  1, 34, 12, 33, 45])\n",
      "tensor([23,  5,  4, 41,  1, 23, 32, 10, 35, 25, 11, 49, 48, 35,  3, 12])\n",
      "tensor([37, 14, 39, 12, 27, 47, 21, 15, 28, 24, 41,  0, 46,  4, 35, 25])\n",
      "tensor([16, 11,  3, 20, 11, 35, 36, 39, 11, 23, 24, 47, 46, 12, 48, 32])\n",
      "tensor([30,  9, 10,  0,  4,  7, 46, 25, 34, 25, 11,  2, 19, 41, 26, 41])\n",
      "tensor([36, 11, 13, 36, 42, 47,  6, 11, 11, 24, 38, 41, 11, 12, 26, 28])\n",
      "tensor([ 7, 25, 15, 34, 10, 25,  9, 37, 19,  7, 16, 17, 14, 39,  0, 38])\n",
      "tensor([41, 47, 13, 49, 10, 19, 34,  3, 10,  3, 32, 49, 36, 31, 17, 24])\n",
      "tensor([27, 27, 12, 35,  1, 20, 20, 10, 16, 12, 21, 28, 33, 23, 31, 49])\n",
      "tensor([19, 43, 30, 40, 19, 32,  2, 19, 44, 31, 40, 27,  0, 29,  0, 29])\n",
      "tensor([44,  7, 32, 10, 41, 48, 34,  7,  9, 43, 43, 21,  3, 28, 26, 33])\n",
      "tensor([46, 11, 18, 31, 23, 23,  7, 12, 16, 13, 30, 33, 39, 23,  9, 28])\n",
      "tensor([ 6, 34,  3,  5, 12,  4,  5, 46, 39, 35, 17, 29, 26, 49, 44, 43])\n",
      "tensor([27,  1, 33, 35, 28, 48, 36, 31,  7, 34, 20,  2, 44, 42, 31, 31])\n",
      "tensor([32, 22, 34, 49,  4,  5,  1, 28, 27, 15, 36, 15, 17, 23, 23, 40])\n",
      "tensor([46,  8, 49, 41,  3, 25, 16, 11, 36, 26, 12, 38, 37,  8, 26,  7])\n",
      "tensor([13,  7,  7, 10, 24, 33, 22,  5, 45, 29, 36,  8, 36,  5, 43, 30])\n",
      "tensor([14, 10,  8, 29, 45, 10, 37, 46, 25, 30, 37, 10, 21, 30, 36,  1])\n",
      "tensor([ 5, 36, 41,  3, 12, 35, 31, 26, 16, 27,  8, 12,  1, 18, 22, 30])\n",
      "tensor([29, 45, 22, 20,  8, 23, 29, 21, 39,  7, 32,  8, 31, 39,  3, 20])\n",
      "tensor([10, 37,  1, 39, 24, 11, 14,  3, 47, 22, 25,  2,  1, 42, 23, 15])\n",
      "tensor([39, 12,  5, 13,  0, 38, 39, 11, 39, 37, 47, 44, 24, 39, 16, 12])\n",
      "tensor([12,  3, 16,  8,  8, 35, 32, 49,  8,  3, 29, 30,  1, 42, 44,  7])\n",
      "tensor([47, 45, 22, 22, 38, 20, 33, 11, 36, 23, 36, 16, 49, 28, 27, 48])\n",
      "tensor([38,  5, 32,  5, 38, 19, 16, 10,  2, 45, 49, 37, 10, 19, 48, 44])\n",
      "tensor([32, 15, 38, 49, 21, 30, 23, 15, 15, 43, 41, 10, 23, 31, 44, 22])\n",
      "tensor([ 5, 16,  3, 20, 10, 24, 17, 35,  1, 27, 29, 10, 37, 34, 34, 24])\n",
      "tensor([19, 27,  2, 16, 23, 19,  6, 47, 11, 49,  2, 13, 32, 33, 13, 18])\n",
      "tensor([22, 38, 27, 32, 19,  7, 32, 42, 46, 29,  0,  8, 32, 15,  3, 27])\n",
      "tensor([ 1, 25, 17, 18, 27, 49,  1, 45, 12,  5, 25,  0, 39,  2, 22, 20])\n",
      "tensor([17, 47, 37,  8, 42, 27, 37, 28, 45,  4, 33, 16, 15, 35, 44, 30])\n",
      "tensor([16,  3, 22,  0, 25, 40, 16, 42, 29, 15, 48, 13, 37, 49, 13, 15])\n",
      "tensor([38, 13, 18,  7, 47, 36, 25, 14,  0, 12, 46, 31, 28, 41,  5, 33])\n",
      "tensor([24, 19, 36, 24, 49, 40, 16, 30, 18, 14,  2, 47,  7, 34, 36, 32])\n",
      "tensor([ 5, 35, 22, 24, 40, 37, 32, 23, 42, 19, 27, 46, 22,  0, 46, 13])\n",
      "tensor([23, 38, 38, 31,  2, 22,  5, 20, 32,  9, 12, 47, 34, 42, 24,  8])\n",
      "tensor([39, 47, 28, 27, 38, 14, 15,  0,  0, 46, 25, 17, 14, 48,  2,  4])\n",
      "tensor([48, 32, 45, 17, 17,  3, 17,  6, 39,  0, 34, 34, 48,  5, 45,  5])\n",
      "tensor([ 9, 11, 25, 10, 16, 44, 38, 29, 12,  2, 24, 35, 41, 15, 43, 48])\n",
      "tensor([12, 48, 36, 15, 21, 34, 30, 31,  4, 23, 42,  1, 45, 48,  2, 15])\n",
      "tensor([33, 38, 29, 29, 21, 20, 32,  6, 39, 44, 14, 43, 26, 38, 23, 33])\n",
      "tensor([ 7, 16,  9,  6, 11, 47, 40, 48,  3, 35, 37,  0, 21, 38, 43, 42])\n",
      "tensor([15, 16, 34, 39, 33, 19, 10,  1,  1,  0, 18, 34,  8,  9, 32, 41])\n",
      "tensor([29, 34, 10, 36, 20, 20, 22, 15, 18, 39, 13, 13, 38, 40, 37, 32])\n",
      "tensor([38, 11, 46, 36, 47, 48, 11,  3, 35, 38,  7, 38,  6, 38, 26, 15])\n",
      "tensor([48,  9, 14, 40, 37, 28, 20, 44, 24, 28, 31,  8, 41, 10, 48, 10])\n",
      "tensor([35, 49,  6, 34, 31, 28, 11, 41, 32, 22, 42, 27, 33, 16, 28, 17])\n",
      "tensor([15, 47, 34, 45, 19, 43, 21, 37, 43,  2,  7, 37, 21, 19, 21, 42])\n",
      "tensor([24, 48, 48, 27, 23,  8, 24, 34,  3, 24, 40, 26, 43, 48, 37, 45])\n",
      "tensor([13, 42, 29, 26, 14,  8, 28, 32, 25, 33, 30, 32, 38,  5, 29, 13])\n",
      "tensor([19, 49, 15, 35, 40,  3,  6,  3, 38, 24, 44, 37,  6, 17, 45, 30])\n",
      "tensor([40,  0, 18, 42, 29, 34, 15,  1, 34, 10, 37,  6, 33, 31, 39, 17])\n",
      "tensor([22, 17, 24,  2,  0, 23, 17, 45,  0, 32, 25, 44, 26,  6, 19,  0])\n",
      "tensor([21, 25,  5, 38, 49,  3,  0, 24, 38, 21,  7, 12, 10, 47,  6, 30])\n",
      "tensor([27, 40, 34, 29,  7,  4,  0,  3,  9, 26, 17, 44, 45, 30, 19, 33])\n",
      "tensor([17, 39,  7, 18, 10, 38,  4, 39,  7, 22,  0,  6, 38,  0, 48, 24])\n",
      "tensor([15,  5, 40,  7, 19, 10, 45, 23, 49, 42, 29, 20,  6,  3, 40,  1])\n",
      "tensor([ 0, 46, 24, 20, 29, 19, 40, 32, 36, 27, 36, 43,  6, 46, 33, 21])\n",
      "tensor([ 9,  2, 25,  7, 15,  4, 22, 32, 10, 34, 48, 33, 21, 21, 46, 38])\n",
      "tensor([20,  7, 46, 35,  0, 22, 33,  4, 34, 47,  2, 24,  3, 24, 39, 38])\n",
      "tensor([45, 14, 15, 14, 39, 29, 23, 16, 43, 33, 33, 45,  3, 11, 47, 23])\n",
      "tensor([ 1, 45, 46, 39, 32, 40, 10, 34, 44, 32, 46, 32, 42, 20, 29, 33])\n",
      "tensor([33, 28, 21,  7, 19, 21, 19, 17, 49, 32, 18, 24, 40, 15, 11, 13])\n",
      "tensor([ 4, 11,  7,  5, 36, 29, 43,  4, 18, 36, 49, 34,  3, 12, 38,  9])\n",
      "tensor([23,  9, 40, 28,  1, 27, 41,  1, 15, 36,  9, 47, 34, 42,  8, 34])\n",
      "tensor([30, 48, 36, 10,  2, 19, 34, 37,  1, 32, 42, 41, 35, 14, 12, 23])\n",
      "tensor([32, 24, 47, 49, 41,  5, 48, 26, 43, 10, 28, 49, 45, 49, 39,  5])\n",
      "tensor([35, 20,  7,  8, 38,  6,  3, 35, 19, 27,  1, 42, 32, 39, 32,  0])\n",
      "tensor([34, 43, 33, 13, 16, 32, 17, 48, 32, 34,  0, 34,  5, 42, 22, 38])\n",
      "tensor([16, 18, 42,  0, 38,  0, 48,  6, 40,  8, 36, 18, 44, 34, 21, 29])\n",
      "tensor([44, 22, 13, 20, 39, 31, 33,  7, 38, 15, 21, 47, 32, 49, 42, 11])\n",
      "tensor([21, 34, 16, 36, 41, 39, 44, 28, 36, 33, 31,  5, 32,  0,  0, 46])\n",
      "tensor([ 6, 23, 35, 41, 39,  5, 22,  3, 15, 19, 39, 41, 26, 17, 35, 22])\n",
      "tensor([10, 38, 19, 44, 33, 44, 18, 10, 24,  4, 28, 15, 29, 38, 20, 37])\n",
      "tensor([ 6,  0, 40, 27, 11, 23, 22, 35, 13,  1, 15, 16, 13, 24, 11,  2])\n",
      "tensor([10, 27,  4, 28,  2, 46,  2, 36,  7, 27, 29,  7, 49, 31, 38, 15])\n",
      "tensor([36, 41, 24, 10, 23, 13, 26, 27, 44, 43, 39, 37, 41, 49, 17, 33])\n",
      "tensor([36, 21, 13, 24, 49, 17, 24,  7, 15,  1,  2, 42, 22, 17, 28, 48])\n",
      "tensor([40, 34, 46, 49, 20,  3,  9, 18, 42, 30, 48, 25, 47, 48, 43,  4])\n",
      "tensor([48, 49, 11, 24,  4, 24, 20,  8,  1,  0, 10, 35,  6, 15,  6,  4])\n",
      "tensor([30,  6,  5, 19, 10, 15, 12, 15, 45,  0, 45, 45, 33,  8, 28, 25])\n",
      "tensor([48,  1, 32, 19, 41, 16,  3,  0, 16, 33, 16, 46, 34,  3, 38,  9])\n",
      "tensor([33, 32, 48,  9, 30, 27, 22, 43, 22,  4,  2, 33, 11, 31, 33,  5])\n",
      "tensor([27, 11, 37, 22, 41, 26, 49, 21, 29, 15, 34, 22, 47, 13, 19, 22])\n",
      "tensor([35,  8, 26, 16, 10, 22, 25, 33, 29, 10, 36, 21, 36, 16, 16, 22])\n",
      "tensor([ 3, 26, 14,  5, 25, 17, 33, 44,  5, 34,  0,  5, 46, 12,  5, 10])\n",
      "tensor([ 4, 48, 36, 26, 40, 47,  4, 49, 17, 40, 46, 23, 10,  8, 33, 11])\n",
      "tensor([46, 14, 17, 44, 13, 46, 49, 23, 28, 33, 27, 42,  8, 49, 17, 11])\n",
      "tensor([14, 12, 15, 29, 36, 20, 36, 35, 18, 28, 12, 11, 28,  6, 37, 46])\n",
      "tensor([10, 47, 29, 34,  2,  1,  2, 23,  5, 21, 18, 13, 49, 47, 34, 35])\n",
      "tensor([41, 27,  8, 32, 31, 35,  4, 49, 31,  8, 17, 28, 45, 19,  6, 10])\n",
      "tensor([39, 34, 14, 43,  5,  2,  8,  0,  3, 35, 15, 43, 34, 15, 27,  6])\n",
      "tensor([45, 21, 40, 12, 46,  2,  4, 27, 38, 18, 40, 29, 19, 36, 44,  4])\n",
      "tensor([ 0, 19, 41, 28, 30, 16, 20, 11,  9,  6, 34, 38,  0, 26, 49, 45])\n",
      "tensor([12,  4,  2, 26, 20,  0, 29, 33, 21, 49, 13, 19, 14, 13, 34, 18])\n",
      "tensor([ 7, 34, 32,  7, 20, 38, 29,  3, 11, 37, 21, 30, 31, 16, 30, 29])\n",
      "tensor([30, 42, 13, 33, 41, 41, 36, 11, 40, 39, 45, 28, 24, 22, 16, 26])\n",
      "tensor([12,  7, 13, 35, 16, 38, 14,  0,  9, 49, 27,  8,  5, 47, 32, 29])\n",
      "tensor([14, 43, 46,  0, 26, 24, 10,  2, 28, 48, 19, 38, 34,  5, 35, 11])\n",
      "tensor([ 4, 37,  9, 46, 29,  0, 15, 32,  7, 25, 34, 36, 47, 10, 38,  3])\n",
      "tensor([21, 41, 11, 40, 35, 48, 42,  4, 46, 14, 47,  6, 34,  3, 40, 29])\n",
      "tensor([ 8, 14, 27, 18, 48,  8, 28, 19, 33,  2, 11, 41, 37, 24, 31, 33])\n",
      "tensor([45, 36, 20,  0, 20,  3, 18, 33, 39, 48, 41, 12, 21,  1, 23,  4])\n",
      "tensor([15, 41, 35, 14, 43, 23, 35, 21, 49, 41, 21,  2,  4, 40, 28, 27])\n",
      "tensor([ 7, 29, 22, 23, 18, 41, 11, 46, 49,  5, 49, 28, 13,  0, 32, 11])\n",
      "tensor([27, 26, 19, 12, 17, 27, 32, 37, 48, 26, 31, 18, 21, 41, 26, 20])\n",
      "tensor([36, 45, 37,  6, 19, 39,  1, 42, 16, 11, 47, 34,  9, 46, 14, 34])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([14, 43, 14, 44, 16, 43, 34, 14,  2,  0,  6, 35, 28, 33,  9,  1])\n",
      "tensor([14, 37, 39, 39,  2, 41, 25, 29, 22, 11, 23, 19, 15,  9, 41, 10])\n",
      "tensor([ 3,  5, 44, 21, 35, 45, 46,  9, 20,  4, 12, 45, 30, 39, 38, 41])\n",
      "tensor([23, 47,  7, 45, 46, 49, 23, 28, 21,  5,  2,  9, 14, 40,  2,  4])\n",
      "tensor([43,  1,  0,  4, 46,  2,  4, 22, 25, 20, 44, 24, 26, 44, 29, 49])\n",
      "tensor([49, 48, 44, 35, 23,  3,  7, 17, 10,  9, 36, 18, 30, 13, 10, 33])\n",
      "tensor([39, 10, 43, 31, 19, 20, 19, 12, 48, 22, 10, 28, 21, 17,  5, 42])\n",
      "tensor([38, 23, 46, 46, 38, 48, 10,  2, 12,  2, 49, 30, 45, 26,  0,  1])\n",
      "tensor([19, 25, 22, 32, 33, 12, 35,  2, 30, 27, 46, 23, 25, 13, 19, 34])\n",
      "tensor([23, 33, 39, 21, 46,  9,  3,  2, 36, 24,  2, 34, 35, 32, 40, 28])\n",
      "tensor([39, 39, 41, 32, 29,  6,  2, 40, 43, 21, 46, 26, 17,  6, 41, 33])\n",
      "tensor([37, 23, 34,  2, 46, 21, 24, 15,  3, 16, 37,  1, 40, 32, 46, 17])\n",
      "tensor([19, 37, 12, 32, 34, 43, 28, 36,  0, 31, 45,  0, 33, 30, 41, 12])\n",
      "tensor([33, 23, 31, 29, 31, 45, 43, 46, 34, 29, 16, 35, 32, 46, 39, 20])\n",
      "tensor([33,  4, 19, 29, 39, 33, 30, 12,  2,  7, 23, 16, 18, 35, 33, 22])\n",
      "tensor([35, 16, 41,  5, 44, 43, 21, 10, 26, 20, 16, 45,  6, 13, 29, 24])\n",
      "tensor([ 5, 46, 39, 34, 16, 15, 25, 22, 40, 16, 24, 48, 10, 48, 45, 26])\n",
      "tensor([17, 16,  2,  3,  6, 11, 28, 31, 18, 38, 42, 13, 41,  3, 10, 25])\n",
      "tensor([36, 29, 32, 22,  0, 10, 27, 11, 42, 28, 13,  6,  7, 18,  3, 20])\n",
      "tensor([ 4, 35, 15, 17, 36, 32, 40, 49, 49, 14, 13,  7, 25,  7, 23, 16])\n",
      "tensor([17, 42, 23, 24, 19,  1,  0, 36, 19, 46, 10, 30, 45, 24, 37,  4])\n",
      "tensor([23, 38,  1, 36, 17, 27, 34,  6, 25, 20, 20, 11, 20,  3,  4, 25])\n",
      "tensor([11, 42, 16, 35, 34, 29, 30, 23, 21, 24, 36, 31, 21, 30, 33, 16])\n",
      "tensor([14, 24, 18, 49, 33, 17, 33, 10, 42, 24, 13, 46, 28, 31,  4, 36])\n",
      "tensor([26, 38, 16, 30, 11, 36, 36, 42, 12, 48, 30, 24,  0, 26, 35, 11])\n",
      "tensor([13, 15,  9, 13, 20, 44, 24, 16, 48, 40, 15, 22, 34, 43, 39, 49])\n",
      "tensor([13, 17, 14,  4, 10, 10, 43, 13, 36, 42, 20,  4,  0, 29, 35, 43])\n",
      "tensor([21, 36, 12, 11, 36, 13, 26, 14, 44, 49, 41, 29, 18,  3, 18, 12])\n",
      "tensor([21, 42, 40, 28, 35, 38,  9, 15, 19, 47,  1,  6, 28, 35, 32, 40])\n",
      "tensor([ 2, 34,  3,  0,  6, 48, 38, 24, 22, 14, 21, 38,  2, 46, 29, 35])\n",
      "tensor([33, 36, 10, 22, 23, 16,  6, 26, 35, 47, 39, 36, 48,  9,  7, 41])\n",
      "tensor([45,  3, 28, 36,  4, 35, 28, 11, 26, 31, 28,  8, 27, 33, 14,  2])\n",
      "tensor([13, 30, 46, 35, 14, 36, 11, 41, 19, 29,  0,  7, 17, 38, 46,  4])\n",
      "tensor([49, 17, 20,  7, 43, 31,  0, 41, 24,  1, 12, 12, 14, 35, 42, 11])\n",
      "tensor([29, 47, 33, 47, 24, 26, 43, 41,  6, 32, 24, 39, 38, 36, 33, 30])\n",
      "tensor([36,  8, 24,  0, 33, 44, 31,  3, 25, 48, 45, 48, 47, 27, 41, 38])\n",
      "tensor([ 9, 32, 16, 21, 49, 27, 15, 11, 13, 20, 39, 23, 35, 28,  5, 29])\n",
      "tensor([ 7,  4, 34, 24, 35, 38,  1, 23, 46,  4, 15, 17, 43, 39, 28, 22])\n",
      "tensor([11, 11, 41, 40, 10, 41, 49, 48, 10, 27, 44, 21,  3, 24, 46,  1])\n",
      "tensor([44, 17, 37, 42, 26, 38, 31, 43, 29, 15, 12, 27, 16,  1,  2, 39])\n",
      "tensor([ 5, 45, 43,  8, 25, 41, 14, 20, 32, 48,  1, 12, 16, 13, 44, 35])\n",
      "tensor([36,  8, 25, 15, 13,  6,  0, 39, 34, 49,  5, 30, 28, 13, 18, 36])\n",
      "tensor([12, 49, 11, 18,  3, 49, 39, 17,  2,  3, 31, 43, 13, 11,  2, 22])\n",
      "tensor([38, 27, 17, 13, 21, 38,  4, 28, 21, 26, 39, 15, 45, 16, 32, 34])\n",
      "tensor([ 3,  9, 26, 42, 26, 36, 15, 42,  7, 35, 18, 16, 39, 14, 15, 36])\n",
      "tensor([ 1, 46, 18, 20, 33,  7, 23,  1, 22, 47, 16, 38, 35, 32, 20, 31])\n",
      "tensor([ 9, 14, 32, 37, 49, 49, 14, 31,  9,  0, 42,  4, 10, 40, 11, 19])\n",
      "tensor([18,  2, 25, 30,  1, 23, 26, 47,  4,  4, 25, 49, 13,  8,  3, 13])\n",
      "tensor([47, 11,  1, 14, 48, 43, 49, 22, 33, 32, 37, 49, 10, 24, 31,  5])\n",
      "tensor([13, 46, 33, 48, 47, 12, 44,  5, 41, 15,  1, 28, 38,  5,  0,  3])\n",
      "tensor([15, 14, 16, 19, 41, 27, 27, 19, 24, 25, 16, 33, 14, 25, 11,  6])\n",
      "tensor([40, 22, 20,  5, 44, 49,  0, 31,  9,  0, 45, 42, 21, 31, 11, 44])\n",
      "tensor([30, 18,  7, 46, 16, 42, 37, 20,  7,  1, 35, 46, 40, 47, 43, 32])\n",
      "tensor([38, 12, 12, 20, 26, 15, 32, 11, 22, 26, 18, 48,  0, 35, 33, 29])\n",
      "tensor([20,  0, 22,  1, 23,  7, 24, 37, 16,  8, 25, 30, 47, 30, 19,  5])\n",
      "tensor([ 5, 44, 35, 38, 27, 45, 42, 11, 32,  6, 23, 30, 22,  9, 11, 49])\n",
      "tensor([42, 35,  3, 10, 15, 35, 39, 24, 32, 41, 21, 44, 10,  9,  3, 35])\n",
      "tensor([44,  2,  4, 21, 31,  2, 41,  0, 47,  2, 22,  6, 36, 23,  5, 44])\n",
      "tensor([17, 39, 11, 29, 19, 23, 24,  5,  3, 21, 35, 14, 28, 31, 30, 32])\n",
      "tensor([15, 40,  6,  5, 19, 37,  8, 37,  3, 31, 34, 18, 43,  0, 34,  5])\n",
      "tensor([38, 17, 48, 40,  6, 41,  0,  5, 18, 30, 33, 44,  0, 32, 39, 41])\n",
      "tensor([13, 21, 43, 45, 11,  7, 27, 34, 48, 33, 45, 40,  7, 14, 16, 18])\n",
      "tensor([47, 16,  6, 27, 11, 43, 26, 49, 22, 45, 45, 46, 49, 49, 28,  7])\n",
      "tensor([49, 21, 17, 23, 38, 22, 40, 27, 17, 32,  0, 21, 44, 44, 28, 46])\n",
      "tensor([11, 44, 33, 48, 28, 13, 13, 39, 22, 16, 45, 33, 24,  4, 21, 20])\n",
      "tensor([11, 21, 11, 25, 40, 29,  5, 20,  7, 42,  4, 38,  3, 20, 17, 48])\n",
      "tensor([ 0, 32, 21, 47, 35, 35, 33, 10, 15, 49,  9, 26, 29, 35, 23,  3])\n",
      "tensor([31, 45, 43, 23, 26,  6,  6, 40, 35, 10, 46,  8,  8, 41,  5, 26])\n",
      "tensor([17, 13, 30, 27,  9, 19,  0, 26, 41, 40, 44, 18, 18, 10, 22, 29])\n",
      "tensor([ 1, 23, 45, 39, 45, 19, 38, 34, 38,  3, 43,  8, 46, 37, 48, 17])\n",
      "tensor([21,  3,  6, 35,  7, 12, 28, 39, 13, 16, 48,  2, 14, 28, 15, 33])\n",
      "tensor([36, 28, 46, 44, 24, 39, 39, 12, 16, 31,  5, 31, 26, 40, 24, 48])\n",
      "tensor([24, 49, 35,  2, 49, 26, 40, 42, 35, 30,  2,  2,  1, 49,  0, 11])\n",
      "tensor([36, 25, 22, 33, 17, 19,  1, 39, 35, 18, 45, 27, 16, 18, 27,  3])\n",
      "tensor([45, 23,  3, 20, 45, 16, 16,  2, 37, 14, 14, 20, 34, 25, 49, 42])\n",
      "tensor([32, 10, 26, 30, 36, 26, 32, 18,  5, 38, 36, 49, 38, 14, 20, 13])\n",
      "tensor([15, 20, 33, 29,  8, 36, 14, 27, 36, 48, 25,  8,  6, 25, 24, 49])\n",
      "tensor([36, 48, 40, 39, 12,  3,  4, 49, 13, 34, 38, 25, 14, 33, 19, 46])\n",
      "tensor([ 5,  9, 19, 27, 35,  1, 16, 25, 32,  0, 46, 28, 46, 15, 29, 41])\n",
      "tensor([14, 43, 39, 36, 41,  9, 11,  0, 41, 18,  1, 42, 18, 44, 48,  0])\n",
      "tensor([ 8, 14, 41, 37, 49, 31,  5, 14, 44, 25,  7, 38, 38,  3, 16, 41])\n",
      "tensor([27, 37,  8, 17, 21, 37, 32, 47,  2, 33, 37,  6, 12, 14,  5, 41])\n",
      "tensor([ 1, 24, 39,  1, 31, 13,  2, 18, 11,  9, 38, 20,  8, 25, 17, 45])\n",
      "tensor([ 8, 38, 37, 13, 10, 36, 13, 10, 19,  0, 39, 16, 40, 10, 29,  8])\n",
      "tensor([42,  2,  5, 26,  0, 32, 44, 11, 36,  5, 34, 14, 36, 26, 33, 49])\n",
      "tensor([30, 39, 27,  7, 37, 28,  6,  9, 23, 40, 24,  2, 34,  6, 18, 35])\n",
      "tensor([16,  9, 23, 27, 11, 15, 37, 20, 44, 48, 24, 47, 33, 15, 40, 26])\n",
      "tensor([18, 12,  4, 39, 15, 22, 12,  6,  1, 27, 29, 14, 16, 22, 29, 26])\n",
      "tensor([13,  8, 39, 33,  7, 45, 42, 16,  1,  6, 25, 49, 45, 16, 18, 46])\n",
      "tensor([22, 13,  0, 32, 45, 16,  4,  5, 35, 30, 38,  5, 45, 19,  5, 20])\n",
      "tensor([14,  0, 14, 18,  8,  4,  2, 43, 17, 48, 48, 45, 49, 18, 21,  8])\n",
      "tensor([26, 24, 15,  2, 42, 18, 18, 47, 33, 30, 21, 47, 21, 23, 18, 33])\n",
      "tensor([23, 15,  6, 16, 14,  8, 32, 37,  9,  5, 34, 40, 31, 18, 15,  5])\n",
      "tensor([46, 10, 21, 38, 25, 37, 30, 35, 45,  5, 10, 20, 41, 30, 29, 44])\n",
      "tensor([25,  9, 29, 36, 35, 38,  3, 40, 10, 25, 19, 22, 15, 20, 31,  2])\n",
      "tensor([25, 38,  1, 14, 36,  9, 34,  1, 35, 13, 12,  2, 17, 14, 42, 32])\n",
      "tensor([ 9, 49, 15, 46, 49, 26, 24, 47, 42, 34, 36, 13, 28, 12, 42, 41])\n",
      "tensor([10, 33, 12, 47, 10, 35, 12,  0, 12, 27, 29, 40, 32, 45, 20, 31])\n",
      "tensor([11,  6, 46, 32, 26, 17, 43,  3, 12,  0, 29, 20, 14,  2, 30, 44])\n",
      "tensor([36, 23, 10, 35, 24, 14, 29, 34,  3, 26, 12, 39,  9,  8, 21, 28])\n",
      "tensor([31, 35, 26, 10, 34,  8, 31, 41,  7, 27, 39, 38,  5, 36, 25,  1])\n",
      "tensor([10, 33, 18, 24, 26, 27, 15, 43, 19, 37, 11, 10, 41, 17, 14, 47])\n",
      "tensor([11,  1, 32, 37,  4, 24, 38, 26, 48, 24, 48, 36, 24, 10, 23,  5])\n",
      "tensor([32, 35, 17, 28, 34, 26,  5, 41, 48, 38, 37,  6, 41, 44, 30, 35])\n",
      "tensor([18, 31, 10, 13, 32, 33, 20, 45, 10, 31, 14,  5, 38,  8,  7, 19])\n",
      "tensor([49, 18, 27, 39, 26,  2, 16, 31, 30, 49, 40, 29, 44, 19, 10,  4])\n",
      "tensor([ 3, 32, 34, 38, 24, 32,  3, 27, 38, 46, 37,  4, 26, 17,  3, 12])\n",
      "tensor([ 9, 22, 27, 11,  2, 45, 31, 44, 48, 32, 18,  4, 39, 24, 27, 16])\n",
      "tensor([34, 21, 20, 47, 21, 48, 18, 14, 35,  6,  8, 30, 27, 45, 14, 15])\n",
      "tensor([11, 34,  8, 27, 14, 21, 33, 35, 19, 15, 16,  4, 35, 30, 11, 26])\n",
      "tensor([ 2, 43, 40, 10, 39, 33, 44, 25,  0, 39, 38, 25,  2, 22,  4, 38])\n",
      "tensor([37,  6, 14, 16, 27, 30,  9, 29, 20, 20, 23, 31, 17, 49, 10, 46])\n",
      "tensor([19, 47, 14, 21, 36,  8, 24,  6, 31, 13, 20,  2, 38, 21, 16, 10])\n",
      "tensor([ 7,  3, 40, 38,  6, 45,  7, 16, 23, 19, 34,  6,  2, 27, 25, 31])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7, 14, 43,  6, 46, 43, 34,  9, 36,  9, 45, 27, 33, 11, 16, 41])\n",
      "tensor([27, 14, 14, 32,  2,  2,  3, 27, 13, 41, 35, 43,  1, 15,  6, 38])\n",
      "tensor([13, 22, 26, 13, 21,  3, 43, 49, 47, 36,  5, 47, 35, 30, 25, 24])\n",
      "tensor([ 4, 34, 49,  6, 24, 10, 11, 28, 44, 23, 18, 20, 39, 27, 41,  9])\n",
      "tensor([13, 24,  0, 29,  1, 14, 11,  5, 30,  7, 23, 27, 36, 13, 24, 43])\n",
      "tensor([25,  0,  7, 12, 36, 47, 11, 39, 10,  0, 43, 12, 35, 45, 37, 42])\n",
      "tensor([11, 46,  1, 41, 20, 16, 31, 43, 28, 34,  0,  2, 16, 21, 14, 42])\n",
      "tensor([13, 26,  4, 24, 38, 11, 37, 39, 18,  7, 40,  6, 49, 37, 26, 45])\n",
      "tensor([49, 19, 38,  9, 39,  4,  5, 45, 30, 19, 34, 20, 14, 12,  6, 39])\n",
      "tensor([20, 12,  3, 12, 21, 36, 28,  6, 36, 20, 30, 34, 27, 25, 35, 18])\n",
      "tensor([26, 32, 36,  4, 44, 32, 27, 19, 30, 25, 41, 29,  6, 18, 36, 40])\n",
      "tensor([26,  4, 46,  6, 13, 11, 11, 49, 18, 47, 10, 14,  9, 16, 11,  9])\n",
      "tensor([21, 16, 15, 27, 13, 11, 17, 39,  1, 21, 38, 48, 27, 16, 18, 19])\n",
      "tensor([13, 21, 20, 16,  6, 25, 13, 20, 28,  5,  5, 24, 47, 18, 18, 48])\n",
      "tensor([ 0, 16, 45, 34, 40, 23, 13, 31,  7, 43, 45, 40, 19,  2,  5, 28])\n",
      "tensor([49, 12, 24, 29, 13, 19, 15, 44, 28, 35, 38, 20, 49, 33, 36, 40])\n",
      "tensor([48,  6, 30, 22, 42, 28, 26,  8,  4, 28, 26, 28, 23, 10, 46, 26])\n",
      "tensor([26,  1, 27, 44, 19,  6, 40, 38, 31, 27, 10,  5, 40,  0,  8, 23])\n",
      "tensor([ 1, 37, 35, 12, 15, 14,  5, 27, 16, 44, 20,  7, 18, 26, 45,  7])\n",
      "tensor([32, 26, 44,  8,  8, 32, 12, 24, 42,  0, 48,  6, 11, 20, 22, 41])\n",
      "tensor([35, 25,  9,  7, 35, 23, 40,  4, 13, 44, 47, 48, 19, 34, 49, 10])\n",
      "tensor([22,  0,  5, 36, 38, 29, 26, 25, 25,  7, 44,  2, 23, 47, 37,  3])\n",
      "tensor([11, 16, 17, 33, 13, 15, 27,  1, 48,  6, 43, 11, 37, 21, 25,  9])\n",
      "tensor([19,  3,  3, 36, 45,  2, 32, 24, 15, 38, 46,  2, 21, 33, 41, 38])\n",
      "tensor([43, 37, 30, 16, 49, 37, 30, 23, 33, 11, 34, 38, 11,  2, 22, 29])\n",
      "tensor([26,  9, 28, 44, 35, 44, 26,  7, 49, 12, 13, 35, 12, 42, 11, 47])\n",
      "tensor([32, 21,  8, 41, 27,  8, 49, 26, 26,  2, 28, 27,  1, 39,  7, 36])\n",
      "tensor([29, 22, 12, 27, 32, 23, 45, 25, 23,  0, 10, 29, 45, 11, 49, 43])\n",
      "tensor([32, 36, 16, 32,  2, 21, 34, 34,  2, 37, 32,  2, 20, 11, 28, 11])\n",
      "tensor([14, 39,  4, 46,  2, 45, 13, 49,  9, 22, 14, 45, 44, 34, 30, 32])\n",
      "tensor([38, 34, 39])\n"
     ]
    }
   ],
   "source": [
    "# cnn2fft\n",
    "# check PyTorch versions\n",
    "# import standard PyTorch modules\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"3\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# calculate train time, writing train data to files etc.\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scipy\n",
    "import scipy.fft\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)     # On by default, leave it here for clarity\n",
    "# torch.cuda.current_device()\n",
    "\n",
    "# Helper class, help track loss, accuracy, epoch time, run time, \n",
    "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
    "\n",
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs\n",
    "\n",
    "class RunManager():\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    # tracking every epoch count, loss, accuracy, time\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "    \n",
    "    self.epoch_val_loss = 0\n",
    "    self.epoch_val_num_correct = 0\n",
    "    self.epoch_start_time = None\n",
    "\n",
    "    # tracking every run count, run data, hyper-params used, time\n",
    "    self.run_params = None\n",
    "    self.run_count = 0\n",
    "    self.run_data = []\n",
    "    self.run_start_time = None\n",
    "\n",
    "    # record model, loader and TensorBoard \n",
    "    self.network = None\n",
    "    self.loader = None\n",
    "    self.vloader = None\n",
    "    self.tb = None\n",
    "\n",
    "  # record the count, hyper-param, model, loader of each run\n",
    "  # record sample images and network graph to TensorBoard  \n",
    "  def begin_run(self, run, network, loader,vloader):\n",
    "\n",
    "    self.run_start_time = time.time()\n",
    "\n",
    "    self.run_params = run\n",
    "    self.run_count += 1\n",
    "\n",
    "    self.network = network\n",
    "    self.loader = loader\n",
    "    self.vloader = vloader\n",
    "    self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "    images, labels = next(iter(self.loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    self.tb.add_image('images', grid)\n",
    "    self.tb.add_graph(self.network, images)\n",
    "\n",
    "  # when run ends, close TensorBoard, zero epoch count\n",
    "  def end_run(self):\n",
    "    self.tb.close()\n",
    "    self.epoch_count = 0\n",
    "\n",
    "  # zero epoch count, loss, accuracy, \n",
    "  def begin_epoch(self):\n",
    "    self.epoch_start_time = time.time()\n",
    "\n",
    "    self.epoch_count += 1\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "\n",
    "  # \n",
    "  def end_epoch(self):\n",
    "    # calculate epoch duration and run duration(accumulate)\n",
    "    epoch_duration = time.time() - self.epoch_start_time\n",
    "    run_duration = time.time() - self.run_start_time\n",
    "\n",
    "    # record epoch loss and accuracy\n",
    "    loss = self.epoch_loss / len(self.loader.dataset)\n",
    "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "    \n",
    "    vloss = self.epoch_val_loss / len(self.vloader.dataset)\n",
    "    vaccuracy = self.epoch_val_num_correct / len(self.vloader.dataset)\n",
    "\n",
    "    # Record epoch loss and accuracy to TensorBoard \n",
    "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "    \n",
    "    # Record epoch loss and accuracy to TensorBoard \n",
    "    self.tb.add_scalar('vLoss', vloss, self.epoch_count)\n",
    "    self.tb.add_scalar('vAccuracy', vaccuracy, self.epoch_count)\n",
    "\n",
    "    # Record params to TensorBoard\n",
    "    for name, param in self.network.named_parameters():\n",
    "      self.tb.add_histogram(name, param, self.epoch_count)\n",
    "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "    \n",
    "    # Write into 'results' (OrderedDict) for all run related data\n",
    "    results = OrderedDict()\n",
    "    results[\"run\"] = self.run_count\n",
    "    results[\"epoch\"] = self.epoch_count\n",
    "    results[\"loss\"] = loss\n",
    "    results[\"val_loss\"] = self.epoch_val_loss\n",
    "    results[\"val_accuracy\"] = self.epoch_val_num_correct\n",
    "    results[\"accuracy\"] = accuracy\n",
    "    results[\"epoch duration\"] = epoch_duration\n",
    "    results[\"run duration\"] = run_duration\n",
    "\n",
    "    # Record hyper-params into 'results'\n",
    "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "    self.run_data.append(results)\n",
    "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "\n",
    "    # display epoch information and show progress\n",
    "    clear_output(wait=True)\n",
    "    #display(df)\n",
    "\n",
    "  def track_vloss_vacc(self, loss, acc):\n",
    "    # multiply batch size so variety of batch sizes can be compared\n",
    "    self.epoch_val_loss = loss.item()\n",
    "    self.epoch_val_num_correct = acc\n",
    "    \n",
    "    \n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "  def track_loss(self, loss):\n",
    "    # multiply batch size so variety of batch sizes can be compared\n",
    "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "  # accumulate number of corrects of batch into entire epoch num_correct\n",
    "  def track_num_correct(self, preds, labels):\n",
    "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def _get_num_correct(self, preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "  \n",
    "  # save end results of all runs into csv, json for further a\n",
    "  def save(self, fileName):\n",
    "\n",
    "    pd.DataFrame.from_dict(\n",
    "        self.run_data, \n",
    "        orient = 'columns',\n",
    "    ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(torch.cuda.get_device_properties(device),torch.cuda.set_device(device),torch.cuda.current_device())\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "#input_size\n",
    "#num_classes = 50\n",
    "#learning_rate = 0.00005\n",
    "BATCH_SIZE = 32\n",
    "epochs = 1\n",
    "\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    exp='6',\n",
    "    lr = [0.0005],#,0.001,0.0001,0.00001], # 0.001\n",
    "    batch_size = [BATCH_SIZE], # 1000\n",
    "    shuffle = [True] # True,False\n",
    "    # Optimizer = [Adam,NAdam,RMSProp,Adamax,SGD,Adagrad,Adadelta]\n",
    ")\n",
    "\n",
    "TRAIN_DATA_PATH = \"./datax/\"+rep+\"/train/\"\n",
    "TEST_DATA_PATH = \"./datax/\"+rep+\"/test/\"\n",
    "\n",
    "transform = transforms.Compose([    \n",
    "    transforms.Resize(299), # preffered size for network\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True,  num_workers=4)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=True,  num_workers=4)\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "\n",
    "#prepare model\n",
    "model_name = 'inceptionresnetv2' # could be fbresnet152 or inceptionresnetv2\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "model.last_linear = nn.Identity() #freeze the model\n",
    "#num_ftrs = model.last_linear.in_features\n",
    "#model.last_linear = nn.Linear(num_ftrs, 50)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad =False\n",
    "    \n",
    "#num_ftrs = model.last_linear.in_features\n",
    "\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "#model.fc = nn.Linear(num_ftrs, 50)\n",
    "\n",
    "PATH = \"models/IRv2.pt\"\n",
    "\n",
    "torch.save(model,PATH)\n",
    "#model = torch.load(PATH)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "def train(model,loader,epochs=60):\n",
    "    model.to(device)\n",
    "    model.train()   \n",
    "    print('Training...')\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        m.begin_epoch()\n",
    "        running_loss=0\n",
    "\n",
    "        for i,batch in enumerate(loader,0):\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                preds = model(images)\n",
    "                loss = F.cross_entropy(preds, labels) # Adam, SGD, RSPROP\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = Variable(loss, requires_grad = True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss+=loss.data\n",
    "\n",
    "                if i%10==9:\n",
    "                    end=time.time()\n",
    "                    #print ('[epoch %d,imgs %5d] time: %0.3f s'%(epoch+1,(i+1)*4,(end-start)))\n",
    "                    print ('[epoch %d,imgs %5d] loss: %.7f  time: %0.3f s'%(epoch+1,(i+1)*4,running_loss/100,(end-start)))\n",
    "                    #tb.add_scalar('Loss', loss, epoch+1)\n",
    "                    start=time.time()\n",
    "                    running_loss=0    \n",
    "    \n",
    "\n",
    "train(model,train_data_loader)\n",
    "\n",
    "\n",
    "print('Extracting Features...')\n",
    "feat,lbls = extract_features(model,train_data_loader)\n",
    "# randomforest, logisticregression, SVM , KNN, LD,  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43, 25, 13,  1, 30, 28, 24,  0, 31, 20,  2, 22, 13, 32, 18, 49])\n",
      "tensor([ 2, 24, 45, 45, 44, 14, 34, 43, 11, 28, 27,  6, 22,  6, 43, 22])\n",
      "tensor([49,  1,  6, 14, 41, 36, 44, 26, 32, 35, 49,  0, 23,  9, 48, 21])\n",
      "tensor([26, 16,  3, 19, 33, 40, 39,  1, 25,  4, 18, 26, 45, 15, 41,  4])\n",
      "tensor([ 6, 24,  6, 41, 11, 28, 20,  0,  0, 46, 43,  3, 11, 44, 46, 33])\n",
      "tensor([ 2,  5, 14, 14, 43, 23, 36, 33,  7,  8, 13,  7, 42, 38, 33, 49])\n",
      "tensor([ 6, 27, 34, 23, 28, 34,  8, 22,  5, 22, 22, 15, 28, 46, 28,  0])\n",
      "tensor([43,  5,  2, 35,  3, 29, 12, 41, 36, 14, 34, 46, 40, 41, 14, 41])\n",
      "tensor([29, 32,  6, 21, 15, 28, 21, 30,  3, 26, 32, 28,  8,  9, 21,  0])\n",
      "tensor([21, 31, 16,  1, 48, 47, 17, 36, 43, 13,  6, 35, 33, 42, 26, 34])\n",
      "tensor([25, 37, 26, 18,  0, 49, 25, 12, 38, 43, 13, 32, 18,  4,  5, 23])\n",
      "tensor([45, 45, 36, 24, 22, 21, 26, 28, 26, 47, 23,  2, 18, 42,  9, 35])\n",
      "tensor([32,  2, 16,  1, 11, 32, 19, 22,  1,  8, 17, 44, 26, 38, 23,  2])\n",
      "tensor([ 5, 39, 45, 45, 41, 11,  7,  2,  4, 18, 21, 37, 19, 34, 19, 48])\n",
      "tensor([49, 13, 21, 43, 34, 41, 33, 42, 40, 11,  6, 38, 11,  5,  7, 43])\n",
      "tensor([41, 13,  1, 12, 37, 22, 34,  8, 25, 26, 49, 18, 43,  9, 21, 31])\n",
      "tensor([37, 44,  8, 23, 21, 26, 13, 10,  2, 31,  6, 43, 30, 24, 16, 33])\n",
      "tensor([24,  9, 14,  3, 20, 43, 48, 32,  0, 46, 22, 39, 27,  1, 19, 33])\n",
      "tensor([10, 18, 48, 27,  8, 20, 46, 21, 34, 34, 11,  6, 16, 26, 44, 32])\n",
      "tensor([41, 11, 14, 29, 39, 38, 32, 25, 13, 38, 42,  6, 49, 11, 19, 13])\n",
      "tensor([11, 14, 23, 10,  5, 32, 20, 14,  3, 44, 46, 27, 27, 17, 46,  6])\n",
      "tensor([23, 39, 39, 22,  6,  8, 38, 24, 36, 45, 28, 18,  0, 39, 38, 29])\n",
      "tensor([ 9, 44, 33,  4, 37,  9, 44, 37,  5, 36, 20, 45, 35, 34,  5, 48])\n",
      "tensor([15, 16, 44, 47, 38, 40, 14, 36, 27, 42, 26, 49,  8, 28, 17, 47])\n",
      "tensor([10, 45,  0, 24, 38, 35, 18, 25, 41, 11, 38, 23, 29, 48,  7, 33])\n",
      "tensor([35, 24, 27, 34, 36, 18, 13, 26,  5, 23, 21, 46, 16, 36, 11,  4])\n",
      "tensor([44, 44, 43, 14, 15, 48, 35,  6, 35,  4,  3,  4, 30, 39, 38, 27])\n",
      "tensor([31, 39, 47, 16, 35, 23, 24, 35, 41, 38,  4, 39, 34,  4, 43, 44])\n",
      "tensor([15, 37, 10,  8,  9, 28, 45, 37, 24, 24, 22, 10, 48, 36, 29,  6])\n",
      "tensor([49, 27, 48, 35, 25, 34,  1, 12,  8,  1, 15, 30, 36, 14, 15, 38])\n",
      "tensor([16,  1, 20, 23, 45, 35,  8, 29, 42, 23, 17, 25, 10,  0, 20, 14])\n",
      "tensor([31, 13, 30, 30,  3,  3,  7, 38, 34, 21, 39, 36, 10, 33, 29, 39])\n",
      "tensor([13, 16, 19,  5, 20, 47,  9, 41, 37, 44, 19, 11,  2, 42, 10, 18])\n",
      "tensor([35, 18, 18, 27,  5, 47, 21,  7, 13,  3, 13, 26, 31, 21, 16, 22])\n",
      "tensor([45, 39,  8, 47,  3, 12, 31, 38, 48, 49, 35, 25, 27,  2, 17,  5])\n",
      "tensor([48, 16,  9,  1, 16,  8, 48, 10, 31,  5, 38, 28, 23, 13, 32, 11])\n",
      "tensor([19, 16, 37, 15, 21,  7, 23, 34, 12, 20,  9, 16, 34, 33, 32, 46])\n",
      "tensor([37, 28,  4, 45,  0,  4, 38, 26, 13, 35,  2,  5, 41, 29,  3, 45])\n",
      "tensor([32, 32, 37, 39, 14, 28, 24,  2,  9, 38,  9, 13, 39,  0, 22, 29])\n",
      "tensor([30, 13, 39, 48, 41, 35, 10, 47, 27, 32, 11, 17,  9, 16, 43,  2])\n",
      "tensor([22, 19, 32, 19,  8, 13,  5, 38, 16, 29,  1, 35, 32,  0,  4, 22])\n",
      "tensor([40, 38, 34, 19, 48, 41,  0,  9,  7, 16,  9, 18, 13, 35, 36, 42])\n",
      "tensor([10, 13, 24, 11, 12, 49, 16, 23, 38,  7,  5, 19,  2, 48, 33,  1])\n",
      "tensor([36, 20, 29, 16, 49,  3, 14, 37, 12, 27, 32, 47,  4, 30, 43, 48])\n",
      "tensor([11, 21,  0, 35, 26, 37, 22, 44, 21, 38, 35, 39, 24, 10, 39, 17])\n",
      "tensor([44, 45,  2, 35, 45, 41, 31, 14, 42, 10, 20, 38, 20,  9, 10, 12])\n",
      "tensor([36, 11, 41, 47,  3, 36, 36,  1, 39, 34, 36, 27, 19, 48, 46, 43])\n",
      "tensor([47, 48,  3, 29, 40, 35, 46, 31,  5, 33, 13, 32, 46, 42,  7,  0])\n",
      "tensor([19, 34, 43, 34,  6,  4, 17, 29, 11,  0, 12, 46, 34,  5, 20, 25])\n",
      "tensor([31,  6, 34, 16, 31, 44,  0, 12, 36, 24, 32, 35, 27,  6, 21, 44])\n",
      "tensor([25, 31, 39,  7, 44, 17, 49, 24, 48,  5, 39, 49, 40, 19, 46, 14])\n",
      "tensor([39, 42, 42, 45, 10, 34,  3, 20,  2, 27, 27, 41, 16, 30, 32, 34])\n",
      "tensor([22, 17,  5,  4, 31, 46,  3, 15, 47, 27, 32, 14,  3, 12, 49, 24])\n",
      "tensor([18, 30, 19,  5, 23, 23, 10, 23, 40,  3, 43, 13, 26, 32, 12,  3])\n",
      "tensor([46, 43, 47, 30, 31, 31, 33, 36,  4, 41, 39, 36,  7, 39, 17, 34])\n",
      "tensor([ 8, 20, 24, 47, 15, 48,  1, 49, 45, 37, 36, 28, 14, 33, 10, 16])\n",
      "tensor([47, 44, 48, 19, 49,  4, 22, 44,  5, 14, 22,  8,  0, 16, 33, 30])\n",
      "tensor([25, 25, 13, 49, 24,  3, 19, 44,  3, 24, 27, 44,  5,  3, 36, 28])\n",
      "tensor([ 4,  2,  1, 37, 46, 33, 16, 28, 27, 43, 15, 19, 30, 45,  6, 12])\n",
      "tensor([14, 11, 12, 23, 46, 42, 16, 14, 17, 32, 20, 32, 45, 48, 13, 37])\n",
      "tensor([ 2, 24,  1, 20, 20, 12, 11, 34, 12, 14, 45, 36, 33, 48, 34,  3])\n",
      "tensor([48, 45, 21, 22, 48,  7,  9, 37, 36, 43, 11, 49, 45, 27, 24, 38])\n",
      "tensor([18, 23, 17, 39, 12, 46, 20, 24, 34, 13, 33, 27, 42, 49, 32, 39])\n",
      "tensor([18, 14, 30, 15, 29, 26, 40, 48, 44, 27, 32, 36,  4, 26, 23, 33])\n",
      "tensor([33, 14, 35, 48, 34, 36, 49, 35, 16, 49, 44, 24, 24, 31, 47, 28])\n",
      "tensor([ 0,  3, 22, 27, 47, 32, 11, 24, 27,  1, 22, 13, 34, 43, 24, 34])\n",
      "tensor([43, 12, 26, 17, 21, 46,  0, 25,  6, 34, 13, 37,  3, 47, 22, 49])\n",
      "tensor([34, 39, 10, 25, 16, 28, 29, 36, 11, 42,  8, 13, 39, 18, 13, 48])\n",
      "tensor([31, 14, 10, 32, 16, 17, 36, 23, 39, 16, 29, 40, 26, 34, 38,  3])\n",
      "tensor([39,  2, 30, 24, 45, 35, 20, 26, 24, 10, 16, 33,  2,  7, 20, 28])\n",
      "tensor([ 2, 11, 32, 49, 33, 10, 36, 27, 20, 20, 23,  1,  3, 31, 27, 26])\n",
      "tensor([18, 13, 29, 33, 43, 21, 28, 31, 48, 16, 27,  0, 40, 45, 25, 45])\n",
      "tensor([47,  6, 27, 30, 11, 43, 10, 28, 19, 20, 16, 49, 17,  3, 16, 46])\n",
      "tensor([31, 48, 10, 37, 46,  0, 10, 25, 41, 14, 28,  4, 10, 17, 29,  7])\n",
      "tensor([29, 41, 16,  8,  6, 22, 41, 47, 38, 23,  2,  2, 13, 26, 23, 22])\n",
      "tensor([ 5, 32, 45, 31,  5,  9,  0, 39,  1, 36, 32, 35, 20, 13,  0, 44])\n",
      "tensor([ 0, 36, 36,  0, 41, 25,  9, 22, 30, 44,  9,  0,  0, 47, 10,  5])\n",
      "tensor([37, 15,  6,  1,  3, 49, 33,  6, 31,  9, 27, 38, 27, 16, 14, 40])\n",
      "tensor([ 7,  6, 11, 49, 32, 34, 18, 25, 26,  7, 45, 23, 32, 25, 35, 48])\n",
      "tensor([23, 30, 12, 24, 38, 15, 28,  2, 28, 14, 45, 20,  6, 43, 20, 28])\n",
      "tensor([20, 32, 33, 30, 43, 19, 11, 35, 45, 28, 37,  5, 40,  6, 15, 28])\n",
      "tensor([ 1,  6, 38, 18, 33, 35, 46, 24,  2, 41, 38, 16, 46, 33, 33, 36])\n",
      "tensor([14,  0, 23, 19, 15, 14, 45, 14, 19,  0, 33, 28, 10, 11, 39, 22])\n",
      "tensor([ 3, 46, 22, 43, 27, 27, 47, 11, 12, 41, 41, 36, 48, 30, 15, 16])\n",
      "tensor([28, 34, 27, 42, 17,  1, 12, 17, 32,  1,  5, 40, 34, 35,  6, 23])\n",
      "tensor([21,  9,  6, 35, 11, 35, 44,  3, 27,  1,  3, 17, 29, 33, 43, 49])\n",
      "tensor([34, 28,  1, 19,  9,  8, 39, 38, 44, 46, 42, 18, 44, 17,  1,  0])\n",
      "tensor([32, 21, 38, 48, 31, 11,  7, 24, 40, 25, 35, 16, 23,  4,  0, 28])\n",
      "tensor([10, 39, 23,  5, 49,  5, 24, 10,  7, 26, 20,  6, 36, 35, 19, 35])\n",
      "tensor([44, 11, 43, 25, 18, 40, 44, 35,  0, 14, 33, 23, 45, 31,  2, 24])\n",
      "tensor([39, 40, 26, 19, 29, 25,  7, 12, 18,  0, 36, 17, 46, 46,  4,  6])\n",
      "tensor([13, 10, 44, 30,  2, 33, 16, 36,  4, 11, 21,  4, 43, 22, 14,  6])\n",
      "tensor([41,  3, 10, 39, 25,  8, 30,  7,  9,  7, 13, 48, 20, 40, 30,  3])\n",
      "tensor([ 5, 24, 22, 32, 35, 25, 43,  6,  3, 31, 33,  3, 39,  1, 12, 23])\n",
      "tensor([21, 40, 30, 36, 16, 34, 21, 29, 26, 24, 26, 49, 26,  3, 40, 20])\n",
      "tensor([33, 27, 38, 47, 23, 28, 24, 28, 26, 17, 17, 39, 15, 34,  4, 38])\n",
      "tensor([32, 42,  4, 26, 26, 16, 18, 30, 39,  0,  9, 45, 10,  4, 43, 28])\n",
      "tensor([18, 18, 43, 38, 46,  0, 13, 41, 31, 19, 28, 22,  6, 40, 25, 23])\n",
      "tensor([49, 49, 31, 25, 28, 29,  2, 35, 15, 16, 25, 32, 16, 49, 19, 47])\n",
      "tensor([ 3, 41, 34, 33, 29, 48, 26, 10, 38, 45, 17, 23, 12, 35, 12,  2])\n",
      "tensor([45, 17, 47, 22,  9, 27, 41, 25, 30, 49, 15,  1, 29,  8, 17,  7])\n",
      "tensor([42,  2, 21, 32,  6, 32, 15, 40, 35, 32, 39, 49, 17, 23, 26,  0])\n",
      "tensor([30, 40, 33,  2, 30, 38,  9, 23, 27,  6, 23, 11, 27, 15, 20,  9])\n",
      "tensor([ 4, 49, 31, 33, 38, 12, 41, 12, 10, 16, 24, 32, 14, 38, 34, 27])\n",
      "tensor([49, 14, 43, 28, 38, 46, 21, 31, 37, 29,  8, 46,  7, 26, 28,  1])\n",
      "tensor([23, 36,  8, 18, 46, 32, 47,  8, 15, 15, 31, 28, 18,  9,  9, 25])\n",
      "tensor([16, 17, 39,  1,  7, 45, 35, 27, 33, 26, 29, 40,  2, 32, 11, 19])\n",
      "tensor([15, 19,  3, 39, 26,  1, 13, 36, 10, 22, 11, 11, 46,  7,  5,  6])\n",
      "tensor([20, 49, 48,  3, 31, 21, 48, 36,  6,  4,  7, 37, 27, 16, 35, 25])\n",
      "tensor([10, 15, 36, 39, 26, 18, 41, 10, 39, 23, 18, 17, 23, 35, 22, 22])\n",
      "tensor([10, 12, 48, 12,  0, 19, 26, 37, 42, 39, 47, 26, 14, 23, 48,  6])\n",
      "tensor([ 6,  7, 49,  7, 20,  1, 43,  9,  4, 46, 37, 12, 36, 25, 11, 39])\n",
      "tensor([45, 31, 32, 32, 27, 16, 38, 26, 13, 30, 29, 16, 35, 20, 31, 26])\n",
      "tensor([39, 13, 32, 35, 31, 46, 12,  2, 25, 29, 21, 18, 10,  6,  9, 38])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([35, 10, 40,  1, 40, 19,  0,  2, 15, 42, 38, 45, 29, 11, 43, 11])\n",
      "tensor([26, 36, 41, 41,  7, 30, 11, 31,  8, 46, 16,  4, 44,  5,  0,  9])\n",
      "tensor([20,  1, 43,  8, 25, 27,  5, 32,  9, 21, 30,  1, 38, 38, 11, 40])\n",
      "tensor([11, 26, 16, 36, 44, 30, 26, 17, 19, 29, 29,  3, 24, 24, 47,  7])\n",
      "tensor([10, 30, 25, 17,  0, 34, 13, 34, 36, 27,  2,  5, 28, 19, 22, 33])\n",
      "tensor([15, 35, 22, 29, 36, 12, 16, 37, 10, 25,  1, 26, 13, 32, 36, 15])\n",
      "tensor([45, 24, 21, 21,  9,  3, 28, 14, 37, 20, 41, 29,  0,  7, 20, 46])\n",
      "tensor([46, 24, 31,  2, 41, 49, 19, 31, 48, 39, 32, 33, 14, 45, 15, 36])\n",
      "tensor([12, 27, 12, 11, 44, 38, 18, 19,  5, 10, 16,  4, 34, 19, 11, 11])\n",
      "tensor([34,  0,  4, 15, 13,  7, 11, 22, 18, 39, 17, 27, 34, 43, 14, 10])\n",
      "tensor([43, 36,  4, 11, 48, 30, 15, 21, 25,  1, 21, 21, 19, 45, 29, 45])\n",
      "tensor([13, 29,  7, 30, 16, 20, 49, 20, 48, 23, 44, 32, 16, 35, 35, 45])\n",
      "tensor([ 6, 35, 33, 20, 15, 41, 16, 32, 48, 44, 41,  2, 27, 10, 38, 13])\n",
      "tensor([39,  8,  9, 36, 48,  2, 18, 24, 33, 42,  3,  3,  0, 24, 43, 14])\n",
      "tensor([22, 47, 10, 21, 42, 34, 33, 32, 41, 26, 15, 49,  9, 32, 33, 10])\n",
      "tensor([10, 47, 40, 37, 48, 45, 32, 32, 34, 22,  3, 21, 13, 34, 45, 10])\n",
      "tensor([36, 18, 21, 43, 32, 23,  3, 21,  8, 26, 11, 16, 24, 34, 38, 27])\n",
      "tensor([37, 27, 39,  7, 35,  1, 40, 13, 43, 19, 29, 10, 21, 17, 26, 34])\n",
      "tensor([18,  0,  6, 46, 25,  7, 32, 21, 20,  5, 38, 49,  0, 39, 49, 29])\n",
      "tensor([40, 21, 24, 41, 32, 11, 38, 37, 12, 49, 39, 11,  2, 19, 42,  3])\n",
      "tensor([45, 37,  8, 39, 21, 21, 11, 26, 16, 35, 35, 47, 21, 12, 46, 43])\n",
      "tensor([14, 39, 42, 44, 40, 13, 11, 23, 29, 13, 15,  4, 12,  5, 38, 21])\n",
      "tensor([26, 36, 20, 35, 29,  6, 39,  4, 33, 46, 12, 12, 36,  5, 21, 38])\n",
      "tensor([13,  4,  2, 36, 49,  2,  0,  8, 47,  3, 24, 36,  7,  0, 40, 38])\n",
      "tensor([ 9, 29, 34, 10, 20, 24,  9, 41, 34, 45,  1, 21, 45, 16, 11,  2])\n",
      "tensor([ 2, 46,  5,  3,  8, 30, 13, 13, 34, 29, 36, 24,  9, 39, 41,  9])\n",
      "tensor([43, 42, 26, 41, 49, 41,  7, 29, 10,  6,  6,  1, 26, 30, 19, 34])\n",
      "tensor([11, 32, 34,  2, 11, 33,  0, 17, 48, 26, 13, 23, 39,  2, 22, 26])\n",
      "tensor([40, 40, 44, 11, 21, 38,  0, 33,  5, 10, 18, 31, 26, 49, 24,  5])\n",
      "tensor([21, 19, 20, 42,  3, 12,  5, 14, 43, 19, 13, 47, 18, 18,  7, 24])\n",
      "tensor([38, 18,  0,  8, 32, 24, 14, 26, 10, 17, 40, 48,  7, 22, 40, 38])\n",
      "tensor([21, 19, 49, 18,  1, 29, 14, 46, 23, 11, 46,  3, 14, 12, 33,  3])\n",
      "tensor([ 2,  5, 39, 49,  1, 26,  1, 11, 14, 49, 46, 21, 31, 26, 19, 41])\n",
      "tensor([45,  4, 48, 13, 17, 28,  4, 14, 19,  3, 30, 19, 44, 25, 16, 12])\n",
      "tensor([23, 17, 41,  1, 44,  0, 24, 35, 29,  0, 14, 35, 29, 29, 31, 21])\n",
      "tensor([ 7, 40, 11, 45, 31, 42, 38,  8, 31,  2, 42,  8,  8, 47, 25, 36])\n",
      "tensor([ 9,  7,  7, 33, 27, 23, 26, 42, 42, 37, 14, 31, 36,  2, 32,  0])\n",
      "tensor([33, 17,  3, 42, 28, 26, 36, 49, 13, 45, 36, 20, 32, 29, 11, 43])\n",
      "tensor([24,  2, 31,  6, 24, 31, 49, 38, 24, 11, 33, 42, 10, 29, 42, 44])\n",
      "tensor([11, 44, 10,  6, 18, 20,  5, 22, 45, 20, 28, 26,  0, 33, 36, 22])\n",
      "tensor([28, 14, 34, 36, 15,  5, 22, 44, 10, 12, 32, 12, 49,  2, 26, 42])\n",
      "tensor([30, 12,  3, 44,  3, 18, 48, 23, 36,  0, 14, 44, 49, 39,  6, 44])\n",
      "tensor([16, 48, 34, 19, 45, 49, 37, 39, 17,  6,  5, 13, 34, 14, 16, 38])\n",
      "tensor([ 6,  5,  9,  6, 15, 40, 49, 45, 12, 36, 23, 19,  0, 13, 10, 37])\n",
      "tensor([10, 42, 47, 25, 15, 23,  8, 38, 16, 14,  1,  1, 11, 11, 16, 31])\n",
      "tensor([27,  7, 17, 35, 33, 31, 10, 39, 29, 30, 18,  8, 14, 34, 11, 20])\n",
      "tensor([20, 38,  8, 47, 20,  5, 37,  2, 48, 33, 42, 27, 45, 44, 43, 18])\n",
      "tensor([ 4, 40, 23, 38,  9,  3, 20, 38, 39, 26, 12, 29,  6, 27, 49, 10])\n",
      "tensor([ 7, 10,  1, 16,  9, 38, 26, 29, 18, 41, 11, 27,  2,  1, 27, 38])\n",
      "tensor([39, 48, 30, 12,  1, 32,  2, 47, 22, 21, 42, 33, 23, 33, 14, 42])\n",
      "tensor([28, 40, 14,  3,  6, 18,  7, 42,  8, 35, 14, 46, 32, 18, 48, 16])\n",
      "tensor([29, 16, 19, 37, 34, 41, 31, 27,  9, 49, 21, 16, 24, 49, 14, 25])\n",
      "tensor([21, 32, 16, 32, 18, 13, 40,  5, 15,  0, 21, 45,  5, 11, 29, 16])\n",
      "tensor([33, 41, 42, 12, 33, 10, 22, 38, 36, 28, 36,  6, 15, 34, 24,  2])\n",
      "tensor([16,  6, 44,  2, 46,  6, 17, 12, 20, 29, 11, 33,  8, 33, 16, 23])\n",
      "tensor([26, 24, 36, 11,  5, 13, 15, 30, 29, 36, 34,  1,  3, 21, 25, 26])\n",
      "tensor([38,  4, 33, 31,  5,  3, 12, 20, 11,  7, 42, 15, 11,  4, 36, 38])\n",
      "tensor([42, 34, 34,  0, 43,  4,  7, 34,  0, 12, 40, 26, 47, 49, 16, 20])\n",
      "tensor([32, 13, 23, 36,  9, 10,  2, 21, 27, 48, 18,  0, 13, 43, 12, 49])\n",
      "tensor([45, 27,  2, 11, 27, 24,  5, 45, 35, 11, 49, 17, 48, 36, 19, 30])\n",
      "tensor([49, 18,  9, 14, 41, 13, 15, 34, 47,  0, 42,  5, 47, 13, 27, 11])\n",
      "tensor([10,  4, 19, 41,  7,  8, 12, 28, 49,  6,  0, 19, 46, 21, 36, 12])\n",
      "tensor([23, 15, 13, 36, 22, 24, 38, 47, 18, 45, 12, 47, 40, 34,  0,  0])\n",
      "tensor([42, 45, 40, 21, 39, 46, 10, 36, 41, 19, 27, 41, 47, 14, 31, 40])\n",
      "tensor([20, 14, 10,  7, 27,  1, 14, 24, 10, 17, 43, 29, 40, 49, 44, 12])\n",
      "tensor([12, 26, 11, 28, 15, 47, 23, 15,  3, 35, 38, 45, 24, 19, 19, 31])\n",
      "tensor([25, 34,  1, 23,  6,  5,  1, 16, 28, 28,  9, 14, 12, 41, 37, 34])\n",
      "tensor([21,  1, 38, 10, 23, 46, 45,  4, 33, 39, 36,  1,  2,  4, 20, 27])\n",
      "tensor([ 0, 20,  8, 49,  8, 42, 37,  4, 11, 36, 28, 22, 42, 33, 25, 28])\n",
      "tensor([38, 47, 41, 10, 46, 44, 12,  4,  3, 13,  2,  0, 36, 25, 15,  2])\n",
      "tensor([ 6, 13,  5, 18, 40, 30, 23, 23, 24, 15, 44, 49, 14, 40, 36,  4])\n",
      "tensor([ 5, 41,  4, 19, 11, 21, 18, 36, 25, 49, 27, 39, 39, 31, 15, 23])\n",
      "tensor([ 2, 42, 49, 47,  5, 27, 27, 11, 34, 25, 11, 49, 23,  0, 18, 33])\n",
      "tensor([ 5, 47, 40, 48,  3, 40, 27, 49, 15, 23,  0, 11, 26, 25, 12, 25])\n",
      "tensor([ 8, 41, 28,  5, 34, 20,  4, 18, 17,  6, 22,  8, 21, 28, 49, 18])\n",
      "tensor([41,  4,  0, 15, 38, 20, 26,  5, 32, 16, 27, 47, 18,  2, 38, 37])\n",
      "tensor([ 1, 24, 21, 46, 10, 21, 33, 14, 30, 25, 15, 41,  1, 23, 16, 24])\n",
      "tensor([44,  2, 39, 37, 45, 45, 15, 36, 45,  1, 32, 11, 13,  8,  3, 24])\n",
      "tensor([32, 45, 20, 26, 12, 22, 47,  8, 27, 33, 26, 21, 39, 29, 29,  1])\n",
      "tensor([22, 29,  2, 34, 48, 37, 41, 27, 16,  5, 24, 45, 25, 26,  2,  5])\n",
      "tensor([28, 41, 45,  5, 19,  6, 46, 15, 33,  5, 16, 33, 38, 21, 44, 20])\n",
      "tensor([ 0, 47, 31,  5, 49, 48, 15, 27, 17, 11, 32, 13, 24,  6, 13, 33])\n",
      "tensor([39,  9, 19, 32, 46, 35, 32,  5, 15, 14, 16, 39, 10,  1, 15, 27])\n",
      "tensor([13,  9,  3, 35, 25, 33, 19, 27, 39, 21, 13, 32,  7, 38, 10, 42])\n",
      "tensor([43, 35, 17,  7, 18, 26, 27, 42, 40, 22, 47,  5, 46, 31,  6,  0])\n",
      "tensor([29,  8, 31, 43,  1, 15, 45, 43, 10, 35, 15, 23,  6, 46, 26, 16])\n",
      "tensor([16,  2, 49, 44,  6, 19, 47, 24, 29, 13, 15, 29, 20, 40, 32,  7])\n",
      "tensor([32,  1,  2, 35, 35, 25,  2,  2, 33, 31,  9, 20, 33, 37, 45, 45])\n",
      "tensor([30, 36, 27, 24, 31, 49, 22,  6, 27, 45, 34, 33, 46, 17, 11, 11])\n",
      "tensor([35,  6, 19, 34, 11,  7, 11, 32, 28, 14, 11, 43, 11,  5, 38, 47])\n",
      "tensor([48, 18, 32, 30, 45,  8, 34, 35, 39, 23, 23, 38, 17,  3, 28, 31])\n",
      "tensor([23, 38, 33, 11, 21, 10, 44, 41, 26, 38, 32,  2, 42,  0, 44, 47])\n",
      "tensor([11, 44, 28, 27, 40, 48, 16, 45, 29, 15, 38, 33, 41, 35, 34, 31])\n",
      "tensor([37, 46,  6, 18, 45, 39,  6,  5,  9,  6,  0, 20,  9, 48, 16, 19])\n",
      "tensor([47, 25, 22, 23, 46, 21,  0, 43, 41, 16, 43, 43, 39, 32, 29, 45])\n",
      "tensor([33, 44, 47, 18,  0, 28, 21,  2, 49,  8, 48, 33, 33, 39, 43, 39])\n",
      "tensor([45, 38, 20, 45, 35, 37, 12, 33, 27, 46, 17, 22, 17, 28, 19,  9])\n",
      "tensor([29, 21, 39, 49, 42, 14,  7, 38,  1, 13, 16,  7, 34,  9, 44, 15])\n",
      "tensor([28, 24, 47,  3, 34,  3, 22, 23, 31, 30, 24,  8, 41,  8,  8, 19])\n",
      "tensor([34, 35, 34,  3, 22, 34, 19, 30, 48, 41, 33, 37, 20, 33,  7, 13])\n",
      "tensor([27, 40, 48,  7, 15, 41, 30, 16, 42,  7,  5, 18, 27, 45, 30, 46])\n",
      "tensor([18, 24, 31,  3, 40, 19,  0,  5, 12, 15, 11, 14,  8, 46, 36, 43])\n",
      "tensor([19, 40, 36,  0, 11, 35, 10, 39, 31, 12, 46,  7, 33, 49, 30,  7])\n",
      "tensor([20, 26, 21, 39, 19, 23,  0, 42, 27, 15, 34,  5, 47, 27,  7, 38])\n",
      "tensor([48,  5, 34, 22, 25, 40, 47, 43, 17, 37,  5, 30,  4, 31, 41,  7])\n",
      "tensor([49, 39, 41, 10, 16, 36, 32, 23, 12,  3,  3, 10, 41, 26, 10, 40])\n",
      "tensor([ 9, 21,  1, 15, 11, 23, 10, 38, 28, 25,  0, 15, 20, 19, 47,  1])\n",
      "tensor([ 3, 35, 44, 36, 10,  6, 10, 11, 44,  4, 32, 41, 40, 41, 22, 27])\n",
      "tensor([26, 22, 24, 35, 32, 23,  8, 49,  8,  3, 18,  2, 17, 44,  1, 41])\n",
      "tensor([49,  0, 36,  5, 31, 38, 31, 37,  7, 43, 30, 40, 16,  0,  7, 10])\n",
      "tensor([27,  5, 35,  5, 43, 41, 37, 14, 25, 45, 36, 36,  7,  0, 34, 49])\n",
      "tensor([35,  9, 46, 30, 36, 14, 32, 26, 31, 25, 22, 18, 12, 14, 46, 48])\n",
      "tensor([ 1, 42, 35,  7, 43, 49,  5,  2, 28, 22, 23, 24, 27,  2,  5,  5])\n",
      "tensor([39, 25, 20, 15, 10, 33, 43,  0, 11, 32,  4,  1, 13, 16,  5, 12])\n",
      "tensor([17, 17, 34, 27, 45, 15, 34, 41, 15, 14, 11, 43, 32, 35, 43, 49])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13, 42, 38, 15, 37, 32, 36, 17, 22, 21,  4,  7,  5, 29, 40,  5])\n",
      "tensor([ 8,  8, 27, 39,  2, 22, 30, 39, 41, 36,  1, 12, 19, 21, 45, 13])\n",
      "tensor([34,  0, 32, 46, 25, 48, 47, 35, 32,  3,  2, 17, 45,  7, 49, 24])\n",
      "tensor([ 5, 28, 27, 32, 17, 35,  2, 41, 14, 24,  2,  2, 22, 38, 43, 21])\n",
      "tensor([ 9, 38, 19, 29, 16,  7, 41,  1, 35, 33, 33, 29, 38, 41, 21, 36])\n",
      "tensor([30, 42, 44, 20, 43,  0,  5, 42,  4,  5,  5,  9, 14, 18, 38, 20])\n",
      "tensor([48,  7, 30, 46, 16, 30,  5, 22, 44, 46, 22, 40, 18, 43, 45, 31])\n",
      "tensor([38, 27, 31, 37, 34, 42, 24, 23, 48,  3, 15, 15, 22,  5, 22, 30])\n",
      "tensor([45, 42, 30, 27, 14,  1, 16,  7, 17, 38, 35, 34, 15, 10,  2, 11])\n",
      "tensor([35,  9,  1, 40, 18, 31, 28,  2, 40,  7, 18, 34, 17, 45, 24,  5])\n",
      "tensor([41,  3, 10, 10,  9, 36, 18, 25,  9,  0,  5, 45, 22, 41, 18, 40])\n",
      "tensor([26, 32, 32,  7, 24, 35, 30, 20, 13, 46,  2, 13,  5, 22, 16, 39])\n",
      "tensor([46, 16, 42, 24, 40, 37, 24, 13, 26, 31, 41, 34, 48, 39, 27, 40])\n",
      "tensor([16,  0, 18, 45, 48, 39,  4, 13, 32, 43, 16, 35, 13, 27, 15, 11])\n",
      "tensor([17, 48, 39, 46, 30, 14, 23, 11,  0,  2, 27, 32, 28, 10, 25, 18])\n",
      "tensor([42, 20, 45,  2, 32,  5, 35, 45, 33,  2, 27, 45, 15, 23, 15,  9])\n",
      "tensor([39, 36, 49, 24, 49, 32, 38, 45, 11, 26, 14,  5, 22, 38, 15, 28])\n",
      "tensor([18, 35, 17, 26, 27, 23, 17, 43, 46, 34, 23, 12, 24, 15, 22, 40])\n",
      "tensor([28,  6, 14, 46, 36, 22, 15, 26,  2, 13, 26, 19, 47, 14,  6, 39])\n",
      "tensor([37,  1, 23, 44, 44, 36, 10, 10, 35, 46, 28,  3, 28, 30, 40,  7])\n",
      "tensor([15,  7, 32, 21, 19, 18, 34,  7, 24, 27, 34, 38, 48, 35, 48, 37])\n",
      "tensor([42, 48, 33, 33, 24,  9, 33, 34, 28, 33, 40, 29, 22,  7, 17, 37])\n",
      "tensor([33, 17,  4,  5,  6,  2, 18, 24, 16, 44, 34, 46, 20, 30, 34,  4])\n",
      "tensor([ 5,  7, 33, 49, 13,  1, 21, 37, 41,  4,  7, 29,  6, 14, 41, 15])\n",
      "tensor([26, 44,  8, 16, 26, 22, 35,  4, 13,  4, 38, 22, 30, 30, 27, 33])\n",
      "tensor([38,  8, 23, 32, 20, 26, 35, 16, 19,  4, 19,  5, 36, 20,  2, 35])\n",
      "tensor([29, 23, 42, 30, 48, 29,  1, 15, 34, 13, 34, 34, 38, 39,  8,  2])\n",
      "tensor([17,  8, 10,  0, 41, 14, 35, 28, 37, 44, 27, 36, 18, 23, 22,  6])\n",
      "tensor([23, 20, 23, 35, 22, 18, 30, 29, 48, 37, 30, 22,  3, 38, 16, 26])\n",
      "tensor([20, 34,  7, 43,  8,  7, 30, 25, 10, 34, 17,  0, 19,  9, 22,  5])\n",
      "tensor([29, 13, 49, 10, 28, 35,  2, 39, 25, 40,  9, 31, 10, 31, 42,  2])\n",
      "tensor([28, 41, 37,  0, 44, 14, 22, 29, 49, 17,  7, 12, 15, 26, 19, 26])\n",
      "tensor([ 9, 39, 11, 10, 45,  3, 34, 12, 49,  6, 47, 21, 29,  1, 18, 10])\n",
      "tensor([ 9, 30, 14, 33, 40, 42, 22, 19, 47, 39, 16, 29, 30,  8, 17,  2])\n",
      "tensor([36, 21, 33, 46,  8, 14, 11, 35, 39, 48, 35, 38, 28, 26,  4, 36])\n",
      "tensor([30, 38,  6, 23, 45, 37, 11, 10,  7,  1, 14, 26, 12, 27, 43,  4])\n",
      "tensor([20, 21, 16, 34,  8, 45, 25, 11, 30, 20, 19, 21, 42, 23, 47, 14])\n",
      "tensor([45, 41,  2, 12, 21,  3, 21, 17, 38,  0, 37, 42, 12,  4, 15,  2])\n",
      "tensor([20, 46, 10, 36, 48, 16, 24, 23, 25, 32,  4, 44,  1, 23, 26, 16])\n",
      "tensor([ 6, 33, 33, 46, 48,  8, 35, 46, 17,  5, 12, 15, 26, 36, 42, 29])\n",
      "tensor([12,  9, 25, 11, 44, 27, 29, 28,  4, 38, 34, 49, 12,  9,  3, 14])\n",
      "tensor([24, 33, 43, 10, 32, 27,  4, 21, 46, 27, 27, 11, 16, 35, 46, 15])\n",
      "tensor([44, 20, 49, 47, 21, 15, 41, 13, 46, 19, 45,  3,  4, 36, 37, 17])\n",
      "tensor([25, 32, 43, 37, 16,  3,  1, 44, 36, 10, 32, 42, 13, 25, 22,  2])\n",
      "tensor([11, 46, 49, 24, 30, 16,  8, 23, 27, 16,  8, 31,  6, 29, 32, 25])\n",
      "tensor([10, 17, 41, 49, 49, 40, 31, 26, 11, 31, 25,  3, 12, 40,  3, 35])\n",
      "tensor([28, 22,  1, 16, 30, 15, 49,  0, 13, 23,  5, 33,  8,  0,  9, 10])\n",
      "tensor([45, 32, 48, 28, 35, 11, 47,  7, 49, 38, 46, 22,  3, 19, 25, 49])\n",
      "tensor([12, 37, 32, 38, 38, 14, 29, 40,  2, 17, 11, 33,  4, 10,  3, 49])\n",
      "tensor([ 1, 15, 24, 37, 37,  5,  6, 17,  2, 34, 48, 27,  9,  3, 29,  4])\n",
      "tensor([45, 34, 45, 23, 28,  2,  6,  8, 39, 20, 40, 24, 15, 43, 34, 12])\n",
      "tensor([42, 16,  0, 27,  0, 25, 44, 39, 12,  2, 18, 36, 48, 49, 42,  7])\n",
      "tensor([12, 19, 45, 13, 25, 29, 42, 11, 18,  6, 42, 27, 39,  0,  4, 15])\n",
      "tensor([39,  5,  9, 11, 44, 18, 29, 38, 36,  7, 29, 47, 42, 11, 37, 24])\n",
      "tensor([38, 44, 42, 20,  6, 28, 38, 20, 21, 10, 25, 49,  5,  8, 26, 39])\n",
      "tensor([44, 49, 12, 38, 45, 13, 45, 48,  2, 42, 21, 21, 44, 34, 43, 13])\n",
      "tensor([41, 13, 42, 33, 13, 27, 49, 45,  3, 31, 25, 38, 12, 37, 21, 23])\n",
      "tensor([20,  3, 44, 26, 46, 32, 44, 35, 16,  3, 37, 47, 47, 31, 23, 23])\n",
      "tensor([ 9, 33, 10, 15,  8, 32, 35, 45, 10, 41, 12, 16,  9, 12, 29,  8])\n",
      "tensor([23, 15, 42, 38, 38, 33, 12, 44, 12, 18, 46, 26,  6, 12, 11, 30])\n",
      "tensor([26, 38, 41, 48,  9, 46, 41, 34, 24, 12, 34,  7, 17, 15, 12, 27])\n",
      "tensor([37, 18, 49, 22, 25, 14, 38, 22, 11, 36, 13, 25,  1,  0, 37, 32])\n",
      "tensor([22, 37,  8, 30,  4, 23, 33, 48,  3,  3, 30,  6, 19, 40, 35, 37])\n",
      "tensor([41,  0,  4, 27, 49, 49, 37, 31, 18, 35, 22, 16, 44, 14, 28, 46])\n",
      "tensor([16, 37, 21, 36, 49, 24,  5, 40, 36, 47, 32, 27, 28, 30, 43, 47])\n",
      "tensor([47, 22, 31, 27, 49, 20, 37, 35, 16, 25,  8, 49, 47, 33, 49, 14])\n",
      "tensor([10,  0, 42,  2, 36, 27, 35, 46,  0, 24, 47, 12, 15, 39,  7, 25])\n",
      "tensor([44, 17, 10, 11, 15, 35,  2, 42,  8, 21, 35, 19, 14, 32, 11, 25])\n",
      "tensor([48, 33, 44, 43,  0, 10, 19, 40, 48,  3,  6, 20, 28, 40, 11, 32])\n",
      "tensor([11, 32, 40, 48, 27,  3,  5, 37, 44, 16, 48,  5,  9, 19, 38,  9])\n",
      "tensor([23,  5,  1, 14, 34, 33, 26, 41, 17, 18, 10, 32, 19, 45,  4, 21])\n",
      "tensor([33,  7, 15, 35, 26,  8,  2, 36, 29, 37, 21, 35, 32, 43, 20, 16])\n",
      "tensor([15, 34,  4,  0, 10, 14, 16, 20, 49, 48,  6, 19, 49, 26, 24, 48])\n",
      "tensor([28, 48, 41])\n"
     ]
    }
   ],
   "source": [
    "feat,lbls = extract_features(model,train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([44, 19, 15, 37, 35, 44,  1, 20,  9, 47,  7, 24, 22, 42, 10, 28])\n",
      "tensor([32, 17, 36,  0, 25, 27, 43, 17, 13, 15, 45, 12, 34, 29, 22,  6])\n",
      "tensor([34, 26,  5, 41, 21, 13, 42, 23, 48, 11, 49, 32, 12, 24,  1, 44])\n",
      "tensor([34, 25, 32, 23, 40, 10, 10, 16,  0, 10, 31, 38,  2, 27, 26, 13])\n",
      "tensor([23, 34, 26, 32, 46, 43, 26, 30,  5,  3, 36, 44, 30, 19, 48, 20])\n",
      "tensor([28, 11, 14, 37, 48, 49, 28, 37, 37,  2, 15, 37, 11, 37, 43, 40])\n",
      "tensor([ 3, 17,  0, 27, 33, 19, 18, 11, 10,  5, 30,  0,  1, 18, 16, 18])\n",
      "tensor([31, 39, 15, 35,  8, 42, 37, 34, 48, 37, 44, 38, 37,  6,  6, 49])\n",
      "tensor([29, 40, 16, 43,  7, 19, 39, 16, 19, 25, 41,  5,  3, 17, 35, 29])\n",
      "tensor([16, 24, 35, 44, 44, 33, 10, 40, 31, 36, 19, 24, 42, 14,  4, 23])\n",
      "tensor([10, 43, 37, 39, 31, 13, 30, 38,  6, 28,  8, 15,  3, 17, 10,  7])\n",
      "tensor([ 1, 14, 45,  5,  2, 14, 32, 45, 42,  3, 45, 20, 22, 36, 20, 35])\n",
      "tensor([21, 13, 12, 34, 37, 19, 49, 43,  1, 48, 29, 34, 19, 32, 24, 20])\n",
      "tensor([17, 38, 15,  0, 19, 16,  0, 14, 31,  1, 33,  2, 32, 37, 24, 34])\n",
      "tensor([ 3, 29, 26,  8, 14, 11,  7, 32, 34, 39, 17, 43, 48, 46, 36, 15])\n",
      "tensor([40, 42,  4, 39, 25, 16, 35, 48, 27, 13, 39, 29, 44,  1, 29,  7])\n",
      "tensor([ 6, 49, 48, 37, 17, 39, 12, 10, 27, 32, 36, 42, 44,  5, 14, 36])\n",
      "tensor([36, 22, 20, 40, 24,  1, 24, 45, 18, 47, 27, 36, 36, 18, 10, 29])\n",
      "tensor([35, 28, 14,  7, 20,  2, 18, 44, 49, 33, 35, 11, 38, 21, 27, 33])\n",
      "tensor([36,  8, 27, 40, 42, 19, 11, 34, 17, 21,  2,  0, 24,  1, 26,  3])\n",
      "tensor([32, 35, 40,  2, 41, 26, 36,  1, 37, 20, 43,  5, 37, 29, 33,  4])\n",
      "tensor([ 7, 44, 32, 17,  4, 41, 11, 31,  8, 23,  0, 23, 42, 28, 35, 15])\n",
      "tensor([13,  9, 47, 24,  2, 13, 21, 14, 15, 41, 29, 39,  0,  2,  4, 48])\n",
      "tensor([ 0,  5, 39, 27, 13, 26,  3, 15, 27,  2, 36, 25, 26, 11, 34, 33])\n",
      "tensor([ 4, 43, 11, 22, 40, 37,  1, 15, 23, 39, 10, 28, 23, 19, 48, 38])\n",
      "tensor([18, 24, 17, 38, 14, 33, 33, 10, 28, 35, 16, 29,  3,  7, 27,  2])\n",
      "tensor([27, 48, 48, 48, 43,  6, 16, 28, 48, 25, 39, 38, 45, 21, 29, 18])\n",
      "tensor([39, 26,  5, 16, 23, 20,  8, 27, 32, 48, 35,  0, 32,  0, 45, 23])\n",
      "tensor([36, 32,  6,  9, 21, 16, 13,  9, 41, 44, 30, 24, 28, 32,  0, 22])\n",
      "tensor([31, 40, 25, 49, 47, 27, 21, 10, 27, 10, 29, 25, 36,  1, 17, 33])\n",
      "tensor([27, 42, 31, 11, 24, 25, 21, 33,  0, 15, 17, 13, 10, 14, 22, 10])\n",
      "tensor([12,  6,  2, 18, 29, 37,  0, 22,  8,  4, 21, 33, 29, 47, 20, 30])\n",
      "tensor([22, 22, 23, 34, 23,  4,  7,  9, 41,  3, 28, 25,  2, 24, 26,  5])\n",
      "tensor([ 8, 10, 34, 18, 48, 48,  3, 32, 28, 24, 47, 17, 21, 30, 46, 38])\n",
      "tensor([31, 37, 47, 27, 32, 10, 11, 41, 43, 23, 20, 11, 30, 10, 20, 10])\n",
      "tensor([28, 15,  2, 13, 33,  7, 15, 47, 41, 39,  3, 15,  9, 46,  4,  8])\n",
      "tensor([32, 32, 49, 46, 16, 14, 32, 45, 48, 26, 22, 29, 35, 45, 13, 26])\n",
      "tensor([ 8, 12, 21, 35, 10, 36, 15, 14, 33,  3,  9,  7, 25, 46,  7, 36])\n",
      "tensor([21, 36, 12, 31,  5, 16, 38,  5, 13, 12, 13, 39, 44, 33, 44, 10])\n",
      "tensor([11, 23, 32, 23, 45, 13, 24, 33, 26, 35,  7,  0, 43, 40, 39,  9])\n",
      "tensor([24, 34, 32,  7, 15, 31, 17, 39, 19, 38, 24, 34, 33, 17, 40,  3])\n",
      "tensor([49, 30, 28, 20, 21, 27, 20, 38, 41, 22, 11, 26, 43,  1,  5, 11])\n",
      "tensor([32, 33,  7, 37, 31, 11,  0, 34, 32, 32, 33, 34, 25, 23, 26, 34])\n",
      "tensor([31, 48, 39, 29,  4, 49, 19, 44,  5, 19, 44, 23,  4, 19, 16, 44])\n",
      "tensor([ 5,  8, 13, 35, 15, 25, 44,  9, 35, 15, 30, 28, 42, 20, 25, 12])\n",
      "tensor([ 2, 45,  3, 38, 13, 10, 33, 42, 16, 47, 40,  6, 14, 45, 36, 22])\n",
      "tensor([11, 21, 21, 19, 49, 42, 12, 33,  7, 40, 10, 22, 41, 21, 33,  5])\n",
      "tensor([16, 24, 48, 21, 40, 30, 19, 48,  0, 48, 38, 30, 45,  5, 22, 31])\n",
      "tensor([ 8, 38, 24,  2, 36, 40, 39, 13, 31, 38,  1, 26,  3, 27, 41, 31])\n",
      "tensor([28, 49, 38, 19, 46, 48, 15,  6, 41, 47, 28,  1, 16, 48,  4, 21])\n",
      "tensor([27, 38, 17, 45,  3, 30, 10, 19, 36, 22, 11, 33, 16, 26, 19, 12])\n",
      "tensor([18, 16, 29, 25,  5, 46, 36,  5, 41,  9, 35, 26, 24, 37, 25, 28])\n",
      "tensor([48, 33, 14, 49, 21, 46, 49, 28, 24, 45, 37, 46, 17, 35, 12, 32])\n",
      "tensor([12,  6, 10, 47, 48, 38, 47, 25,  0,  5, 27, 35, 30,  0,  5, 45])\n",
      "tensor([49, 33,  6,  0, 32, 23, 48, 15, 37,  5, 13, 23,  3,  6, 20, 36])\n",
      "tensor([20,  7, 18, 27,  9, 10, 36, 45, 17, 39, 16, 19, 33, 48, 48, 27])\n",
      "tensor([ 5, 37, 34,  9, 38,  3, 38, 48, 19, 21, 18, 32, 11, 34, 26, 29])\n",
      "tensor([ 7, 24,  0,  4, 20, 43, 33, 30,  0, 27, 22, 37, 46, 26,  9,  6])\n",
      "tensor([ 3, 46,  3, 29,  6, 12, 16, 25, 11, 41, 25, 42, 41, 11, 10,  8])\n",
      "tensor([32,  8, 24, 13, 38, 43, 31, 42, 44, 12,  5,  2, 38, 11, 24, 45])\n",
      "tensor([21, 33, 39, 11, 26, 36, 39, 35, 27, 18, 36, 22, 49,  1, 33, 44])\n",
      "tensor([39, 32, 40, 38, 33, 16, 33, 43, 31, 14, 44, 30, 21, 28, 15, 44])\n",
      "tensor([39, 11, 41, 49, 18, 42,  6, 16,  0, 38, 15, 38, 19, 38, 14, 46])\n",
      "tensor([ 3, 42, 18, 40,  5, 36, 45, 34, 13, 25, 27,  7, 26, 34, 47,  3])\n",
      "tensor([11,  2, 31, 14,  6, 38,  5, 10, 45, 38,  9, 38, 10, 42, 19, 22])\n",
      "tensor([29, 36, 48,  2, 12, 45,  4, 18,  1, 16, 45, 11, 28, 18, 26, 36])\n",
      "tensor([40, 46, 45, 11, 10, 22, 33, 45,  4, 20, 27, 49, 39,  4,  4, 14])\n",
      "tensor([ 5, 41,  4, 19, 21,  0, 26,  2, 32, 33, 27,  0, 34, 43,  7, 32])\n",
      "tensor([38, 43, 44, 21, 35, 48,  5,  0,  1, 35,  7,  2, 37, 27,  5, 29])\n",
      "tensor([43, 41,  6, 47, 39, 20, 49, 46, 20, 16, 16, 49, 28,  0, 28, 43])\n",
      "tensor([ 9, 47, 10, 33, 46, 10, 26, 35, 30,  6, 18, 40,  7, 41, 24, 30])\n",
      "tensor([14, 14,  4, 42, 12, 35, 27, 37, 24,  1, 35,  5,  3, 11, 46,  6])\n",
      "tensor([29,  6, 45, 30, 43, 48, 19, 33, 45, 14, 15,  4, 21, 43, 27, 11])\n",
      "tensor([21, 12, 33, 36, 15, 23, 41, 11, 49, 38, 23,  8, 12, 45, 12, 23])\n",
      "tensor([21, 33, 28,  6, 40, 45, 20, 36, 44, 40, 18, 12, 35, 23, 19, 46])\n",
      "tensor([47,  5,  5, 18, 35, 42,  3, 18, 30, 32, 27, 12, 30, 24, 20, 44])\n",
      "tensor([22, 41, 41, 28,  3, 47,  8, 24, 12, 30, 46, 12, 44,  8, 23, 18])\n",
      "tensor([22, 34, 46,  0, 25, 28, 47, 15, 42, 34, 49, 34, 32, 46, 49, 25])\n",
      "tensor([ 8,  7, 35, 22, 14, 37, 15, 15, 38, 14, 38, 45, 12, 38, 32, 39])\n",
      "tensor([38, 49,  3, 12,  2, 29, 26, 29, 47, 43, 46,  2, 17,  6, 36, 45])\n",
      "tensor([15, 20,  9, 47, 38, 31, 47, 11, 28, 10, 29, 49, 36, 16, 16,  4])\n",
      "tensor([28, 45, 28, 29, 15, 49, 25, 45, 23,  5, 42,  6, 10,  4, 21, 12])\n",
      "tensor([ 6, 11, 26,  2, 31, 32,  9, 45, 49, 30, 22, 23, 32,  5, 45,  1])\n",
      "tensor([19,  0,  4, 49, 44, 42, 41, 14, 20, 39, 29, 20, 22, 23, 17, 36])\n",
      "tensor([32, 44, 26,  1, 14, 12,  5, 28, 30, 49, 47,  4, 13, 48,  8, 40])\n",
      "tensor([25, 35, 16, 33, 34, 15,  4,  7, 44, 29,  3, 15, 32, 32, 42, 41])\n",
      "tensor([44, 43, 23, 25, 44, 20, 22, 39, 26, 28, 19,  7, 26, 11, 42, 26])\n",
      "tensor([39, 11, 19, 47, 15, 35, 10, 20, 26,  8,  1, 24, 33, 23, 49, 40])\n",
      "tensor([29, 22, 17, 32, 17, 31, 28, 21, 46, 27,  9, 12, 35, 16,  6, 35])\n",
      "tensor([33, 46, 18,  2, 32, 45,  4, 40,  3, 36, 13, 35, 40,  0, 35, 45])\n",
      "tensor([40, 33, 22, 30, 36, 26,  0, 22,  7, 44, 48, 31, 30, 40, 47,  2])\n",
      "tensor([21, 28, 41, 14,  8, 30,  6, 41, 24, 49, 38, 27, 45, 38,  6, 23])\n",
      "tensor([24, 30, 34, 12,  1, 20, 46, 48, 16, 11,  3, 36,  8, 49, 22, 49])\n",
      "tensor([35, 30, 34,  9, 49, 19, 43,  6, 36, 26, 22, 42, 21, 38, 11, 13])\n",
      "tensor([48, 34, 38, 35, 14, 16, 26,  9, 33, 10, 11,  2, 40, 24, 21, 42])\n",
      "tensor([22, 24,  5,  1, 36, 27, 35, 34, 39,  9, 34, 12, 27,  1, 37, 34])\n",
      "tensor([13, 31, 19, 39, 33, 14,  4, 37, 34,  6,  9, 37, 32, 37, 41, 16])\n",
      "tensor([ 2, 15, 23, 47, 49, 30, 13, 13,  2, 25, 34,  2, 35,  7, 46, 24])\n",
      "tensor([10, 11, 29, 18, 45, 36,  1, 30,  3, 47, 10, 47, 12, 32, 36, 12])\n",
      "tensor([ 2, 14, 16, 27, 43,  0, 19, 14, 30, 48, 11, 25, 43,  1, 43,  5])\n",
      "tensor([47, 12, 32,  5,  3, 32, 25, 14, 24, 45, 47, 21, 13, 20,  2,  6])\n",
      "tensor([ 1, 23,  9, 48,  7,  2, 10, 16, 49, 25, 17,  6, 13, 21, 43,  8])\n",
      "tensor([37, 40, 37, 43, 19, 43,  4,  8, 22,  5, 44, 26,  3, 33, 20,  3])\n",
      "tensor([48,  9, 19, 41, 35, 36, 47, 39,  3,  0,  4, 11, 13,  7, 27, 20])\n",
      "tensor([46, 34,  2, 16, 14, 23,  3, 29, 15, 38, 39,  8,  2, 36, 15, 17])\n",
      "tensor([21, 11, 38, 35, 18, 31, 20, 43, 24, 47, 13, 15, 17, 26, 46, 41])\n",
      "tensor([44, 16, 35,  2, 48, 16, 17, 33, 39,  2,  5, 44,  7, 34, 34, 20])\n",
      "tensor([27, 22, 36, 46, 40, 41, 10, 13, 38, 38, 24, 49, 20, 36, 19, 29])\n",
      "tensor([ 0,  5, 23, 40,  9, 12,  1, 26,  0, 49, 15, 27,  9, 15, 27, 41])\n",
      "tensor([25, 31,  5, 28, 47, 49, 29, 34, 25,  0, 22, 14, 26, 14, 13, 49])\n",
      "tensor([16, 42, 12, 16, 24, 38,  6, 48,  9, 14, 49, 42, 40,  6, 14, 15])\n",
      "tensor([ 7, 38,  9, 18, 24,  4, 24, 34, 11, 16, 10, 18, 15,  8, 11, 40])\n",
      "tensor([ 2, 21, 46,  6, 18, 42,  7, 31, 38, 21, 17, 20, 44, 19, 42,  7])\n",
      "tensor([20, 23,  3, 23, 44,  9, 32, 45, 43, 41,  4,  9, 41, 16, 37, 12])\n",
      "tensor([21, 39, 46, 31, 34,  1,  5,  6, 27, 24, 16, 14, 11,  1, 44, 15])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 49, 41,  7, 26, 36, 18,  1,  8, 44,  8,  3,  3,  1])\n"
     ]
    }
   ],
   "source": [
    "#feat,lbls = extract_features(model,train_data_loader)\n",
    "test_feat,test_lbls = extract_features(model,test_data_loader)\n",
    "lbls = flatten_list(lbls)\n",
    "test_lbls  =flatten_list(test_lbls) # flatting the lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4835, 1854)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbls),len(test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 1536), 4835, (1854, 1536), 1854)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape,len(lbls),test_feat.shape,len(test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cat_feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a6bc9b646aa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVM Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_lbls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_feat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcat_feat_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_lbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "# returns SVM accuracy\n",
    "# accepts train and test feature set\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def svm(X,Y,x_lbls,y_lbls):\n",
    "    print('Train-Without FFT')\n",
    "    #SVM\n",
    "    svm = SVC(kernel='linear').fit(X,x_lbls)\n",
    "    preds = svm.predict(Y)\n",
    "    print(\"SVM Accuracy:\",metrics.accuracy_score(y_lbls, preds))\n",
    "    \n",
    "svm(cat_feat_train,cat_feat_test,lbls,test_lbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Without FFT\n",
      "SVM Accuracy: 0.5609492988133765\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Train-Without FFT')\n",
    "#SVM\n",
    "svm_preds = SVC(kernel='linear').fit(feat,lbls).predict(test_feat)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_lbls, svm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 4608), (1854, 4608))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save np network features and labels\n",
    "# Use pickle for serialization or np.save for saving np objects. two options\n",
    "\n",
    "\n",
    "\n",
    "i = 0 #video index 4797\n",
    "j = 0 # neuron index 1000\n",
    "\n",
    "def hstft(S1):\n",
    "    S21, S22 = np.split(S1,2)  # 500+500\n",
    "    S311, S312 = np.split(S21,2) # 500    \n",
    "    S321, S322 = np.split(S22,2) # 500\n",
    "    #S1.shape,S21.shape,S22.shape,S311.shape,S312.shape,S321.shape,S322.shape    \n",
    "    return np.concatenate((S1,S21,S22,S311,S312,S321,S322))\n",
    "\n",
    "def alpha(features):\n",
    "    A = np.zeros((len(features),4608))\n",
    "    for i,f in enumerate(features):\n",
    "        h = scipy.fft.fft(f)    \n",
    "        #print(f.shape,h.shape)\n",
    "        #print(h.shape)\n",
    "        h = hstft(h)\n",
    "        #print(h.shape)\n",
    "        A[i,:] = h.real\n",
    "    return A\n",
    "\n",
    "train_alpha = alpha(feat)\n",
    "test_alpha = alpha(test_feat)\n",
    "train_alpha.shape,test_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 4608), (4835,), (1854, 4608), (1854,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_alpha\n",
    "Y = lbls\n",
    "test_x = test_alpha\n",
    "test_y = test_lbls\n",
    "X.shape,Y.shape,test_x.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5285868392664509\n",
      "KNN Accuracy: 0.38349514563106796\n",
      "RF Accuracy: 0.48327939590075514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#SVM\n",
    "clf = SVC(kernel='linear').fit(X,Y)\n",
    "preds = clf.predict(test_x)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_y, preds))\n",
    "\n",
    "#KNN\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3).fit(X,Y)\n",
    "knn_preds = knn_clf.predict(test_x)\n",
    "print(\"KNN Accuracy:\",metrics.accuracy_score(test_y, knn_preds))\n",
    "\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100).fit(X,Y)\n",
    "rf_preds = rf_clf.predict(test_x)\n",
    "print(\"RF Accuracy:\",metrics.accuracy_score(test_y, rf_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0239f972e8efcc00ec9fa7a595c90a818e30a75607d9e34132d6cc1dc8c76e26"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
