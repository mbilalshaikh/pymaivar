# PyMAiVAR

License: PyMAiVAR is distributed under the GNU V3 GPL license. See the LICENSE file for more details.


## Abstract

We present PyMAiVAR which is a toolbox preferable for generating audio-image representations that incorporates for human actions information. The Spectral Centroid feature, which is widely used for music genre identification and audio classification, inspired our feature methodology. The representation’s performance is evaluated for multimodal human action recognition and is comparable to other representations and other unimodal approaches on the same dataset. We also present few other use case of the toolbox for generating image-based representations.  PyMAiVAR can be a valuable tool for researchers in the field of multimodal action recognition, providing enhanced performance by leveraging multiple modalities. The package is implemented in Python and can be used across different operating systems. 

## Modules

	core: Core funtionality of pymaivar


## Documentation

	Documentation for each module is in their respective .md files

	core --> core.md

> An example can be found in **example.py**

## Cite the following reference if you use the code implementation
M. B. Shaikh, D. Chai, S. M. S. Islam and N. Akhtar, "MAiVAR: Multimodal Audio-Image and Video Action Recognizer," 2022 IEEE International Conference on Visual Communications and Image Processing (VCIP), Suzhou, China, 2022, pp. 1-5, doi: 10.1109/VCIP56404.2022.10008833.
URL: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10008833&isnumber=10008793 

## Acknowledgements
This research is jointly supported by Edith Cowan University (ECU) and Higher Education Commission (HEC) of Pakistan under Project #PM/HRDI-UESTPs/UETs-I/Phase-1/Batch-VI/2018. Dr. Akhtar is a recipient of Office of National Intelligence National Intelligence Postdoctoral Grant # NIPG-2021–001 funded by the Australian Government.


