{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/muhammadbsheikh/workspace/try\n"
     ]
    }
   ],
   "source": [
    "cd /home/muhammadbsheikh/workspace/try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(model,dl):\n",
    "    lbls = []\n",
    "    model.eval()\n",
    "    device = 'cuda:0'\n",
    "    model.cuda(device)\n",
    "    with torch.no_grad():\n",
    "        features = None\n",
    "        for batch in tqdm(dl, disable=True):\n",
    "            \n",
    "            images = batch[0]\n",
    "            labels = batch[1]\n",
    "            images = images.to(device)\n",
    "            #labels = labels.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            lbls.append(labels)\n",
    "            print(labels)\n",
    "\n",
    "            if features is not None:\n",
    "                features = torch.cat((features, output), 0)\n",
    "\n",
    "            else:\n",
    "                features = output        \n",
    "            \n",
    "\n",
    "    return features.cpu().numpy(),lbls\n",
    "\n",
    "\n",
    "def flatten_list(t):\n",
    "    flat_list = [item for sublist in t for item in sublist]\n",
    "    flat_list = np.array(flat_list)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1\n",
      "0.9.1\n",
      "_CudaDeviceProperties(name='GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11178MB, multi_processor_count=28) None 0\n",
      "Training...\n",
      "[epoch 1,imgs    40] loss: 0.7375014  time: 1.262 s\n",
      "[epoch 1,imgs    80] loss: 0.7414163  time: 0.896 s\n",
      "[epoch 1,imgs   120] loss: 0.7363210  time: 0.893 s\n",
      "[epoch 1,imgs   160] loss: 0.7386515  time: 0.894 s\n",
      "[epoch 1,imgs   200] loss: 0.7363651  time: 0.898 s\n",
      "[epoch 1,imgs   240] loss: 0.7394509  time: 0.896 s\n",
      "[epoch 1,imgs   280] loss: 0.7392181  time: 0.897 s\n",
      "[epoch 1,imgs   320] loss: 0.7364129  time: 0.898 s\n",
      "[epoch 1,imgs   360] loss: 0.7357797  time: 0.897 s\n",
      "[epoch 1,imgs   400] loss: 0.7440923  time: 0.898 s\n",
      "[epoch 1,imgs   440] loss: 0.7433805  time: 0.903 s\n",
      "[epoch 1,imgs   480] loss: 0.7381796  time: 0.898 s\n",
      "[epoch 1,imgs   520] loss: 0.7396355  time: 0.900 s\n",
      "[epoch 1,imgs   560] loss: 0.7414164  time: 0.899 s\n",
      "[epoch 1,imgs   600] loss: 0.7410792  time: 0.900 s\n",
      "[epoch 1,imgs   640] loss: 0.7402314  time: 0.900 s\n",
      "[epoch 1,imgs   680] loss: 0.7371876  time: 0.899 s\n",
      "[epoch 1,imgs   720] loss: 0.7378924  time: 0.899 s\n",
      "[epoch 1,imgs   760] loss: 0.7398025  time: 0.900 s\n",
      "[epoch 1,imgs   800] loss: 0.7405886  time: 0.901 s\n",
      "[epoch 1,imgs   840] loss: 0.7337906  time: 0.901 s\n",
      "[epoch 1,imgs   880] loss: 0.7403437  time: 0.902 s\n",
      "[epoch 1,imgs   920] loss: 0.7373413  time: 0.905 s\n",
      "[epoch 1,imgs   960] loss: 0.7421796  time: 0.901 s\n",
      "[epoch 1,imgs  1000] loss: 0.7395925  time: 0.903 s\n",
      "[epoch 1,imgs  1040] loss: 0.7374426  time: 0.907 s\n",
      "[epoch 1,imgs  1080] loss: 0.7395311  time: 0.905 s\n",
      "[epoch 1,imgs  1120] loss: 0.7394121  time: 0.905 s\n",
      "[epoch 1,imgs  1160] loss: 0.7356516  time: 0.905 s\n",
      "[epoch 1,imgs  1200] loss: 0.7413282  time: 0.907 s\n",
      "[epoch 2,imgs    40] loss: 0.7410480  time: 1.289 s\n",
      "[epoch 2,imgs    80] loss: 0.7377692  time: 0.907 s\n",
      "[epoch 2,imgs   120] loss: 0.7412210  time: 0.907 s\n",
      "[epoch 2,imgs   160] loss: 0.7371134  time: 0.907 s\n",
      "[epoch 2,imgs   200] loss: 0.7373092  time: 0.909 s\n",
      "[epoch 2,imgs   240] loss: 0.7395218  time: 0.908 s\n",
      "[epoch 2,imgs   280] loss: 0.7382756  time: 0.908 s\n",
      "[epoch 2,imgs   320] loss: 0.7400263  time: 0.908 s\n",
      "[epoch 2,imgs   360] loss: 0.7442188  time: 0.909 s\n",
      "[epoch 2,imgs   400] loss: 0.7395468  time: 0.909 s\n",
      "[epoch 2,imgs   440] loss: 0.7369848  time: 0.909 s\n",
      "[epoch 2,imgs   480] loss: 0.7373491  time: 0.913 s\n",
      "[epoch 2,imgs   520] loss: 0.7340246  time: 0.912 s\n",
      "[epoch 2,imgs   560] loss: 0.7405539  time: 0.912 s\n",
      "[epoch 2,imgs   600] loss: 0.7376686  time: 0.913 s\n",
      "[epoch 2,imgs   640] loss: 0.7419640  time: 0.913 s\n",
      "[epoch 2,imgs   680] loss: 0.7375386  time: 0.914 s\n",
      "[epoch 2,imgs   720] loss: 0.7384163  time: 0.914 s\n",
      "[epoch 2,imgs   760] loss: 0.7388404  time: 0.915 s\n",
      "[epoch 2,imgs   800] loss: 0.7378058  time: 0.914 s\n",
      "[epoch 2,imgs   840] loss: 0.7365645  time: 0.914 s\n",
      "[epoch 2,imgs   880] loss: 0.7353196  time: 0.915 s\n",
      "[epoch 2,imgs   920] loss: 0.7423366  time: 0.916 s\n",
      "[epoch 2,imgs   960] loss: 0.7395848  time: 0.917 s\n",
      "[epoch 2,imgs  1000] loss: 0.7354505  time: 0.916 s\n",
      "[epoch 2,imgs  1040] loss: 0.7355013  time: 0.916 s\n",
      "[epoch 2,imgs  1080] loss: 0.7378691  time: 0.916 s\n",
      "[epoch 2,imgs  1120] loss: 0.7413338  time: 0.918 s\n",
      "[epoch 2,imgs  1160] loss: 0.7380376  time: 0.918 s\n",
      "[epoch 2,imgs  1200] loss: 0.7379270  time: 0.925 s\n",
      "[epoch 3,imgs    40] loss: 0.7402604  time: 1.323 s\n",
      "[epoch 3,imgs    80] loss: 0.7360504  time: 0.926 s\n",
      "[epoch 3,imgs   120] loss: 0.7406026  time: 0.917 s\n",
      "[epoch 3,imgs   160] loss: 0.7410873  time: 0.925 s\n",
      "[epoch 3,imgs   200] loss: 0.7374541  time: 0.933 s\n",
      "[epoch 3,imgs   240] loss: 0.7413201  time: 0.925 s\n",
      "[epoch 3,imgs   280] loss: 0.7382718  time: 0.921 s\n",
      "[epoch 3,imgs   320] loss: 0.7403839  time: 0.923 s\n",
      "[epoch 3,imgs   360] loss: 0.7416127  time: 0.922 s\n",
      "[epoch 3,imgs   400] loss: 0.7366385  time: 0.923 s\n",
      "[epoch 3,imgs   440] loss: 0.7387303  time: 0.921 s\n",
      "[epoch 3,imgs   480] loss: 0.7430731  time: 0.925 s\n",
      "[epoch 3,imgs   520] loss: 0.7406971  time: 0.919 s\n",
      "[epoch 3,imgs   560] loss: 0.7381617  time: 0.921 s\n",
      "[epoch 3,imgs   600] loss: 0.7390015  time: 0.926 s\n",
      "[epoch 3,imgs   640] loss: 0.7374652  time: 0.926 s\n",
      "[epoch 3,imgs   680] loss: 0.7402878  time: 0.931 s\n",
      "[epoch 3,imgs   720] loss: 0.7367450  time: 0.927 s\n",
      "[epoch 3,imgs   760] loss: 0.7422375  time: 0.923 s\n",
      "[epoch 3,imgs   800] loss: 0.7379773  time: 0.920 s\n",
      "[epoch 3,imgs   840] loss: 0.7431591  time: 0.921 s\n",
      "[epoch 3,imgs   880] loss: 0.7374505  time: 0.922 s\n",
      "[epoch 3,imgs   920] loss: 0.7374085  time: 0.920 s\n",
      "[epoch 3,imgs   960] loss: 0.7396955  time: 0.929 s\n",
      "[epoch 3,imgs  1000] loss: 0.7376249  time: 0.929 s\n",
      "[epoch 3,imgs  1040] loss: 0.7391696  time: 0.925 s\n",
      "[epoch 3,imgs  1080] loss: 0.7345043  time: 0.925 s\n",
      "[epoch 3,imgs  1120] loss: 0.7333427  time: 0.931 s\n",
      "[epoch 3,imgs  1160] loss: 0.7379789  time: 0.925 s\n",
      "[epoch 3,imgs  1200] loss: 0.7353224  time: 0.927 s\n",
      "[epoch 4,imgs    40] loss: 0.7372329  time: 1.313 s\n",
      "[epoch 4,imgs    80] loss: 0.7365445  time: 0.927 s\n",
      "[epoch 4,imgs   120] loss: 0.7435721  time: 0.925 s\n",
      "[epoch 4,imgs   160] loss: 0.7413410  time: 0.923 s\n",
      "[epoch 4,imgs   200] loss: 0.7442536  time: 0.928 s\n",
      "[epoch 4,imgs   240] loss: 0.7370183  time: 0.923 s\n",
      "[epoch 4,imgs   280] loss: 0.7377542  time: 0.924 s\n",
      "[epoch 4,imgs   320] loss: 0.7357501  time: 0.924 s\n",
      "[epoch 4,imgs   360] loss: 0.7363942  time: 0.924 s\n",
      "[epoch 4,imgs   400] loss: 0.7367676  time: 0.924 s\n",
      "[epoch 4,imgs   440] loss: 0.7382037  time: 0.923 s\n",
      "[epoch 4,imgs   480] loss: 0.7384759  time: 0.928 s\n",
      "[epoch 4,imgs   520] loss: 0.7403060  time: 0.924 s\n",
      "[epoch 4,imgs   560] loss: 0.7434180  time: 0.925 s\n",
      "[epoch 4,imgs   600] loss: 0.7356718  time: 0.924 s\n",
      "[epoch 4,imgs   640] loss: 0.7398415  time: 0.928 s\n",
      "[epoch 4,imgs   680] loss: 0.7352759  time: 0.949 s\n",
      "[epoch 4,imgs   720] loss: 0.7420565  time: 0.931 s\n",
      "[epoch 4,imgs   760] loss: 0.7370524  time: 0.930 s\n",
      "[epoch 4,imgs   800] loss: 0.7418590  time: 0.928 s\n",
      "[epoch 4,imgs   840] loss: 0.7344543  time: 0.930 s\n",
      "[epoch 4,imgs   880] loss: 0.7406724  time: 0.931 s\n",
      "[epoch 4,imgs   920] loss: 0.7402351  time: 0.932 s\n",
      "[epoch 4,imgs   960] loss: 0.7361273  time: 0.930 s\n",
      "[epoch 4,imgs  1000] loss: 0.7392132  time: 0.929 s\n",
      "[epoch 4,imgs  1040] loss: 0.7345058  time: 0.932 s\n",
      "[epoch 4,imgs  1080] loss: 0.7382319  time: 0.929 s\n",
      "[epoch 4,imgs  1120] loss: 0.7361890  time: 0.928 s\n",
      "[epoch 4,imgs  1160] loss: 0.7384398  time: 0.931 s\n",
      "[epoch 4,imgs  1200] loss: 0.7421207  time: 0.930 s\n",
      "[epoch 5,imgs    40] loss: 0.7413916  time: 1.344 s\n",
      "[epoch 5,imgs    80] loss: 0.7374892  time: 0.931 s\n",
      "[epoch 5,imgs   120] loss: 0.7368829  time: 0.930 s\n",
      "[epoch 5,imgs   160] loss: 0.7396593  time: 0.928 s\n",
      "[epoch 5,imgs   200] loss: 0.7389582  time: 0.929 s\n",
      "[epoch 5,imgs   240] loss: 0.7389851  time: 0.929 s\n",
      "[epoch 5,imgs   280] loss: 0.7387539  time: 0.929 s\n",
      "[epoch 5,imgs   320] loss: 0.7371376  time: 0.928 s\n",
      "[epoch 5,imgs   360] loss: 0.7349126  time: 0.930 s\n",
      "[epoch 5,imgs   400] loss: 0.7418150  time: 0.929 s\n",
      "[epoch 5,imgs   440] loss: 0.7423636  time: 0.927 s\n",
      "[epoch 5,imgs   480] loss: 0.7354131  time: 0.930 s\n",
      "[epoch 5,imgs   520] loss: 0.7365423  time: 0.928 s\n",
      "[epoch 5,imgs   560] loss: 0.7362611  time: 0.929 s\n",
      "[epoch 5,imgs   600] loss: 0.7415206  time: 0.929 s\n",
      "[epoch 5,imgs   640] loss: 0.7405753  time: 0.930 s\n",
      "[epoch 5,imgs   680] loss: 0.7427706  time: 0.928 s\n",
      "[epoch 5,imgs   720] loss: 0.7374795  time: 0.930 s\n",
      "[epoch 5,imgs   760] loss: 0.7347594  time: 0.929 s\n",
      "[epoch 5,imgs   800] loss: 0.7375770  time: 0.929 s\n",
      "[epoch 5,imgs   840] loss: 0.7393876  time: 0.930 s\n",
      "[epoch 5,imgs   880] loss: 0.7405204  time: 0.930 s\n",
      "[epoch 5,imgs   920] loss: 0.7405220  time: 0.930 s\n",
      "[epoch 5,imgs   960] loss: 0.7362024  time: 0.930 s\n",
      "[epoch 5,imgs  1000] loss: 0.7407072  time: 0.933 s\n",
      "[epoch 5,imgs  1040] loss: 0.7391785  time: 0.929 s\n",
      "[epoch 5,imgs  1080] loss: 0.7370738  time: 0.931 s\n",
      "[epoch 5,imgs  1120] loss: 0.7356703  time: 0.930 s\n",
      "[epoch 5,imgs  1160] loss: 0.7399042  time: 0.934 s\n",
      "[epoch 5,imgs  1200] loss: 0.7376561  time: 0.931 s\n",
      "[epoch 6,imgs    40] loss: 0.7289027  time: 1.319 s\n",
      "[epoch 6,imgs    80] loss: 0.7353601  time: 0.935 s\n",
      "[epoch 6,imgs   120] loss: 0.7431094  time: 0.935 s\n",
      "[epoch 6,imgs   160] loss: 0.7363765  time: 0.930 s\n",
      "[epoch 6,imgs   200] loss: 0.7386374  time: 0.931 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 6,imgs   240] loss: 0.7404406  time: 0.931 s\n",
      "[epoch 6,imgs   280] loss: 0.7406595  time: 0.929 s\n",
      "[epoch 6,imgs   320] loss: 0.7384154  time: 0.931 s\n",
      "[epoch 6,imgs   360] loss: 0.7412270  time: 0.930 s\n",
      "[epoch 6,imgs   400] loss: 0.7382645  time: 0.930 s\n",
      "[epoch 6,imgs   440] loss: 0.7425505  time: 0.933 s\n",
      "[epoch 6,imgs   480] loss: 0.7374544  time: 0.932 s\n",
      "[epoch 6,imgs   520] loss: 0.7405995  time: 0.932 s\n",
      "[epoch 6,imgs   560] loss: 0.7359759  time: 0.934 s\n",
      "[epoch 6,imgs   600] loss: 0.7361525  time: 0.931 s\n",
      "[epoch 6,imgs   640] loss: 0.7388428  time: 0.934 s\n",
      "[epoch 6,imgs   680] loss: 0.7407253  time: 0.930 s\n",
      "[epoch 6,imgs   720] loss: 0.7404938  time: 0.930 s\n",
      "[epoch 6,imgs   760] loss: 0.7372701  time: 0.932 s\n",
      "[epoch 6,imgs   800] loss: 0.7380025  time: 0.929 s\n",
      "[epoch 6,imgs   840] loss: 0.7315590  time: 0.930 s\n",
      "[epoch 6,imgs   880] loss: 0.7409509  time: 0.931 s\n",
      "[epoch 6,imgs   920] loss: 0.7402627  time: 0.929 s\n",
      "[epoch 6,imgs   960] loss: 0.7382134  time: 0.930 s\n",
      "[epoch 6,imgs  1000] loss: 0.7397350  time: 0.933 s\n",
      "[epoch 6,imgs  1040] loss: 0.7373914  time: 0.929 s\n",
      "[epoch 6,imgs  1080] loss: 0.7365358  time: 0.930 s\n",
      "[epoch 6,imgs  1120] loss: 0.7371637  time: 0.929 s\n",
      "[epoch 6,imgs  1160] loss: 0.7374178  time: 0.929 s\n",
      "[epoch 6,imgs  1200] loss: 0.7321321  time: 0.929 s\n",
      "[epoch 7,imgs    40] loss: 0.7403491  time: 1.304 s\n",
      "[epoch 7,imgs    80] loss: 0.7351559  time: 0.932 s\n",
      "[epoch 7,imgs   120] loss: 0.7378595  time: 0.934 s\n",
      "[epoch 7,imgs   160] loss: 0.7390928  time: 0.932 s\n",
      "[epoch 7,imgs   200] loss: 0.7401527  time: 0.933 s\n",
      "[epoch 7,imgs   240] loss: 0.7410219  time: 0.934 s\n",
      "[epoch 7,imgs   280] loss: 0.7364153  time: 0.935 s\n",
      "[epoch 7,imgs   320] loss: 0.7324036  time: 0.933 s\n",
      "[epoch 7,imgs   360] loss: 0.7407542  time: 0.933 s\n",
      "[epoch 7,imgs   400] loss: 0.7426886  time: 0.934 s\n",
      "[epoch 7,imgs   440] loss: 0.7376165  time: 0.934 s\n",
      "[epoch 7,imgs   480] loss: 0.7405650  time: 0.933 s\n",
      "[epoch 7,imgs   520] loss: 0.7379636  time: 0.932 s\n",
      "[epoch 7,imgs   560] loss: 0.7387691  time: 0.933 s\n",
      "[epoch 7,imgs   600] loss: 0.7343829  time: 0.933 s\n",
      "[epoch 7,imgs   640] loss: 0.7362828  time: 0.933 s\n",
      "[epoch 7,imgs   680] loss: 0.7337538  time: 0.930 s\n",
      "[epoch 7,imgs   720] loss: 0.7411120  time: 0.933 s\n",
      "[epoch 7,imgs   760] loss: 0.7384385  time: 0.933 s\n",
      "[epoch 7,imgs   800] loss: 0.7403936  time: 0.933 s\n",
      "[epoch 7,imgs   840] loss: 0.7415150  time: 0.930 s\n",
      "[epoch 7,imgs   880] loss: 0.7359512  time: 0.931 s\n",
      "[epoch 7,imgs   920] loss: 0.7421341  time: 0.932 s\n",
      "[epoch 7,imgs   960] loss: 0.7416655  time: 0.930 s\n",
      "[epoch 7,imgs  1000] loss: 0.7340897  time: 0.933 s\n",
      "[epoch 7,imgs  1040] loss: 0.7350167  time: 0.930 s\n",
      "[epoch 7,imgs  1080] loss: 0.7348726  time: 0.934 s\n",
      "[epoch 7,imgs  1120] loss: 0.7362636  time: 0.933 s\n",
      "[epoch 7,imgs  1160] loss: 0.7411933  time: 0.933 s\n",
      "[epoch 7,imgs  1200] loss: 0.7401464  time: 0.938 s\n",
      "[epoch 8,imgs    40] loss: 0.7381045  time: 1.345 s\n",
      "[epoch 8,imgs    80] loss: 0.7400709  time: 0.934 s\n",
      "[epoch 8,imgs   120] loss: 0.7409119  time: 0.941 s\n",
      "[epoch 8,imgs   160] loss: 0.7376952  time: 0.938 s\n",
      "[epoch 8,imgs   200] loss: 0.7384143  time: 0.936 s\n",
      "[epoch 8,imgs   240] loss: 0.7426021  time: 0.934 s\n",
      "[epoch 8,imgs   280] loss: 0.7363663  time: 0.931 s\n",
      "[epoch 8,imgs   320] loss: 0.7425689  time: 0.945 s\n",
      "[epoch 8,imgs   360] loss: 0.7381867  time: 0.938 s\n",
      "[epoch 8,imgs   400] loss: 0.7366694  time: 0.937 s\n",
      "[epoch 8,imgs   440] loss: 0.7326372  time: 0.933 s\n",
      "[epoch 8,imgs   480] loss: 0.7399470  time: 0.934 s\n",
      "[epoch 8,imgs   520] loss: 0.7380497  time: 0.932 s\n",
      "[epoch 8,imgs   560] loss: 0.7390705  time: 0.933 s\n",
      "[epoch 8,imgs   600] loss: 0.7377900  time: 0.931 s\n",
      "[epoch 8,imgs   640] loss: 0.7387652  time: 0.932 s\n",
      "[epoch 8,imgs   680] loss: 0.7383368  time: 0.927 s\n",
      "[epoch 8,imgs   720] loss: 0.7366557  time: 0.932 s\n",
      "[epoch 8,imgs   760] loss: 0.7334515  time: 0.935 s\n",
      "[epoch 8,imgs   800] loss: 0.7332066  time: 0.934 s\n",
      "[epoch 8,imgs   840] loss: 0.7420650  time: 0.937 s\n",
      "[epoch 8,imgs   880] loss: 0.7438868  time: 0.931 s\n",
      "[epoch 8,imgs   920] loss: 0.7383363  time: 0.937 s\n",
      "[epoch 8,imgs   960] loss: 0.7385965  time: 0.931 s\n",
      "[epoch 8,imgs  1000] loss: 0.7326049  time: 0.931 s\n",
      "[epoch 8,imgs  1040] loss: 0.7412519  time: 0.933 s\n",
      "[epoch 8,imgs  1080] loss: 0.7378706  time: 0.932 s\n",
      "[epoch 8,imgs  1120] loss: 0.7427593  time: 0.932 s\n",
      "[epoch 8,imgs  1160] loss: 0.7347307  time: 0.931 s\n",
      "[epoch 8,imgs  1200] loss: 0.7383826  time: 0.929 s\n",
      "[epoch 9,imgs    40] loss: 0.7382247  time: 1.309 s\n",
      "[epoch 9,imgs    80] loss: 0.7405323  time: 0.937 s\n",
      "[epoch 9,imgs   120] loss: 0.7382355  time: 0.935 s\n",
      "[epoch 9,imgs   160] loss: 0.7359002  time: 0.935 s\n",
      "[epoch 9,imgs   200] loss: 0.7415104  time: 0.933 s\n",
      "[epoch 9,imgs   240] loss: 0.7413306  time: 0.935 s\n",
      "[epoch 9,imgs   280] loss: 0.7432794  time: 0.935 s\n",
      "[epoch 9,imgs   320] loss: 0.7384582  time: 0.935 s\n",
      "[epoch 9,imgs   360] loss: 0.7367372  time: 0.935 s\n",
      "[epoch 9,imgs   400] loss: 0.7357924  time: 0.934 s\n",
      "[epoch 9,imgs   440] loss: 0.7374489  time: 0.934 s\n",
      "[epoch 9,imgs   480] loss: 0.7407308  time: 0.933 s\n",
      "[epoch 9,imgs   520] loss: 0.7379737  time: 0.935 s\n",
      "[epoch 9,imgs   560] loss: 0.7371554  time: 0.932 s\n",
      "[epoch 9,imgs   600] loss: 0.7371193  time: 0.933 s\n",
      "[epoch 9,imgs   640] loss: 0.7398829  time: 0.934 s\n",
      "[epoch 9,imgs   680] loss: 0.7338188  time: 0.935 s\n",
      "[epoch 9,imgs   720] loss: 0.7393644  time: 0.938 s\n",
      "[epoch 9,imgs   760] loss: 0.7385130  time: 0.936 s\n",
      "[epoch 9,imgs   800] loss: 0.7376230  time: 0.934 s\n",
      "[epoch 9,imgs   840] loss: 0.7386042  time: 0.933 s\n",
      "[epoch 9,imgs   880] loss: 0.7428573  time: 0.932 s\n",
      "[epoch 9,imgs   920] loss: 0.7423086  time: 0.934 s\n",
      "[epoch 9,imgs   960] loss: 0.7392894  time: 0.934 s\n",
      "[epoch 9,imgs  1000] loss: 0.7417734  time: 0.934 s\n",
      "[epoch 9,imgs  1040] loss: 0.7387075  time: 0.932 s\n",
      "[epoch 9,imgs  1080] loss: 0.7406395  time: 0.935 s\n",
      "[epoch 9,imgs  1120] loss: 0.7405373  time: 0.937 s\n",
      "[epoch 9,imgs  1160] loss: 0.7387258  time: 0.932 s\n",
      "[epoch 9,imgs  1200] loss: 0.7401753  time: 0.934 s\n",
      "[epoch 10,imgs    40] loss: 0.7391777  time: 1.340 s\n",
      "[epoch 10,imgs    80] loss: 0.7353805  time: 0.938 s\n",
      "[epoch 10,imgs   120] loss: 0.7370775  time: 0.935 s\n",
      "[epoch 10,imgs   160] loss: 0.7338094  time: 0.934 s\n",
      "[epoch 10,imgs   200] loss: 0.7412873  time: 0.934 s\n",
      "[epoch 10,imgs   240] loss: 0.7386775  time: 0.936 s\n",
      "[epoch 10,imgs   280] loss: 0.7366723  time: 0.935 s\n",
      "[epoch 10,imgs   320] loss: 0.7383693  time: 0.933 s\n",
      "[epoch 10,imgs   360] loss: 0.7400129  time: 0.934 s\n",
      "[epoch 10,imgs   400] loss: 0.7325369  time: 0.936 s\n",
      "[epoch 10,imgs   440] loss: 0.7376691  time: 0.936 s\n",
      "[epoch 10,imgs   480] loss: 0.7328303  time: 0.936 s\n",
      "[epoch 10,imgs   520] loss: 0.7342029  time: 0.934 s\n",
      "[epoch 10,imgs   560] loss: 0.7400944  time: 0.936 s\n",
      "[epoch 10,imgs   600] loss: 0.7402453  time: 0.935 s\n",
      "[epoch 10,imgs   640] loss: 0.7403570  time: 0.936 s\n",
      "[epoch 10,imgs   680] loss: 0.7375591  time: 0.932 s\n",
      "[epoch 10,imgs   720] loss: 0.7379647  time: 0.936 s\n",
      "[epoch 10,imgs   760] loss: 0.7371639  time: 0.941 s\n",
      "[epoch 10,imgs   800] loss: 0.7365519  time: 0.934 s\n",
      "[epoch 10,imgs   840] loss: 0.7433234  time: 0.933 s\n",
      "[epoch 10,imgs   880] loss: 0.7410042  time: 0.936 s\n",
      "[epoch 10,imgs   920] loss: 0.7395707  time: 0.933 s\n",
      "[epoch 10,imgs   960] loss: 0.7324502  time: 0.933 s\n",
      "[epoch 10,imgs  1000] loss: 0.7400404  time: 0.933 s\n",
      "[epoch 10,imgs  1040] loss: 0.7359269  time: 0.939 s\n",
      "[epoch 10,imgs  1080] loss: 0.7374107  time: 0.935 s\n",
      "[epoch 10,imgs  1120] loss: 0.7354227  time: 0.935 s\n",
      "[epoch 10,imgs  1160] loss: 0.7413200  time: 0.934 s\n",
      "[epoch 10,imgs  1200] loss: 0.7386004  time: 0.932 s\n",
      "[epoch 11,imgs    40] loss: 0.7400946  time: 1.342 s\n",
      "[epoch 11,imgs    80] loss: 0.7383375  time: 0.935 s\n",
      "[epoch 11,imgs   120] loss: 0.7391622  time: 0.934 s\n",
      "[epoch 11,imgs   160] loss: 0.7419091  time: 0.934 s\n",
      "[epoch 11,imgs   200] loss: 0.7353873  time: 0.934 s\n",
      "[epoch 11,imgs   240] loss: 0.7373265  time: 0.934 s\n",
      "[epoch 11,imgs   280] loss: 0.7351494  time: 0.934 s\n",
      "[epoch 11,imgs   320] loss: 0.7384362  time: 0.935 s\n",
      "[epoch 11,imgs   360] loss: 0.7387442  time: 0.935 s\n",
      "[epoch 11,imgs   400] loss: 0.7346699  time: 0.935 s\n",
      "[epoch 11,imgs   440] loss: 0.7393726  time: 0.934 s\n",
      "[epoch 11,imgs   480] loss: 0.7334588  time: 0.934 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 11,imgs   520] loss: 0.7387303  time: 0.934 s\n",
      "[epoch 11,imgs   560] loss: 0.7383431  time: 0.935 s\n",
      "[epoch 11,imgs   600] loss: 0.7369595  time: 0.935 s\n",
      "[epoch 11,imgs   640] loss: 0.7385309  time: 0.935 s\n",
      "[epoch 11,imgs   680] loss: 0.7406453  time: 0.930 s\n",
      "[epoch 11,imgs   720] loss: 0.7375014  time: 0.935 s\n",
      "[epoch 11,imgs   760] loss: 0.7388705  time: 0.943 s\n",
      "[epoch 11,imgs   800] loss: 0.7338961  time: 0.937 s\n",
      "[epoch 11,imgs   840] loss: 0.7401778  time: 0.938 s\n",
      "[epoch 11,imgs   880] loss: 0.7403925  time: 0.937 s\n",
      "[epoch 11,imgs   920] loss: 0.7397698  time: 0.938 s\n",
      "[epoch 11,imgs   960] loss: 0.7399380  time: 0.936 s\n",
      "[epoch 11,imgs  1000] loss: 0.7379647  time: 0.939 s\n",
      "[epoch 11,imgs  1040] loss: 0.7384796  time: 0.939 s\n",
      "[epoch 11,imgs  1080] loss: 0.7369708  time: 0.936 s\n",
      "[epoch 11,imgs  1120] loss: 0.7374852  time: 0.937 s\n",
      "[epoch 11,imgs  1160] loss: 0.7401639  time: 0.936 s\n",
      "[epoch 11,imgs  1200] loss: 0.7351434  time: 0.937 s\n",
      "[epoch 12,imgs    40] loss: 0.7393758  time: 1.328 s\n",
      "[epoch 12,imgs    80] loss: 0.7389150  time: 0.937 s\n",
      "[epoch 12,imgs   120] loss: 0.7356379  time: 0.938 s\n",
      "[epoch 12,imgs   160] loss: 0.7380995  time: 0.938 s\n",
      "[epoch 12,imgs   200] loss: 0.7383884  time: 0.936 s\n",
      "[epoch 12,imgs   240] loss: 0.7391500  time: 0.937 s\n",
      "[epoch 12,imgs   280] loss: 0.7422163  time: 0.936 s\n",
      "[epoch 12,imgs   320] loss: 0.7341579  time: 0.936 s\n",
      "[epoch 12,imgs   360] loss: 0.7394276  time: 0.938 s\n",
      "[epoch 12,imgs   400] loss: 0.7433593  time: 0.936 s\n",
      "[epoch 12,imgs   440] loss: 0.7400786  time: 0.935 s\n",
      "[epoch 12,imgs   480] loss: 0.7415892  time: 0.937 s\n",
      "[epoch 12,imgs   520] loss: 0.7367741  time: 0.937 s\n",
      "[epoch 12,imgs   560] loss: 0.7353012  time: 0.938 s\n",
      "[epoch 12,imgs   600] loss: 0.7431096  time: 0.936 s\n",
      "[epoch 12,imgs   640] loss: 0.7360528  time: 0.937 s\n",
      "[epoch 12,imgs   680] loss: 0.7336733  time: 0.938 s\n",
      "[epoch 12,imgs   720] loss: 0.7391781  time: 0.933 s\n",
      "[epoch 12,imgs   760] loss: 0.7368867  time: 0.935 s\n",
      "[epoch 12,imgs   800] loss: 0.7437083  time: 0.939 s\n",
      "[epoch 12,imgs   840] loss: 0.7408170  time: 0.934 s\n",
      "[epoch 12,imgs   880] loss: 0.7398396  time: 0.936 s\n",
      "[epoch 12,imgs   920] loss: 0.7439889  time: 0.934 s\n",
      "[epoch 12,imgs   960] loss: 0.7440639  time: 0.935 s\n",
      "[epoch 12,imgs  1000] loss: 0.7376211  time: 0.937 s\n",
      "[epoch 12,imgs  1040] loss: 0.7390682  time: 0.936 s\n",
      "[epoch 12,imgs  1080] loss: 0.7388747  time: 0.935 s\n",
      "[epoch 12,imgs  1120] loss: 0.7407663  time: 0.937 s\n",
      "[epoch 12,imgs  1160] loss: 0.7403095  time: 0.936 s\n",
      "[epoch 12,imgs  1200] loss: 0.7373996  time: 0.937 s\n",
      "[epoch 13,imgs    40] loss: 0.7416993  time: 1.377 s\n",
      "[epoch 13,imgs    80] loss: 0.7385607  time: 0.936 s\n",
      "[epoch 13,imgs   120] loss: 0.7371101  time: 0.952 s\n",
      "[epoch 13,imgs   160] loss: 0.7351542  time: 0.944 s\n",
      "[epoch 13,imgs   200] loss: 0.7382303  time: 0.935 s\n",
      "[epoch 13,imgs   240] loss: 0.7402419  time: 0.935 s\n",
      "[epoch 13,imgs   280] loss: 0.7349663  time: 0.935 s\n",
      "[epoch 13,imgs   320] loss: 0.7388570  time: 0.940 s\n",
      "[epoch 13,imgs   360] loss: 0.7367421  time: 0.936 s\n",
      "[epoch 13,imgs   400] loss: 0.7395213  time: 0.937 s\n",
      "[epoch 13,imgs   440] loss: 0.7387186  time: 0.935 s\n",
      "[epoch 13,imgs   480] loss: 0.7347072  time: 0.937 s\n",
      "[epoch 13,imgs   520] loss: 0.7331157  time: 0.935 s\n",
      "[epoch 13,imgs   560] loss: 0.7372903  time: 0.935 s\n",
      "[epoch 13,imgs   600] loss: 0.7381517  time: 0.936 s\n",
      "[epoch 13,imgs   640] loss: 0.7367325  time: 0.934 s\n",
      "[epoch 13,imgs   680] loss: 0.7353541  time: 0.934 s\n",
      "[epoch 13,imgs   720] loss: 0.7352303  time: 0.934 s\n",
      "[epoch 13,imgs   760] loss: 0.7335176  time: 0.936 s\n",
      "[epoch 13,imgs   800] loss: 0.7402134  time: 0.935 s\n",
      "[epoch 13,imgs   840] loss: 0.7401438  time: 0.933 s\n",
      "[epoch 13,imgs   880] loss: 0.7370909  time: 0.934 s\n",
      "[epoch 13,imgs   920] loss: 0.7406442  time: 0.938 s\n",
      "[epoch 13,imgs   960] loss: 0.7373791  time: 0.934 s\n",
      "[epoch 13,imgs  1000] loss: 0.7434556  time: 0.936 s\n",
      "[epoch 13,imgs  1040] loss: 0.7404110  time: 0.934 s\n",
      "[epoch 13,imgs  1080] loss: 0.7403119  time: 0.935 s\n",
      "[epoch 13,imgs  1120] loss: 0.7363663  time: 0.933 s\n",
      "[epoch 13,imgs  1160] loss: 0.7333840  time: 0.935 s\n",
      "[epoch 13,imgs  1200] loss: 0.7377763  time: 0.931 s\n",
      "[epoch 14,imgs    40] loss: 0.7398887  time: 1.334 s\n",
      "[epoch 14,imgs    80] loss: 0.7367915  time: 0.935 s\n",
      "[epoch 14,imgs   120] loss: 0.7361363  time: 0.934 s\n",
      "[epoch 14,imgs   160] loss: 0.7386366  time: 0.932 s\n",
      "[epoch 14,imgs   200] loss: 0.7403619  time: 0.935 s\n",
      "[epoch 14,imgs   240] loss: 0.7380669  time: 0.935 s\n",
      "[epoch 14,imgs   280] loss: 0.7349188  time: 0.933 s\n",
      "[epoch 14,imgs   320] loss: 0.7372222  time: 0.939 s\n",
      "[epoch 14,imgs   360] loss: 0.7362505  time: 0.933 s\n",
      "[epoch 14,imgs   400] loss: 0.7372177  time: 0.933 s\n",
      "[epoch 14,imgs   440] loss: 0.7387173  time: 0.933 s\n",
      "[epoch 14,imgs   480] loss: 0.7380135  time: 0.934 s\n",
      "[epoch 14,imgs   520] loss: 0.7424048  time: 0.934 s\n",
      "[epoch 14,imgs   560] loss: 0.7398141  time: 0.934 s\n",
      "[epoch 14,imgs   600] loss: 0.7403167  time: 0.935 s\n",
      "[epoch 14,imgs   640] loss: 0.7359297  time: 0.934 s\n",
      "[epoch 14,imgs   680] loss: 0.7436966  time: 0.934 s\n",
      "[epoch 14,imgs   720] loss: 0.7340938  time: 0.940 s\n",
      "[epoch 14,imgs   760] loss: 0.7386800  time: 0.937 s\n",
      "[epoch 14,imgs   800] loss: 0.7374290  time: 0.938 s\n",
      "[epoch 14,imgs   840] loss: 0.7405334  time: 0.937 s\n",
      "[epoch 14,imgs   880] loss: 0.7391143  time: 0.937 s\n",
      "[epoch 14,imgs   920] loss: 0.7385821  time: 0.938 s\n",
      "[epoch 14,imgs   960] loss: 0.7351288  time: 0.936 s\n",
      "[epoch 14,imgs  1000] loss: 0.7408004  time: 0.935 s\n",
      "[epoch 14,imgs  1040] loss: 0.7366015  time: 0.935 s\n",
      "[epoch 14,imgs  1080] loss: 0.7401918  time: 0.935 s\n",
      "[epoch 14,imgs  1120] loss: 0.7370329  time: 0.934 s\n",
      "[epoch 14,imgs  1160] loss: 0.7376831  time: 0.936 s\n",
      "[epoch 14,imgs  1200] loss: 0.7353042  time: 0.933 s\n",
      "[epoch 15,imgs    40] loss: 0.7372171  time: 1.333 s\n",
      "[epoch 15,imgs    80] loss: 0.7341331  time: 0.934 s\n",
      "[epoch 15,imgs   120] loss: 0.7353508  time: 0.934 s\n",
      "[epoch 15,imgs   160] loss: 0.7385754  time: 0.935 s\n",
      "[epoch 15,imgs   200] loss: 0.7437218  time: 0.935 s\n",
      "[epoch 15,imgs   240] loss: 0.7385759  time: 0.936 s\n",
      "[epoch 15,imgs   280] loss: 0.7406654  time: 0.935 s\n",
      "[epoch 15,imgs   320] loss: 0.7376878  time: 0.934 s\n",
      "[epoch 15,imgs   360] loss: 0.7376203  time: 0.936 s\n",
      "[epoch 15,imgs   400] loss: 0.7379879  time: 0.934 s\n",
      "[epoch 15,imgs   440] loss: 0.7371432  time: 0.935 s\n",
      "[epoch 15,imgs   480] loss: 0.7367358  time: 0.935 s\n",
      "[epoch 15,imgs   520] loss: 0.7387636  time: 0.934 s\n",
      "[epoch 15,imgs   560] loss: 0.7367547  time: 0.936 s\n",
      "[epoch 15,imgs   600] loss: 0.7386082  time: 0.936 s\n",
      "[epoch 15,imgs   640] loss: 0.7371309  time: 0.937 s\n",
      "[epoch 15,imgs   680] loss: 0.7356292  time: 0.933 s\n",
      "[epoch 15,imgs   720] loss: 0.7390484  time: 0.934 s\n",
      "[epoch 15,imgs   760] loss: 0.7345536  time: 0.935 s\n",
      "[epoch 15,imgs   800] loss: 0.7360398  time: 0.936 s\n",
      "[epoch 15,imgs   840] loss: 0.7383127  time: 0.937 s\n",
      "[epoch 15,imgs   880] loss: 0.7362845  time: 0.935 s\n",
      "[epoch 15,imgs   920] loss: 0.7383832  time: 0.934 s\n",
      "[epoch 15,imgs   960] loss: 0.7395895  time: 0.937 s\n",
      "[epoch 15,imgs  1000] loss: 0.7405353  time: 0.935 s\n",
      "[epoch 15,imgs  1040] loss: 0.7365271  time: 0.939 s\n",
      "[epoch 15,imgs  1080] loss: 0.7376086  time: 0.937 s\n",
      "[epoch 15,imgs  1120] loss: 0.7386356  time: 0.934 s\n",
      "[epoch 15,imgs  1160] loss: 0.7353041  time: 0.938 s\n",
      "[epoch 15,imgs  1200] loss: 0.7356374  time: 0.935 s\n",
      "[epoch 16,imgs    40] loss: 0.7352533  time: 1.325 s\n",
      "[epoch 16,imgs    80] loss: 0.7340029  time: 0.940 s\n",
      "[epoch 16,imgs   120] loss: 0.7359099  time: 0.936 s\n",
      "[epoch 16,imgs   160] loss: 0.7372006  time: 0.937 s\n",
      "[epoch 16,imgs   200] loss: 0.7384946  time: 0.935 s\n",
      "[epoch 16,imgs   240] loss: 0.7408274  time: 0.933 s\n",
      "[epoch 16,imgs   280] loss: 0.7390996  time: 0.934 s\n",
      "[epoch 16,imgs   320] loss: 0.7383250  time: 0.933 s\n",
      "[epoch 16,imgs   360] loss: 0.7415939  time: 0.935 s\n",
      "[epoch 16,imgs   400] loss: 0.7389543  time: 0.931 s\n",
      "[epoch 16,imgs   440] loss: 0.7414311  time: 0.933 s\n",
      "[epoch 16,imgs   480] loss: 0.7391818  time: 0.934 s\n",
      "[epoch 16,imgs   520] loss: 0.7399344  time: 0.933 s\n",
      "[epoch 16,imgs   560] loss: 0.7414007  time: 0.934 s\n",
      "[epoch 16,imgs   600] loss: 0.7368071  time: 0.939 s\n",
      "[epoch 16,imgs   640] loss: 0.7356585  time: 0.933 s\n",
      "[epoch 16,imgs   680] loss: 0.7421347  time: 0.935 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 16,imgs   720] loss: 0.7399348  time: 0.941 s\n",
      "[epoch 16,imgs   760] loss: 0.7372630  time: 0.934 s\n",
      "[epoch 16,imgs   800] loss: 0.7387965  time: 0.942 s\n",
      "[epoch 16,imgs   840] loss: 0.7401462  time: 0.935 s\n",
      "[epoch 16,imgs   880] loss: 0.7391950  time: 0.944 s\n",
      "[epoch 16,imgs   920] loss: 0.7441376  time: 0.933 s\n",
      "[epoch 16,imgs   960] loss: 0.7364734  time: 0.933 s\n",
      "[epoch 16,imgs  1000] loss: 0.7418770  time: 0.951 s\n",
      "[epoch 16,imgs  1040] loss: 0.7423965  time: 0.938 s\n",
      "[epoch 16,imgs  1080] loss: 0.7385496  time: 0.933 s\n",
      "[epoch 16,imgs  1120] loss: 0.7374170  time: 0.935 s\n",
      "[epoch 16,imgs  1160] loss: 0.7392739  time: 0.935 s\n",
      "[epoch 16,imgs  1200] loss: 0.7406347  time: 0.935 s\n",
      "[epoch 17,imgs    40] loss: 0.7418728  time: 1.349 s\n",
      "[epoch 17,imgs    80] loss: 0.7395778  time: 0.932 s\n",
      "[epoch 17,imgs   120] loss: 0.7351792  time: 0.933 s\n",
      "[epoch 17,imgs   160] loss: 0.7420490  time: 0.932 s\n",
      "[epoch 17,imgs   200] loss: 0.7366135  time: 0.931 s\n",
      "[epoch 17,imgs   240] loss: 0.7376568  time: 0.934 s\n",
      "[epoch 17,imgs   280] loss: 0.7363343  time: 0.935 s\n",
      "[epoch 17,imgs   320] loss: 0.7398225  time: 0.934 s\n",
      "[epoch 17,imgs   360] loss: 0.7427169  time: 0.934 s\n",
      "[epoch 17,imgs   400] loss: 0.7341299  time: 0.931 s\n",
      "[epoch 17,imgs   440] loss: 0.7389055  time: 0.934 s\n",
      "[epoch 17,imgs   480] loss: 0.7343005  time: 0.932 s\n",
      "[epoch 17,imgs   520] loss: 0.7379403  time: 0.936 s\n",
      "[epoch 17,imgs   560] loss: 0.7389481  time: 0.932 s\n",
      "[epoch 17,imgs   600] loss: 0.7382838  time: 0.933 s\n",
      "[epoch 17,imgs   640] loss: 0.7412695  time: 0.935 s\n",
      "[epoch 17,imgs   680] loss: 0.7413113  time: 0.939 s\n",
      "[epoch 17,imgs   720] loss: 0.7399004  time: 0.934 s\n",
      "[epoch 17,imgs   760] loss: 0.7398814  time: 0.932 s\n",
      "[epoch 17,imgs   800] loss: 0.7390380  time: 0.934 s\n",
      "[epoch 17,imgs   840] loss: 0.7398015  time: 0.949 s\n",
      "[epoch 17,imgs   880] loss: 0.7405136  time: 0.938 s\n",
      "[epoch 17,imgs   920] loss: 0.7408980  time: 0.933 s\n",
      "[epoch 17,imgs   960] loss: 0.7378794  time: 0.934 s\n",
      "[epoch 17,imgs  1000] loss: 0.7403587  time: 0.931 s\n",
      "[epoch 17,imgs  1040] loss: 0.7429082  time: 0.933 s\n",
      "[epoch 17,imgs  1080] loss: 0.7355223  time: 0.945 s\n",
      "[epoch 17,imgs  1120] loss: 0.7394837  time: 0.933 s\n",
      "[epoch 17,imgs  1160] loss: 0.7423910  time: 0.932 s\n",
      "[epoch 17,imgs  1200] loss: 0.7372811  time: 0.929 s\n",
      "[epoch 18,imgs    40] loss: 0.7432151  time: 1.317 s\n",
      "[epoch 18,imgs    80] loss: 0.7392895  time: 0.934 s\n",
      "[epoch 18,imgs   120] loss: 0.7409393  time: 0.934 s\n",
      "[epoch 18,imgs   160] loss: 0.7438712  time: 0.931 s\n",
      "[epoch 18,imgs   200] loss: 0.7354267  time: 0.932 s\n",
      "[epoch 18,imgs   240] loss: 0.7356805  time: 0.934 s\n",
      "[epoch 18,imgs   280] loss: 0.7467608  time: 0.933 s\n",
      "[epoch 18,imgs   320] loss: 0.7416952  time: 0.935 s\n",
      "[epoch 18,imgs   360] loss: 0.7368239  time: 0.933 s\n",
      "[epoch 18,imgs   400] loss: 0.7358835  time: 0.934 s\n",
      "[epoch 18,imgs   440] loss: 0.7390882  time: 0.932 s\n",
      "[epoch 18,imgs   480] loss: 0.7436951  time: 0.933 s\n",
      "[epoch 18,imgs   520] loss: 0.7403698  time: 0.952 s\n",
      "[epoch 18,imgs   560] loss: 0.7393708  time: 0.938 s\n",
      "[epoch 18,imgs   600] loss: 0.7330353  time: 0.934 s\n",
      "[epoch 18,imgs   640] loss: 0.7323845  time: 0.934 s\n",
      "[epoch 18,imgs   680] loss: 0.7431799  time: 0.933 s\n",
      "[epoch 18,imgs   720] loss: 0.7395254  time: 0.936 s\n",
      "[epoch 18,imgs   760] loss: 0.7345947  time: 0.934 s\n",
      "[epoch 18,imgs   800] loss: 0.7415912  time: 0.942 s\n",
      "[epoch 18,imgs   840] loss: 0.7394122  time: 0.950 s\n",
      "[epoch 18,imgs   880] loss: 0.7388142  time: 0.937 s\n",
      "[epoch 18,imgs   920] loss: 0.7366532  time: 0.932 s\n",
      "[epoch 18,imgs   960] loss: 0.7338403  time: 0.934 s\n",
      "[epoch 18,imgs  1000] loss: 0.7378603  time: 0.933 s\n",
      "[epoch 18,imgs  1040] loss: 0.7407483  time: 0.934 s\n",
      "[epoch 18,imgs  1080] loss: 0.7350606  time: 0.933 s\n",
      "[epoch 18,imgs  1120] loss: 0.7404383  time: 0.933 s\n",
      "[epoch 18,imgs  1160] loss: 0.7391742  time: 0.933 s\n",
      "[epoch 18,imgs  1200] loss: 0.7400929  time: 0.931 s\n",
      "[epoch 19,imgs    40] loss: 0.7377481  time: 1.321 s\n",
      "[epoch 19,imgs    80] loss: 0.7404676  time: 0.934 s\n",
      "[epoch 19,imgs   120] loss: 0.7378281  time: 0.934 s\n",
      "[epoch 19,imgs   160] loss: 0.7371368  time: 0.934 s\n",
      "[epoch 19,imgs   200] loss: 0.7352990  time: 0.933 s\n",
      "[epoch 19,imgs   240] loss: 0.7410150  time: 0.934 s\n",
      "[epoch 19,imgs   280] loss: 0.7356721  time: 0.941 s\n",
      "[epoch 19,imgs   320] loss: 0.7374069  time: 0.942 s\n",
      "[epoch 19,imgs   360] loss: 0.7394608  time: 0.931 s\n",
      "[epoch 19,imgs   400] loss: 0.7374971  time: 0.933 s\n",
      "[epoch 19,imgs   440] loss: 0.7423044  time: 0.933 s\n",
      "[epoch 19,imgs   480] loss: 0.7337647  time: 0.934 s\n",
      "[epoch 19,imgs   520] loss: 0.7361215  time: 0.934 s\n",
      "[epoch 19,imgs   560] loss: 0.7374126  time: 0.937 s\n",
      "[epoch 19,imgs   600] loss: 0.7364652  time: 0.931 s\n",
      "[epoch 19,imgs   640] loss: 0.7380306  time: 0.936 s\n",
      "[epoch 19,imgs   680] loss: 0.7367281  time: 0.966 s\n",
      "[epoch 19,imgs   720] loss: 0.7371361  time: 0.941 s\n",
      "[epoch 19,imgs   760] loss: 0.7392383  time: 0.934 s\n",
      "[epoch 19,imgs   800] loss: 0.7378983  time: 0.961 s\n",
      "[epoch 19,imgs   840] loss: 0.7391850  time: 0.944 s\n",
      "[epoch 19,imgs   880] loss: 0.7356179  time: 0.934 s\n",
      "[epoch 19,imgs   920] loss: 0.7389475  time: 0.933 s\n",
      "[epoch 19,imgs   960] loss: 0.7441602  time: 0.933 s\n",
      "[epoch 19,imgs  1000] loss: 0.7398496  time: 0.934 s\n",
      "[epoch 19,imgs  1040] loss: 0.7368104  time: 0.934 s\n",
      "[epoch 19,imgs  1080] loss: 0.7338573  time: 0.934 s\n",
      "[epoch 19,imgs  1120] loss: 0.7379075  time: 0.936 s\n",
      "[epoch 19,imgs  1160] loss: 0.7388065  time: 0.933 s\n",
      "[epoch 19,imgs  1200] loss: 0.7366949  time: 0.930 s\n",
      "[epoch 20,imgs    40] loss: 0.7385889  time: 1.322 s\n",
      "[epoch 20,imgs    80] loss: 0.7408994  time: 0.935 s\n",
      "[epoch 20,imgs   120] loss: 0.7379724  time: 0.934 s\n",
      "[epoch 20,imgs   160] loss: 0.7402403  time: 0.933 s\n",
      "[epoch 20,imgs   200] loss: 0.7417843  time: 0.933 s\n",
      "[epoch 20,imgs   240] loss: 0.7368645  time: 0.932 s\n",
      "[epoch 20,imgs   280] loss: 0.7384309  time: 0.939 s\n",
      "[epoch 20,imgs   320] loss: 0.7399924  time: 0.952 s\n",
      "[epoch 20,imgs   360] loss: 0.7388262  time: 0.932 s\n",
      "[epoch 20,imgs   400] loss: 0.7377652  time: 0.932 s\n",
      "[epoch 20,imgs   440] loss: 0.7398887  time: 0.932 s\n",
      "[epoch 20,imgs   480] loss: 0.7396252  time: 0.935 s\n",
      "[epoch 20,imgs   520] loss: 0.7396508  time: 0.934 s\n",
      "[epoch 20,imgs   560] loss: 0.7376828  time: 0.934 s\n",
      "[epoch 20,imgs   600] loss: 0.7395753  time: 0.937 s\n",
      "[epoch 20,imgs   640] loss: 0.7377563  time: 0.933 s\n",
      "[epoch 20,imgs   680] loss: 0.7432504  time: 0.943 s\n",
      "[epoch 20,imgs   720] loss: 0.7364569  time: 0.942 s\n",
      "[epoch 20,imgs   760] loss: 0.7339941  time: 0.934 s\n",
      "[epoch 20,imgs   800] loss: 0.7427076  time: 0.937 s\n",
      "[epoch 20,imgs   840] loss: 0.7391809  time: 0.941 s\n",
      "[epoch 20,imgs   880] loss: 0.7355808  time: 0.936 s\n",
      "[epoch 20,imgs   920] loss: 0.7344635  time: 0.936 s\n",
      "[epoch 20,imgs   960] loss: 0.7365826  time: 0.935 s\n",
      "[epoch 20,imgs  1000] loss: 0.7422767  time: 0.942 s\n",
      "[epoch 20,imgs  1040] loss: 0.7375522  time: 0.945 s\n",
      "[epoch 20,imgs  1080] loss: 0.7351909  time: 0.936 s\n",
      "[epoch 20,imgs  1120] loss: 0.7394375  time: 0.939 s\n",
      "[epoch 20,imgs  1160] loss: 0.7376006  time: 0.934 s\n",
      "[epoch 20,imgs  1200] loss: 0.7353585  time: 0.948 s\n",
      "[epoch 21,imgs    40] loss: 0.7398208  time: 1.324 s\n",
      "[epoch 21,imgs    80] loss: 0.7353991  time: 0.945 s\n",
      "[epoch 21,imgs   120] loss: 0.7387657  time: 0.936 s\n",
      "[epoch 21,imgs   160] loss: 0.7408096  time: 0.935 s\n",
      "[epoch 21,imgs   200] loss: 0.7368397  time: 0.941 s\n",
      "[epoch 21,imgs   240] loss: 0.7361794  time: 0.941 s\n",
      "[epoch 21,imgs   280] loss: 0.7359372  time: 0.935 s\n",
      "[epoch 21,imgs   320] loss: 0.7319351  time: 0.939 s\n",
      "[epoch 21,imgs   360] loss: 0.7402714  time: 0.935 s\n",
      "[epoch 21,imgs   400] loss: 0.7369493  time: 0.934 s\n",
      "[epoch 21,imgs   440] loss: 0.7415715  time: 0.939 s\n",
      "[epoch 21,imgs   480] loss: 0.7360690  time: 0.936 s\n",
      "[epoch 21,imgs   520] loss: 0.7429401  time: 0.940 s\n",
      "[epoch 21,imgs   560] loss: 0.7416426  time: 0.945 s\n",
      "[epoch 21,imgs   600] loss: 0.7378801  time: 0.937 s\n",
      "[epoch 21,imgs   640] loss: 0.7395721  time: 0.935 s\n",
      "[epoch 21,imgs   680] loss: 0.7418934  time: 0.945 s\n",
      "[epoch 21,imgs   720] loss: 0.7421681  time: 0.936 s\n",
      "[epoch 21,imgs   760] loss: 0.7413323  time: 0.947 s\n",
      "[epoch 21,imgs   800] loss: 0.7426054  time: 0.941 s\n",
      "[epoch 21,imgs   840] loss: 0.7359404  time: 0.943 s\n",
      "[epoch 21,imgs   880] loss: 0.7395271  time: 0.944 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21,imgs   920] loss: 0.7374574  time: 0.935 s\n",
      "[epoch 21,imgs   960] loss: 0.7420740  time: 0.936 s\n",
      "[epoch 21,imgs  1000] loss: 0.7377959  time: 0.956 s\n",
      "[epoch 21,imgs  1040] loss: 0.7347416  time: 0.935 s\n",
      "[epoch 21,imgs  1080] loss: 0.7336783  time: 0.940 s\n",
      "[epoch 21,imgs  1120] loss: 0.7417535  time: 0.952 s\n",
      "[epoch 21,imgs  1160] loss: 0.7377763  time: 0.940 s\n",
      "[epoch 21,imgs  1200] loss: 0.7360905  time: 0.947 s\n",
      "[epoch 22,imgs    40] loss: 0.7388805  time: 1.327 s\n",
      "[epoch 22,imgs    80] loss: 0.7397828  time: 0.937 s\n",
      "[epoch 22,imgs   120] loss: 0.7362656  time: 0.940 s\n",
      "[epoch 22,imgs   160] loss: 0.7345927  time: 0.944 s\n",
      "[epoch 22,imgs   200] loss: 0.7356947  time: 0.934 s\n",
      "[epoch 22,imgs   240] loss: 0.7448137  time: 0.933 s\n",
      "[epoch 22,imgs   280] loss: 0.7343153  time: 0.935 s\n",
      "[epoch 22,imgs   320] loss: 0.7364736  time: 0.941 s\n",
      "[epoch 22,imgs   360] loss: 0.7353471  time: 0.938 s\n",
      "[epoch 22,imgs   400] loss: 0.7439263  time: 0.938 s\n",
      "[epoch 22,imgs   440] loss: 0.7399565  time: 0.935 s\n",
      "[epoch 22,imgs   480] loss: 0.7426484  time: 0.936 s\n",
      "[epoch 22,imgs   520] loss: 0.7365165  time: 0.940 s\n",
      "[epoch 22,imgs   560] loss: 0.7337500  time: 0.936 s\n",
      "[epoch 22,imgs   600] loss: 0.7391284  time: 0.944 s\n",
      "[epoch 22,imgs   640] loss: 0.7399371  time: 0.946 s\n",
      "[epoch 22,imgs   680] loss: 0.7393644  time: 0.935 s\n",
      "[epoch 22,imgs   720] loss: 0.7395000  time: 0.936 s\n",
      "[epoch 22,imgs   760] loss: 0.7375143  time: 0.936 s\n",
      "[epoch 22,imgs   800] loss: 0.7332519  time: 0.938 s\n",
      "[epoch 22,imgs   840] loss: 0.7396789  time: 0.949 s\n",
      "[epoch 22,imgs   880] loss: 0.7360100  time: 0.935 s\n",
      "[epoch 22,imgs   920] loss: 0.7405181  time: 0.956 s\n",
      "[epoch 22,imgs   960] loss: 0.7373150  time: 0.967 s\n",
      "[epoch 22,imgs  1000] loss: 0.7353442  time: 0.938 s\n",
      "[epoch 22,imgs  1040] loss: 0.7400183  time: 0.935 s\n",
      "[epoch 22,imgs  1080] loss: 0.7404633  time: 0.956 s\n",
      "[epoch 22,imgs  1120] loss: 0.7385709  time: 0.952 s\n",
      "[epoch 22,imgs  1160] loss: 0.7326388  time: 0.938 s\n",
      "[epoch 22,imgs  1200] loss: 0.7330816  time: 0.937 s\n",
      "[epoch 23,imgs    40] loss: 0.7412988  time: 1.349 s\n",
      "[epoch 23,imgs    80] loss: 0.7403434  time: 0.935 s\n",
      "[epoch 23,imgs   120] loss: 0.7393734  time: 0.935 s\n",
      "[epoch 23,imgs   160] loss: 0.7361783  time: 0.933 s\n",
      "[epoch 23,imgs   200] loss: 0.7329249  time: 0.934 s\n",
      "[epoch 23,imgs   240] loss: 0.7395221  time: 0.932 s\n",
      "[epoch 23,imgs   280] loss: 0.7413943  time: 0.934 s\n",
      "[epoch 23,imgs   320] loss: 0.7408178  time: 0.937 s\n",
      "[epoch 23,imgs   360] loss: 0.7413840  time: 0.933 s\n",
      "[epoch 23,imgs   400] loss: 0.7378165  time: 0.951 s\n",
      "[epoch 23,imgs   440] loss: 0.7364596  time: 0.953 s\n",
      "[epoch 23,imgs   480] loss: 0.7365426  time: 0.933 s\n",
      "[epoch 23,imgs   520] loss: 0.7384920  time: 0.935 s\n",
      "[epoch 23,imgs   560] loss: 0.7400882  time: 0.958 s\n",
      "[epoch 23,imgs   600] loss: 0.7414167  time: 0.939 s\n",
      "[epoch 23,imgs   640] loss: 0.7418694  time: 0.935 s\n",
      "[epoch 23,imgs   680] loss: 0.7392601  time: 0.937 s\n",
      "[epoch 23,imgs   720] loss: 0.7363568  time: 0.933 s\n",
      "[epoch 23,imgs   760] loss: 0.7395301  time: 0.948 s\n",
      "[epoch 23,imgs   800] loss: 0.7399658  time: 0.934 s\n",
      "[epoch 23,imgs   840] loss: 0.7391649  time: 0.934 s\n",
      "[epoch 23,imgs   880] loss: 0.7406287  time: 0.954 s\n",
      "[epoch 23,imgs   920] loss: 0.7369039  time: 0.937 s\n",
      "[epoch 23,imgs   960] loss: 0.7364768  time: 0.940 s\n",
      "[epoch 23,imgs  1000] loss: 0.7400266  time: 0.953 s\n",
      "[epoch 23,imgs  1040] loss: 0.7397789  time: 0.935 s\n",
      "[epoch 23,imgs  1080] loss: 0.7384680  time: 0.935 s\n",
      "[epoch 23,imgs  1120] loss: 0.7365196  time: 0.940 s\n",
      "[epoch 23,imgs  1160] loss: 0.7428965  time: 0.941 s\n",
      "[epoch 23,imgs  1200] loss: 0.7410474  time: 0.938 s\n",
      "[epoch 24,imgs    40] loss: 0.7389862  time: 1.335 s\n",
      "[epoch 24,imgs    80] loss: 0.7429457  time: 0.963 s\n",
      "[epoch 24,imgs   120] loss: 0.7337411  time: 0.948 s\n",
      "[epoch 24,imgs   160] loss: 0.7411554  time: 0.938 s\n",
      "[epoch 24,imgs   200] loss: 0.7383481  time: 0.936 s\n",
      "[epoch 24,imgs   240] loss: 0.7400891  time: 0.933 s\n",
      "[epoch 24,imgs   280] loss: 0.7369784  time: 0.936 s\n",
      "[epoch 24,imgs   320] loss: 0.7411035  time: 0.956 s\n",
      "[epoch 24,imgs   360] loss: 0.7379979  time: 0.948 s\n",
      "[epoch 24,imgs   400] loss: 0.7359999  time: 0.935 s\n",
      "[epoch 24,imgs   440] loss: 0.7405377  time: 0.944 s\n",
      "[epoch 24,imgs   480] loss: 0.7350927  time: 0.935 s\n",
      "[epoch 24,imgs   520] loss: 0.7414048  time: 0.936 s\n",
      "[epoch 24,imgs   560] loss: 0.7408101  time: 0.951 s\n",
      "[epoch 24,imgs   600] loss: 0.7372944  time: 0.933 s\n",
      "[epoch 24,imgs   640] loss: 0.7382052  time: 0.937 s\n",
      "[epoch 24,imgs   680] loss: 0.7420405  time: 0.943 s\n",
      "[epoch 24,imgs   720] loss: 0.7349089  time: 0.932 s\n",
      "[epoch 24,imgs   760] loss: 0.7359616  time: 0.946 s\n",
      "[epoch 24,imgs   800] loss: 0.7392506  time: 0.966 s\n",
      "[epoch 24,imgs   840] loss: 0.7376066  time: 0.936 s\n",
      "[epoch 24,imgs   880] loss: 0.7373740  time: 0.933 s\n",
      "[epoch 24,imgs   920] loss: 0.7360954  time: 0.934 s\n",
      "[epoch 24,imgs   960] loss: 0.7359467  time: 0.932 s\n",
      "[epoch 24,imgs  1000] loss: 0.7350293  time: 0.933 s\n",
      "[epoch 24,imgs  1040] loss: 0.7386800  time: 0.946 s\n",
      "[epoch 24,imgs  1080] loss: 0.7380961  time: 0.935 s\n",
      "[epoch 24,imgs  1120] loss: 0.7358658  time: 0.937 s\n",
      "[epoch 24,imgs  1160] loss: 0.7390897  time: 0.935 s\n",
      "[epoch 24,imgs  1200] loss: 0.7384899  time: 0.934 s\n",
      "[epoch 25,imgs    40] loss: 0.7384890  time: 1.317 s\n",
      "[epoch 25,imgs    80] loss: 0.7378186  time: 0.932 s\n",
      "[epoch 25,imgs   120] loss: 0.7398385  time: 0.942 s\n",
      "[epoch 25,imgs   160] loss: 0.7390108  time: 0.936 s\n",
      "[epoch 25,imgs   200] loss: 0.7340133  time: 0.945 s\n",
      "[epoch 25,imgs   240] loss: 0.7376083  time: 0.939 s\n",
      "[epoch 25,imgs   280] loss: 0.7400296  time: 0.934 s\n",
      "[epoch 25,imgs   320] loss: 0.7378775  time: 0.940 s\n",
      "[epoch 25,imgs   360] loss: 0.7402450  time: 0.936 s\n",
      "[epoch 25,imgs   400] loss: 0.7394077  time: 0.941 s\n",
      "[epoch 25,imgs   440] loss: 0.7377102  time: 0.955 s\n",
      "[epoch 25,imgs   480] loss: 0.7386346  time: 0.932 s\n",
      "[epoch 25,imgs   520] loss: 0.7374496  time: 0.935 s\n",
      "[epoch 25,imgs   560] loss: 0.7400582  time: 0.978 s\n",
      "[epoch 25,imgs   600] loss: 0.7355514  time: 0.945 s\n",
      "[epoch 25,imgs   640] loss: 0.7410916  time: 0.933 s\n",
      "[epoch 25,imgs   680] loss: 0.7347047  time: 0.938 s\n",
      "[epoch 25,imgs   720] loss: 0.7383644  time: 0.938 s\n",
      "[epoch 25,imgs   760] loss: 0.7403322  time: 0.935 s\n",
      "[epoch 25,imgs   800] loss: 0.7425843  time: 0.948 s\n",
      "[epoch 25,imgs   840] loss: 0.7390758  time: 0.934 s\n",
      "[epoch 25,imgs   880] loss: 0.7401006  time: 0.932 s\n",
      "[epoch 25,imgs   920] loss: 0.7384778  time: 0.941 s\n",
      "[epoch 25,imgs   960] loss: 0.7320718  time: 0.932 s\n",
      "[epoch 25,imgs  1000] loss: 0.7401554  time: 0.938 s\n",
      "[epoch 25,imgs  1040] loss: 0.7362403  time: 0.939 s\n",
      "[epoch 25,imgs  1080] loss: 0.7373453  time: 0.932 s\n",
      "[epoch 25,imgs  1120] loss: 0.7424917  time: 0.987 s\n",
      "[epoch 25,imgs  1160] loss: 0.7391235  time: 0.968 s\n",
      "[epoch 25,imgs  1200] loss: 0.7413977  time: 0.931 s\n",
      "[epoch 26,imgs    40] loss: 0.7348173  time: 1.337 s\n",
      "[epoch 26,imgs    80] loss: 0.7345173  time: 0.931 s\n",
      "[epoch 26,imgs   120] loss: 0.7431284  time: 0.933 s\n",
      "[epoch 26,imgs   160] loss: 0.7372764  time: 0.931 s\n",
      "[epoch 26,imgs   200] loss: 0.7335391  time: 0.934 s\n",
      "[epoch 26,imgs   240] loss: 0.7381836  time: 0.932 s\n",
      "[epoch 26,imgs   280] loss: 0.7388646  time: 0.946 s\n",
      "[epoch 26,imgs   320] loss: 0.7348903  time: 0.955 s\n",
      "[epoch 26,imgs   360] loss: 0.7335344  time: 0.933 s\n",
      "[epoch 26,imgs   400] loss: 0.7389916  time: 0.931 s\n",
      "[epoch 26,imgs   440] loss: 0.7346797  time: 0.931 s\n",
      "[epoch 26,imgs   480] loss: 0.7358381  time: 0.930 s\n",
      "[epoch 26,imgs   520] loss: 0.7342520  time: 0.933 s\n",
      "[epoch 26,imgs   560] loss: 0.7384048  time: 0.933 s\n",
      "[epoch 26,imgs   600] loss: 0.7366191  time: 0.950 s\n",
      "[epoch 26,imgs   640] loss: 0.7391001  time: 0.935 s\n",
      "[epoch 26,imgs   680] loss: 0.7321693  time: 0.933 s\n",
      "[epoch 26,imgs   720] loss: 0.7418330  time: 0.961 s\n",
      "[epoch 26,imgs   760] loss: 0.7345119  time: 0.937 s\n",
      "[epoch 26,imgs   800] loss: 0.7378056  time: 0.931 s\n",
      "[epoch 26,imgs   840] loss: 0.7393922  time: 0.939 s\n",
      "[epoch 26,imgs   880] loss: 0.7406108  time: 0.935 s\n",
      "[epoch 26,imgs   920] loss: 0.7389412  time: 0.931 s\n",
      "[epoch 26,imgs   960] loss: 0.7404650  time: 0.948 s\n",
      "[epoch 26,imgs  1000] loss: 0.7368383  time: 0.935 s\n",
      "[epoch 26,imgs  1040] loss: 0.7384511  time: 0.938 s\n",
      "[epoch 26,imgs  1080] loss: 0.7410042  time: 0.934 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 26,imgs  1120] loss: 0.7399349  time: 0.933 s\n",
      "[epoch 26,imgs  1160] loss: 0.7366934  time: 0.963 s\n",
      "[epoch 26,imgs  1200] loss: 0.7412032  time: 0.953 s\n",
      "[epoch 27,imgs    40] loss: 0.7399178  time: 1.313 s\n",
      "[epoch 27,imgs    80] loss: 0.7388549  time: 0.932 s\n",
      "[epoch 27,imgs   120] loss: 0.7318410  time: 0.933 s\n",
      "[epoch 27,imgs   160] loss: 0.7404664  time: 0.932 s\n",
      "[epoch 27,imgs   200] loss: 0.7381361  time: 0.932 s\n",
      "[epoch 27,imgs   240] loss: 0.7377214  time: 0.933 s\n",
      "[epoch 27,imgs   280] loss: 0.7408772  time: 0.944 s\n",
      "[epoch 27,imgs   320] loss: 0.7417981  time: 0.932 s\n",
      "[epoch 27,imgs   360] loss: 0.7377412  time: 0.933 s\n",
      "[epoch 27,imgs   400] loss: 0.7324619  time: 0.951 s\n",
      "[epoch 27,imgs   440] loss: 0.7396124  time: 0.932 s\n",
      "[epoch 27,imgs   480] loss: 0.7371341  time: 0.945 s\n",
      "[epoch 27,imgs   520] loss: 0.7362720  time: 0.936 s\n",
      "[epoch 27,imgs   560] loss: 0.7381522  time: 0.932 s\n",
      "[epoch 27,imgs   600] loss: 0.7372658  time: 0.942 s\n",
      "[epoch 27,imgs   640] loss: 0.7412979  time: 0.936 s\n",
      "[epoch 27,imgs   680] loss: 0.7352189  time: 0.937 s\n",
      "[epoch 27,imgs   720] loss: 0.7425374  time: 0.965 s\n",
      "[epoch 27,imgs   760] loss: 0.7421623  time: 0.934 s\n",
      "[epoch 27,imgs   800] loss: 0.7391353  time: 0.935 s\n",
      "[epoch 27,imgs   840] loss: 0.7382756  time: 0.950 s\n",
      "[epoch 27,imgs   880] loss: 0.7407268  time: 0.939 s\n",
      "[epoch 27,imgs   920] loss: 0.7403500  time: 0.932 s\n",
      "[epoch 27,imgs   960] loss: 0.7379361  time: 1.010 s\n",
      "[epoch 27,imgs  1000] loss: 0.7385572  time: 0.985 s\n",
      "[epoch 27,imgs  1040] loss: 0.7385460  time: 0.939 s\n",
      "[epoch 27,imgs  1080] loss: 0.7406067  time: 0.933 s\n",
      "[epoch 27,imgs  1120] loss: 0.7377514  time: 0.933 s\n",
      "[epoch 27,imgs  1160] loss: 0.7398803  time: 0.934 s\n",
      "[epoch 27,imgs  1200] loss: 0.7395923  time: 0.927 s\n",
      "[epoch 28,imgs    40] loss: 0.7364011  time: 1.352 s\n",
      "[epoch 28,imgs    80] loss: 0.7392117  time: 0.933 s\n",
      "[epoch 28,imgs   120] loss: 0.7383822  time: 0.933 s\n",
      "[epoch 28,imgs   160] loss: 0.7371864  time: 0.934 s\n",
      "[epoch 28,imgs   200] loss: 0.7393237  time: 0.960 s\n",
      "[epoch 28,imgs   240] loss: 0.7411664  time: 0.940 s\n",
      "[epoch 28,imgs   280] loss: 0.7384958  time: 0.934 s\n",
      "[epoch 28,imgs   320] loss: 0.7374469  time: 0.935 s\n",
      "[epoch 28,imgs   360] loss: 0.7398894  time: 0.933 s\n",
      "[epoch 28,imgs   400] loss: 0.7373692  time: 0.939 s\n",
      "[epoch 28,imgs   440] loss: 0.7332915  time: 0.934 s\n",
      "[epoch 28,imgs   480] loss: 0.7355419  time: 0.940 s\n",
      "[epoch 28,imgs   520] loss: 0.7422348  time: 0.956 s\n",
      "[epoch 28,imgs   560] loss: 0.7348539  time: 0.936 s\n",
      "[epoch 28,imgs   600] loss: 0.7423402  time: 0.934 s\n",
      "[epoch 28,imgs   640] loss: 0.7380712  time: 0.956 s\n",
      "[epoch 28,imgs   680] loss: 0.7411462  time: 0.934 s\n",
      "[epoch 28,imgs   720] loss: 0.7382753  time: 0.934 s\n",
      "[epoch 28,imgs   760] loss: 0.7396197  time: 0.941 s\n",
      "[epoch 28,imgs   800] loss: 0.7367660  time: 0.933 s\n",
      "[epoch 28,imgs   840] loss: 0.7389402  time: 0.944 s\n",
      "[epoch 28,imgs   880] loss: 0.7410041  time: 0.935 s\n",
      "[epoch 28,imgs   920] loss: 0.7382870  time: 0.934 s\n",
      "[epoch 28,imgs   960] loss: 0.7395464  time: 0.955 s\n",
      "[epoch 28,imgs  1000] loss: 0.7420336  time: 0.932 s\n",
      "[epoch 28,imgs  1040] loss: 0.7397990  time: 0.941 s\n",
      "[epoch 28,imgs  1080] loss: 0.7332091  time: 0.949 s\n",
      "[epoch 28,imgs  1120] loss: 0.7386401  time: 0.933 s\n",
      "[epoch 28,imgs  1160] loss: 0.7414788  time: 0.937 s\n",
      "[epoch 28,imgs  1200] loss: 0.7342553  time: 0.963 s\n",
      "[epoch 29,imgs    40] loss: 0.7361751  time: 1.363 s\n",
      "[epoch 29,imgs    80] loss: 0.7376657  time: 0.935 s\n",
      "[epoch 29,imgs   120] loss: 0.7418391  time: 0.937 s\n",
      "[epoch 29,imgs   160] loss: 0.7373105  time: 0.945 s\n",
      "[epoch 29,imgs   200] loss: 0.7393749  time: 0.944 s\n",
      "[epoch 29,imgs   240] loss: 0.7387934  time: 0.935 s\n",
      "[epoch 29,imgs   280] loss: 0.7391825  time: 0.940 s\n",
      "[epoch 29,imgs   320] loss: 0.7372756  time: 0.934 s\n",
      "[epoch 29,imgs   360] loss: 0.7403589  time: 0.983 s\n",
      "[epoch 29,imgs   400] loss: 0.7430628  time: 0.960 s\n",
      "[epoch 29,imgs   440] loss: 0.7382933  time: 0.936 s\n",
      "[epoch 29,imgs   480] loss: 0.7429666  time: 0.934 s\n",
      "[epoch 29,imgs   520] loss: 0.7358733  time: 0.953 s\n",
      "[epoch 29,imgs   560] loss: 0.7354747  time: 0.952 s\n",
      "[epoch 29,imgs   600] loss: 0.7390426  time: 0.936 s\n",
      "[epoch 29,imgs   640] loss: 0.7382178  time: 0.935 s\n",
      "[epoch 29,imgs   680] loss: 0.7410197  time: 0.939 s\n",
      "[epoch 29,imgs   720] loss: 0.7388148  time: 0.936 s\n",
      "[epoch 29,imgs   760] loss: 0.7382386  time: 1.023 s\n",
      "[epoch 29,imgs   800] loss: 0.7398252  time: 0.985 s\n",
      "[epoch 29,imgs   840] loss: 0.7389979  time: 0.945 s\n",
      "[epoch 29,imgs   880] loss: 0.7358003  time: 0.935 s\n",
      "[epoch 29,imgs   920] loss: 0.7396587  time: 0.938 s\n",
      "[epoch 29,imgs   960] loss: 0.7415618  time: 0.934 s\n",
      "[epoch 29,imgs  1000] loss: 0.7354129  time: 0.936 s\n",
      "[epoch 29,imgs  1040] loss: 0.7363823  time: 0.934 s\n",
      "[epoch 29,imgs  1080] loss: 0.7382541  time: 0.933 s\n",
      "[epoch 29,imgs  1120] loss: 0.7410796  time: 0.936 s\n",
      "[epoch 29,imgs  1160] loss: 0.7379034  time: 0.932 s\n",
      "[epoch 29,imgs  1200] loss: 0.7381358  time: 0.953 s\n",
      "[epoch 30,imgs    40] loss: 0.7409138  time: 1.319 s\n",
      "[epoch 30,imgs    80] loss: 0.7375429  time: 0.935 s\n",
      "[epoch 30,imgs   120] loss: 0.7333955  time: 0.935 s\n",
      "[epoch 30,imgs   160] loss: 0.7362336  time: 0.934 s\n",
      "[epoch 30,imgs   200] loss: 0.7397874  time: 0.945 s\n",
      "[epoch 30,imgs   240] loss: 0.7388003  time: 0.932 s\n",
      "[epoch 30,imgs   280] loss: 0.7364932  time: 0.936 s\n",
      "[epoch 30,imgs   320] loss: 0.7380925  time: 0.936 s\n",
      "[epoch 30,imgs   360] loss: 0.7392224  time: 0.933 s\n",
      "[epoch 30,imgs   400] loss: 0.7350415  time: 0.957 s\n",
      "[epoch 30,imgs   440] loss: 0.7383832  time: 0.935 s\n",
      "[epoch 30,imgs   480] loss: 0.7404884  time: 0.932 s\n",
      "[epoch 30,imgs   520] loss: 0.7393742  time: 0.947 s\n",
      "[epoch 30,imgs   560] loss: 0.7356062  time: 0.934 s\n",
      "[epoch 30,imgs   600] loss: 0.7398984  time: 0.941 s\n",
      "[epoch 30,imgs   640] loss: 0.7369980  time: 0.953 s\n",
      "[epoch 30,imgs   680] loss: 0.7364321  time: 0.936 s\n",
      "[epoch 30,imgs   720] loss: 0.7385029  time: 0.936 s\n",
      "[epoch 30,imgs   760] loss: 0.7372658  time: 0.961 s\n",
      "[epoch 30,imgs   800] loss: 0.7366375  time: 0.937 s\n",
      "[epoch 30,imgs   840] loss: 0.7402750  time: 0.933 s\n",
      "[epoch 30,imgs   880] loss: 0.7389855  time: 0.959 s\n",
      "[epoch 30,imgs   920] loss: 0.7387300  time: 0.939 s\n",
      "[epoch 30,imgs   960] loss: 0.7381167  time: 0.933 s\n",
      "[epoch 30,imgs  1000] loss: 0.7412832  time: 0.970 s\n",
      "[epoch 30,imgs  1040] loss: 0.7350851  time: 0.948 s\n",
      "[epoch 30,imgs  1080] loss: 0.7354597  time: 0.935 s\n",
      "[epoch 30,imgs  1120] loss: 0.7426913  time: 0.935 s\n",
      "[epoch 30,imgs  1160] loss: 0.7369747  time: 0.970 s\n",
      "[epoch 30,imgs  1200] loss: 0.7372296  time: 0.948 s\n",
      "[epoch 31,imgs    40] loss: 0.7422211  time: 1.316 s\n",
      "[epoch 31,imgs    80] loss: 0.7371131  time: 0.935 s\n",
      "[epoch 31,imgs   120] loss: 0.7378126  time: 0.934 s\n",
      "[epoch 31,imgs   160] loss: 0.7364036  time: 0.936 s\n",
      "[epoch 31,imgs   200] loss: 0.7381195  time: 0.932 s\n",
      "[epoch 31,imgs   240] loss: 0.7411982  time: 0.937 s\n",
      "[epoch 31,imgs   280] loss: 0.7395751  time: 0.966 s\n",
      "[epoch 31,imgs   320] loss: 0.7337791  time: 0.946 s\n",
      "[epoch 31,imgs   360] loss: 0.7400665  time: 0.937 s\n",
      "[epoch 31,imgs   400] loss: 0.7345102  time: 0.936 s\n",
      "[epoch 31,imgs   440] loss: 0.7410800  time: 0.935 s\n",
      "[epoch 31,imgs   480] loss: 0.7375517  time: 0.938 s\n",
      "[epoch 31,imgs   520] loss: 0.7364284  time: 0.954 s\n",
      "[epoch 31,imgs   560] loss: 0.7363684  time: 0.936 s\n",
      "[epoch 31,imgs   600] loss: 0.7388093  time: 0.946 s\n",
      "[epoch 31,imgs   640] loss: 0.7372274  time: 0.940 s\n",
      "[epoch 31,imgs   680] loss: 0.7337189  time: 0.937 s\n",
      "[epoch 31,imgs   720] loss: 0.7381229  time: 0.943 s\n",
      "[epoch 31,imgs   760] loss: 0.7384866  time: 0.965 s\n",
      "[epoch 31,imgs   800] loss: 0.7344342  time: 0.939 s\n",
      "[epoch 31,imgs   840] loss: 0.7394361  time: 0.942 s\n",
      "[epoch 31,imgs   880] loss: 0.7369208  time: 0.948 s\n",
      "[epoch 31,imgs   920] loss: 0.7417660  time: 0.937 s\n",
      "[epoch 31,imgs   960] loss: 0.7379276  time: 0.936 s\n",
      "[epoch 31,imgs  1000] loss: 0.7374450  time: 1.032 s\n",
      "[epoch 31,imgs  1040] loss: 0.7343293  time: 0.993 s\n",
      "[epoch 31,imgs  1080] loss: 0.7392749  time: 0.951 s\n",
      "[epoch 31,imgs  1120] loss: 0.7396963  time: 0.936 s\n",
      "[epoch 31,imgs  1160] loss: 0.7413742  time: 0.937 s\n",
      "[epoch 31,imgs  1200] loss: 0.7375214  time: 0.938 s\n",
      "[epoch 32,imgs    40] loss: 0.7389780  time: 1.332 s\n",
      "[epoch 32,imgs    80] loss: 0.7392252  time: 0.937 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 32,imgs   120] loss: 0.7369431  time: 0.937 s\n",
      "[epoch 32,imgs   160] loss: 0.7344257  time: 0.934 s\n",
      "[epoch 32,imgs   200] loss: 0.7361559  time: 0.938 s\n",
      "[epoch 32,imgs   240] loss: 0.7344082  time: 0.935 s\n",
      "[epoch 32,imgs   280] loss: 0.7367426  time: 0.936 s\n",
      "[epoch 32,imgs   320] loss: 0.7428612  time: 0.936 s\n",
      "[epoch 32,imgs   360] loss: 0.7418398  time: 0.938 s\n",
      "[epoch 32,imgs   400] loss: 0.7401201  time: 0.936 s\n",
      "[epoch 32,imgs   440] loss: 0.7389786  time: 0.961 s\n",
      "[epoch 32,imgs   480] loss: 0.7382920  time: 0.940 s\n",
      "[epoch 32,imgs   520] loss: 0.7350225  time: 0.935 s\n",
      "[epoch 32,imgs   560] loss: 0.7401197  time: 0.937 s\n",
      "[epoch 32,imgs   600] loss: 0.7348849  time: 0.946 s\n",
      "[epoch 32,imgs   640] loss: 0.7398120  time: 0.936 s\n",
      "[epoch 32,imgs   680] loss: 0.7357661  time: 0.960 s\n",
      "[epoch 32,imgs   720] loss: 0.7373593  time: 0.936 s\n",
      "[epoch 32,imgs   760] loss: 0.7367163  time: 0.938 s\n",
      "[epoch 32,imgs   800] loss: 0.7428688  time: 0.947 s\n",
      "[epoch 32,imgs   840] loss: 0.7394179  time: 0.945 s\n",
      "[epoch 32,imgs   880] loss: 0.7353318  time: 0.936 s\n",
      "[epoch 32,imgs   920] loss: 0.7396154  time: 0.953 s\n",
      "[epoch 32,imgs   960] loss: 0.7408197  time: 0.937 s\n",
      "[epoch 32,imgs  1000] loss: 0.7414284  time: 0.935 s\n",
      "[epoch 32,imgs  1040] loss: 0.7370459  time: 0.959 s\n",
      "[epoch 32,imgs  1080] loss: 0.7394377  time: 0.939 s\n",
      "[epoch 32,imgs  1120] loss: 0.7378283  time: 0.945 s\n",
      "[epoch 32,imgs  1160] loss: 0.7422609  time: 0.966 s\n",
      "[epoch 32,imgs  1200] loss: 0.7401292  time: 0.940 s\n",
      "[epoch 33,imgs    40] loss: 0.7329089  time: 1.326 s\n",
      "[epoch 33,imgs    80] loss: 0.7405187  time: 0.935 s\n",
      "[epoch 33,imgs   120] loss: 0.7409794  time: 0.937 s\n",
      "[epoch 33,imgs   160] loss: 0.7356895  time: 0.939 s\n",
      "[epoch 33,imgs   200] loss: 0.7383733  time: 0.940 s\n",
      "[epoch 33,imgs   240] loss: 0.7395883  time: 0.935 s\n",
      "[epoch 33,imgs   280] loss: 0.7398784  time: 0.955 s\n",
      "[epoch 33,imgs   320] loss: 0.7360138  time: 0.933 s\n",
      "[epoch 33,imgs   360] loss: 0.7393327  time: 0.935 s\n",
      "[epoch 33,imgs   400] loss: 0.7355952  time: 0.939 s\n",
      "[epoch 33,imgs   440] loss: 0.7410138  time: 0.933 s\n",
      "[epoch 33,imgs   480] loss: 0.7391917  time: 0.945 s\n",
      "[epoch 33,imgs   520] loss: 0.7370364  time: 0.951 s\n",
      "[epoch 33,imgs   560] loss: 0.7368510  time: 0.938 s\n",
      "[epoch 33,imgs   600] loss: 0.7368287  time: 0.941 s\n",
      "[epoch 33,imgs   640] loss: 0.7383848  time: 0.957 s\n",
      "[epoch 33,imgs   680] loss: 0.7391962  time: 0.937 s\n",
      "[epoch 33,imgs   720] loss: 0.7353790  time: 0.936 s\n",
      "[epoch 33,imgs   760] loss: 0.7395453  time: 0.959 s\n",
      "[epoch 33,imgs   800] loss: 0.7372350  time: 0.938 s\n",
      "[epoch 33,imgs   840] loss: 0.7391493  time: 0.934 s\n",
      "[epoch 33,imgs   880] loss: 0.7357199  time: 0.944 s\n",
      "[epoch 33,imgs   920] loss: 0.7366111  time: 0.938 s\n",
      "[epoch 33,imgs   960] loss: 0.7350269  time: 0.940 s\n",
      "[epoch 33,imgs  1000] loss: 0.7460219  time: 0.948 s\n",
      "[epoch 33,imgs  1040] loss: 0.7359868  time: 0.935 s\n",
      "[epoch 33,imgs  1080] loss: 0.7395859  time: 0.943 s\n",
      "[epoch 33,imgs  1120] loss: 0.7350194  time: 0.958 s\n",
      "[epoch 33,imgs  1160] loss: 0.7391720  time: 0.938 s\n",
      "[epoch 33,imgs  1200] loss: 0.7412350  time: 0.934 s\n",
      "[epoch 34,imgs    40] loss: 0.7341021  time: 1.345 s\n",
      "[epoch 34,imgs    80] loss: 0.7338900  time: 0.934 s\n",
      "[epoch 34,imgs   120] loss: 0.7429969  time: 0.935 s\n",
      "[epoch 34,imgs   160] loss: 0.7435011  time: 0.934 s\n",
      "[epoch 34,imgs   200] loss: 0.7363838  time: 0.935 s\n",
      "[epoch 34,imgs   240] loss: 0.7393432  time: 0.934 s\n",
      "[epoch 34,imgs   280] loss: 0.7461299  time: 0.935 s\n",
      "[epoch 34,imgs   320] loss: 0.7360842  time: 0.941 s\n",
      "[epoch 34,imgs   360] loss: 0.7412193  time: 0.934 s\n",
      "[epoch 34,imgs   400] loss: 0.7403372  time: 0.938 s\n",
      "[epoch 34,imgs   440] loss: 0.7367623  time: 0.950 s\n",
      "[epoch 34,imgs   480] loss: 0.7396802  time: 0.933 s\n",
      "[epoch 34,imgs   520] loss: 0.7410153  time: 0.935 s\n",
      "[epoch 34,imgs   560] loss: 0.7377826  time: 0.963 s\n",
      "[epoch 34,imgs   600] loss: 0.7448342  time: 0.936 s\n",
      "[epoch 34,imgs   640] loss: 0.7407421  time: 0.936 s\n",
      "[epoch 34,imgs   680] loss: 0.7413881  time: 0.967 s\n",
      "[epoch 34,imgs   720] loss: 0.7360413  time: 0.940 s\n",
      "[epoch 34,imgs   760] loss: 0.7381965  time: 0.934 s\n",
      "[epoch 34,imgs   800] loss: 0.7348026  time: 0.945 s\n",
      "[epoch 34,imgs   840] loss: 0.7376890  time: 0.940 s\n",
      "[epoch 34,imgs   880] loss: 0.7387361  time: 0.945 s\n",
      "[epoch 34,imgs   920] loss: 0.7395259  time: 0.942 s\n",
      "[epoch 34,imgs   960] loss: 0.7405282  time: 0.940 s\n",
      "[epoch 34,imgs  1000] loss: 0.7395285  time: 0.936 s\n",
      "[epoch 34,imgs  1040] loss: 0.7385590  time: 0.947 s\n",
      "[epoch 34,imgs  1080] loss: 0.7356271  time: 0.936 s\n",
      "[epoch 34,imgs  1120] loss: 0.7381587  time: 0.947 s\n",
      "[epoch 34,imgs  1160] loss: 0.7388294  time: 0.955 s\n",
      "[epoch 34,imgs  1200] loss: 0.7412181  time: 0.934 s\n",
      "[epoch 35,imgs    40] loss: 0.7402350  time: 1.349 s\n",
      "[epoch 35,imgs    80] loss: 0.7413104  time: 0.934 s\n",
      "[epoch 35,imgs   120] loss: 0.7422146  time: 0.936 s\n",
      "[epoch 35,imgs   160] loss: 0.7363358  time: 0.935 s\n",
      "[epoch 35,imgs   200] loss: 0.7355480  time: 0.935 s\n",
      "[epoch 35,imgs   240] loss: 0.7419040  time: 0.941 s\n",
      "[epoch 35,imgs   280] loss: 0.7346587  time: 0.950 s\n",
      "[epoch 35,imgs   320] loss: 0.7400562  time: 0.934 s\n",
      "[epoch 35,imgs   360] loss: 0.7371603  time: 0.935 s\n",
      "[epoch 35,imgs   400] loss: 0.7367816  time: 0.946 s\n",
      "[epoch 35,imgs   440] loss: 0.7406683  time: 0.935 s\n",
      "[epoch 35,imgs   480] loss: 0.7409755  time: 0.947 s\n",
      "[epoch 35,imgs   520] loss: 0.7399006  time: 0.953 s\n",
      "[epoch 35,imgs   560] loss: 0.7367135  time: 0.935 s\n",
      "[epoch 35,imgs   600] loss: 0.7339424  time: 0.935 s\n",
      "[epoch 35,imgs   640] loss: 0.7401887  time: 0.945 s\n",
      "[epoch 35,imgs   680] loss: 0.7398154  time: 0.932 s\n",
      "[epoch 35,imgs   720] loss: 0.7374874  time: 0.943 s\n",
      "[epoch 35,imgs   760] loss: 0.7414826  time: 0.937 s\n",
      "[epoch 35,imgs   800] loss: 0.7355198  time: 0.934 s\n",
      "[epoch 35,imgs   840] loss: 0.7339435  time: 0.939 s\n",
      "[epoch 35,imgs   880] loss: 0.7401743  time: 0.930 s\n",
      "[epoch 35,imgs   920] loss: 0.7367039  time: 0.952 s\n",
      "[epoch 35,imgs   960] loss: 0.7360976  time: 0.955 s\n",
      "[epoch 35,imgs  1000] loss: 0.7401176  time: 0.933 s\n",
      "[epoch 35,imgs  1040] loss: 0.7398886  time: 0.932 s\n",
      "[epoch 35,imgs  1080] loss: 0.7387176  time: 0.964 s\n",
      "[epoch 35,imgs  1120] loss: 0.7365767  time: 0.948 s\n",
      "[epoch 35,imgs  1160] loss: 0.7450753  time: 0.935 s\n",
      "[epoch 35,imgs  1200] loss: 0.7403677  time: 0.930 s\n",
      "[epoch 36,imgs    40] loss: 0.7374201  time: 1.313 s\n",
      "[epoch 36,imgs    80] loss: 0.7378404  time: 0.932 s\n",
      "[epoch 36,imgs   120] loss: 0.7352897  time: 0.931 s\n",
      "[epoch 36,imgs   160] loss: 0.7313908  time: 0.932 s\n",
      "[epoch 36,imgs   200] loss: 0.7420111  time: 0.931 s\n",
      "[epoch 36,imgs   240] loss: 0.7331135  time: 0.930 s\n",
      "[epoch 36,imgs   280] loss: 0.7375963  time: 0.933 s\n",
      "[epoch 36,imgs   320] loss: 0.7378930  time: 0.930 s\n",
      "[epoch 36,imgs   360] loss: 0.7342290  time: 0.941 s\n",
      "[epoch 36,imgs   400] loss: 0.7361584  time: 0.933 s\n",
      "[epoch 36,imgs   440] loss: 0.7375823  time: 0.932 s\n",
      "[epoch 36,imgs   480] loss: 0.7371810  time: 0.946 s\n",
      "[epoch 36,imgs   520] loss: 0.7384322  time: 0.934 s\n",
      "[epoch 36,imgs   560] loss: 0.7431216  time: 0.938 s\n",
      "[epoch 36,imgs   600] loss: 0.7391742  time: 0.939 s\n",
      "[epoch 36,imgs   640] loss: 0.7428102  time: 0.933 s\n",
      "[epoch 36,imgs   680] loss: 0.7419661  time: 0.933 s\n",
      "[epoch 36,imgs   720] loss: 0.7410648  time: 0.934 s\n",
      "[epoch 36,imgs   760] loss: 0.7400252  time: 0.936 s\n",
      "[epoch 36,imgs   800] loss: 0.7412436  time: 0.934 s\n",
      "[epoch 36,imgs   840] loss: 0.7390867  time: 0.932 s\n",
      "[epoch 36,imgs   880] loss: 0.7396530  time: 0.967 s\n",
      "[epoch 36,imgs   920] loss: 0.7399145  time: 0.948 s\n",
      "[epoch 36,imgs   960] loss: 0.7368892  time: 0.932 s\n",
      "[epoch 36,imgs  1000] loss: 0.7369046  time: 0.932 s\n",
      "[epoch 36,imgs  1040] loss: 0.7379559  time: 0.938 s\n",
      "[epoch 36,imgs  1080] loss: 0.7402843  time: 0.935 s\n",
      "[epoch 36,imgs  1120] loss: 0.7381784  time: 0.937 s\n",
      "[epoch 36,imgs  1160] loss: 0.7400984  time: 0.931 s\n",
      "[epoch 36,imgs  1200] loss: 0.7443559  time: 0.932 s\n",
      "[epoch 37,imgs    40] loss: 0.7358443  time: 1.315 s\n",
      "[epoch 37,imgs    80] loss: 0.7381897  time: 0.940 s\n",
      "[epoch 37,imgs   120] loss: 0.7391447  time: 0.932 s\n",
      "[epoch 37,imgs   160] loss: 0.7367108  time: 0.935 s\n",
      "[epoch 37,imgs   200] loss: 0.7382044  time: 0.932 s\n",
      "[epoch 37,imgs   240] loss: 0.7375364  time: 0.932 s\n",
      "[epoch 37,imgs   280] loss: 0.7386938  time: 0.933 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 37,imgs   320] loss: 0.7387586  time: 0.933 s\n",
      "[epoch 37,imgs   360] loss: 0.7354749  time: 0.940 s\n",
      "[epoch 37,imgs   400] loss: 0.7386505  time: 0.946 s\n",
      "[epoch 37,imgs   440] loss: 0.7351769  time: 0.930 s\n",
      "[epoch 37,imgs   480] loss: 0.7351127  time: 0.940 s\n",
      "[epoch 37,imgs   520] loss: 0.7390078  time: 0.952 s\n",
      "[epoch 37,imgs   560] loss: 0.7414834  time: 0.934 s\n",
      "[epoch 37,imgs   600] loss: 0.7378762  time: 0.936 s\n",
      "[epoch 37,imgs   640] loss: 0.7396019  time: 0.949 s\n",
      "[epoch 37,imgs   680] loss: 0.7367484  time: 0.932 s\n",
      "[epoch 37,imgs   720] loss: 0.7405005  time: 0.941 s\n",
      "[epoch 37,imgs   760] loss: 0.7417108  time: 0.934 s\n",
      "[epoch 37,imgs   800] loss: 0.7374969  time: 0.933 s\n",
      "[epoch 37,imgs   840] loss: 0.7408240  time: 0.946 s\n",
      "[epoch 37,imgs   880] loss: 0.7383059  time: 0.935 s\n",
      "[epoch 37,imgs   920] loss: 0.7351118  time: 0.936 s\n",
      "[epoch 37,imgs   960] loss: 0.7369012  time: 0.935 s\n",
      "[epoch 37,imgs  1000] loss: 0.7376584  time: 0.933 s\n",
      "[epoch 37,imgs  1040] loss: 0.7338033  time: 0.934 s\n",
      "[epoch 37,imgs  1080] loss: 0.7407548  time: 0.934 s\n",
      "[epoch 37,imgs  1120] loss: 0.7376202  time: 0.974 s\n",
      "[epoch 37,imgs  1160] loss: 0.7396170  time: 0.947 s\n",
      "[epoch 37,imgs  1200] loss: 0.7337671  time: 0.933 s\n",
      "[epoch 38,imgs    40] loss: 0.7401137  time: 1.318 s\n",
      "[epoch 38,imgs    80] loss: 0.7359040  time: 0.935 s\n",
      "[epoch 38,imgs   120] loss: 0.7363940  time: 0.932 s\n",
      "[epoch 38,imgs   160] loss: 0.7363614  time: 0.935 s\n",
      "[epoch 38,imgs   200] loss: 0.7404184  time: 0.933 s\n",
      "[epoch 38,imgs   240] loss: 0.7323684  time: 0.933 s\n",
      "[epoch 38,imgs   280] loss: 0.7381063  time: 0.934 s\n",
      "[epoch 38,imgs   320] loss: 0.7382992  time: 0.933 s\n",
      "[epoch 38,imgs   360] loss: 0.7430015  time: 0.934 s\n",
      "[epoch 38,imgs   400] loss: 0.7423181  time: 0.934 s\n",
      "[epoch 38,imgs   440] loss: 0.7382352  time: 0.939 s\n",
      "[epoch 38,imgs   480] loss: 0.7401397  time: 0.935 s\n",
      "[epoch 38,imgs   520] loss: 0.7359591  time: 0.940 s\n",
      "[epoch 38,imgs   560] loss: 0.7353843  time: 0.940 s\n",
      "[epoch 38,imgs   600] loss: 0.7370592  time: 0.940 s\n",
      "[epoch 38,imgs   640] loss: 0.7373086  time: 0.956 s\n",
      "[epoch 38,imgs   680] loss: 0.7409971  time: 0.934 s\n",
      "[epoch 38,imgs   720] loss: 0.7377980  time: 0.935 s\n",
      "[epoch 38,imgs   760] loss: 0.7353890  time: 0.932 s\n",
      "[epoch 38,imgs   800] loss: 0.7377522  time: 0.935 s\n",
      "[epoch 38,imgs   840] loss: 0.7407905  time: 0.946 s\n",
      "[epoch 38,imgs   880] loss: 0.7427688  time: 0.937 s\n",
      "[epoch 38,imgs   920] loss: 0.7383602  time: 0.932 s\n",
      "[epoch 38,imgs   960] loss: 0.7370669  time: 0.939 s\n",
      "[epoch 38,imgs  1000] loss: 0.7341649  time: 0.933 s\n",
      "[epoch 38,imgs  1040] loss: 0.7378730  time: 0.940 s\n",
      "[epoch 38,imgs  1080] loss: 0.7384174  time: 0.935 s\n",
      "[epoch 38,imgs  1120] loss: 0.7414233  time: 0.932 s\n",
      "[epoch 38,imgs  1160] loss: 0.7365153  time: 0.939 s\n",
      "[epoch 38,imgs  1200] loss: 0.7437128  time: 0.930 s\n",
      "[epoch 39,imgs    40] loss: 0.7417227  time: 1.327 s\n",
      "[epoch 39,imgs    80] loss: 0.7389350  time: 0.934 s\n",
      "[epoch 39,imgs   120] loss: 0.7365482  time: 0.933 s\n",
      "[epoch 39,imgs   160] loss: 0.7378088  time: 0.934 s\n",
      "[epoch 39,imgs   200] loss: 0.7422073  time: 0.933 s\n",
      "[epoch 39,imgs   240] loss: 0.7377154  time: 0.936 s\n",
      "[epoch 39,imgs   280] loss: 0.7388949  time: 0.938 s\n",
      "[epoch 39,imgs   320] loss: 0.7433823  time: 0.938 s\n",
      "[epoch 39,imgs   360] loss: 0.7414704  time: 0.937 s\n",
      "[epoch 39,imgs   400] loss: 0.7392276  time: 0.934 s\n",
      "[epoch 39,imgs   440] loss: 0.7389897  time: 0.953 s\n",
      "[epoch 39,imgs   480] loss: 0.7440012  time: 0.939 s\n",
      "[epoch 39,imgs   520] loss: 0.7364170  time: 0.938 s\n",
      "[epoch 39,imgs   560] loss: 0.7393318  time: 0.934 s\n",
      "[epoch 39,imgs   600] loss: 0.7443693  time: 0.934 s\n",
      "[epoch 39,imgs   640] loss: 0.7343480  time: 0.934 s\n",
      "[epoch 39,imgs   680] loss: 0.7400356  time: 0.938 s\n",
      "[epoch 39,imgs   720] loss: 0.7389991  time: 0.934 s\n",
      "[epoch 39,imgs   760] loss: 0.7418353  time: 0.983 s\n",
      "[epoch 39,imgs   800] loss: 0.7390468  time: 0.961 s\n",
      "[epoch 39,imgs   840] loss: 0.7418481  time: 0.937 s\n",
      "[epoch 39,imgs   880] loss: 0.7376643  time: 0.933 s\n",
      "[epoch 39,imgs   920] loss: 0.7349513  time: 0.932 s\n",
      "[epoch 39,imgs   960] loss: 0.7372310  time: 0.933 s\n",
      "[epoch 39,imgs  1000] loss: 0.7391577  time: 0.933 s\n",
      "[epoch 39,imgs  1040] loss: 0.7395229  time: 0.933 s\n",
      "[epoch 39,imgs  1080] loss: 0.7410223  time: 0.936 s\n",
      "[epoch 39,imgs  1120] loss: 0.7427968  time: 0.933 s\n",
      "[epoch 39,imgs  1160] loss: 0.7342116  time: 0.933 s\n",
      "[epoch 39,imgs  1200] loss: 0.7396371  time: 0.930 s\n",
      "[epoch 40,imgs    40] loss: 0.7374939  time: 1.336 s\n",
      "[epoch 40,imgs    80] loss: 0.7374378  time: 0.936 s\n",
      "[epoch 40,imgs   120] loss: 0.7398478  time: 0.935 s\n",
      "[epoch 40,imgs   160] loss: 0.7416917  time: 0.935 s\n",
      "[epoch 40,imgs   200] loss: 0.7387889  time: 0.931 s\n",
      "[epoch 40,imgs   240] loss: 0.7424987  time: 0.935 s\n",
      "[epoch 40,imgs   280] loss: 0.7414550  time: 0.934 s\n",
      "[epoch 40,imgs   320] loss: 0.7382597  time: 0.934 s\n",
      "[epoch 40,imgs   360] loss: 0.7417527  time: 0.934 s\n",
      "[epoch 40,imgs   400] loss: 0.7411151  time: 0.944 s\n",
      "[epoch 40,imgs   440] loss: 0.7339225  time: 0.934 s\n",
      "[epoch 40,imgs   480] loss: 0.7375126  time: 0.936 s\n",
      "[epoch 40,imgs   520] loss: 0.7404159  time: 0.960 s\n",
      "[epoch 40,imgs   560] loss: 0.7436936  time: 0.939 s\n",
      "[epoch 40,imgs   600] loss: 0.7389251  time: 0.962 s\n",
      "[epoch 40,imgs   640] loss: 0.7371367  time: 0.938 s\n",
      "[epoch 40,imgs   680] loss: 0.7407416  time: 0.936 s\n",
      "[epoch 40,imgs   720] loss: 0.7397668  time: 0.982 s\n",
      "[epoch 40,imgs   760] loss: 0.7383282  time: 0.970 s\n",
      "[epoch 40,imgs   800] loss: 0.7382696  time: 0.937 s\n",
      "[epoch 40,imgs   840] loss: 0.7380819  time: 0.937 s\n",
      "[epoch 40,imgs   880] loss: 0.7419294  time: 0.934 s\n",
      "[epoch 40,imgs   920] loss: 0.7348645  time: 0.933 s\n",
      "[epoch 40,imgs   960] loss: 0.7419842  time: 0.934 s\n",
      "[epoch 40,imgs  1000] loss: 0.7393718  time: 0.934 s\n",
      "[epoch 40,imgs  1040] loss: 0.7362652  time: 0.935 s\n",
      "[epoch 40,imgs  1080] loss: 0.7410083  time: 0.933 s\n",
      "[epoch 40,imgs  1120] loss: 0.7350088  time: 0.935 s\n",
      "[epoch 40,imgs  1160] loss: 0.7361978  time: 0.936 s\n",
      "[epoch 40,imgs  1200] loss: 0.7369513  time: 0.933 s\n",
      "[epoch 41,imgs    40] loss: 0.7420481  time: 1.315 s\n",
      "[epoch 41,imgs    80] loss: 0.7369103  time: 0.937 s\n",
      "[epoch 41,imgs   120] loss: 0.7380864  time: 0.940 s\n",
      "[epoch 41,imgs   160] loss: 0.7401312  time: 0.933 s\n",
      "[epoch 41,imgs   200] loss: 0.7340576  time: 0.937 s\n",
      "[epoch 41,imgs   240] loss: 0.7379519  time: 0.934 s\n",
      "[epoch 41,imgs   280] loss: 0.7372040  time: 0.936 s\n",
      "[epoch 41,imgs   320] loss: 0.7374129  time: 0.942 s\n",
      "[epoch 41,imgs   360] loss: 0.7425101  time: 0.937 s\n",
      "[epoch 41,imgs   400] loss: 0.7420246  time: 0.934 s\n",
      "[epoch 41,imgs   440] loss: 0.7375932  time: 0.936 s\n",
      "[epoch 41,imgs   480] loss: 0.7380500  time: 0.938 s\n",
      "[epoch 41,imgs   520] loss: 0.7372066  time: 0.933 s\n",
      "[epoch 41,imgs   560] loss: 0.7408876  time: 0.973 s\n",
      "[epoch 41,imgs   600] loss: 0.7378841  time: 0.937 s\n",
      "[epoch 41,imgs   640] loss: 0.7411000  time: 0.936 s\n",
      "[epoch 41,imgs   680] loss: 0.7348092  time: 0.935 s\n",
      "[epoch 41,imgs   720] loss: 0.7379453  time: 0.935 s\n",
      "[epoch 41,imgs   760] loss: 0.7404996  time: 0.941 s\n",
      "[epoch 41,imgs   800] loss: 0.7409578  time: 0.947 s\n",
      "[epoch 41,imgs   840] loss: 0.7367210  time: 0.938 s\n",
      "[epoch 41,imgs   880] loss: 0.7358589  time: 0.939 s\n",
      "[epoch 41,imgs   920] loss: 0.7378941  time: 0.935 s\n",
      "[epoch 41,imgs   960] loss: 0.7402379  time: 0.955 s\n",
      "[epoch 41,imgs  1000] loss: 0.7386760  time: 0.943 s\n",
      "[epoch 41,imgs  1040] loss: 0.7356488  time: 0.940 s\n",
      "[epoch 41,imgs  1080] loss: 0.7378773  time: 0.937 s\n",
      "[epoch 41,imgs  1120] loss: 0.7358565  time: 0.935 s\n",
      "[epoch 41,imgs  1160] loss: 0.7341634  time: 0.937 s\n",
      "[epoch 41,imgs  1200] loss: 0.7342983  time: 0.957 s\n",
      "[epoch 42,imgs    40] loss: 0.7364342  time: 1.312 s\n",
      "[epoch 42,imgs    80] loss: 0.7404822  time: 0.937 s\n",
      "[epoch 42,imgs   120] loss: 0.7385497  time: 0.936 s\n",
      "[epoch 42,imgs   160] loss: 0.7380292  time: 0.935 s\n",
      "[epoch 42,imgs   200] loss: 0.7381506  time: 0.933 s\n",
      "[epoch 42,imgs   240] loss: 0.7368012  time: 0.936 s\n",
      "[epoch 42,imgs   280] loss: 0.7376289  time: 0.932 s\n",
      "[epoch 42,imgs   320] loss: 0.7382908  time: 0.935 s\n",
      "[epoch 42,imgs   360] loss: 0.7396130  time: 0.937 s\n",
      "[epoch 42,imgs   400] loss: 0.7385796  time: 0.934 s\n",
      "[epoch 42,imgs   440] loss: 0.7356561  time: 0.934 s\n",
      "[epoch 42,imgs   480] loss: 0.7387092  time: 0.937 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 42,imgs   520] loss: 0.7412477  time: 0.939 s\n",
      "[epoch 42,imgs   560] loss: 0.7394912  time: 0.936 s\n",
      "[epoch 42,imgs   600] loss: 0.7326745  time: 0.934 s\n",
      "[epoch 42,imgs   640] loss: 0.7373675  time: 0.933 s\n",
      "[epoch 42,imgs   680] loss: 0.7399791  time: 0.934 s\n",
      "[epoch 42,imgs   720] loss: 0.7354890  time: 0.932 s\n",
      "[epoch 42,imgs   760] loss: 0.7402899  time: 0.934 s\n",
      "[epoch 42,imgs   800] loss: 0.7345089  time: 0.942 s\n",
      "[epoch 42,imgs   840] loss: 0.7377883  time: 0.935 s\n",
      "[epoch 42,imgs   880] loss: 0.7375193  time: 0.941 s\n",
      "[epoch 42,imgs   920] loss: 0.7414314  time: 0.933 s\n",
      "[epoch 42,imgs   960] loss: 0.7439479  time: 0.934 s\n",
      "[epoch 42,imgs  1000] loss: 0.7366459  time: 0.953 s\n",
      "[epoch 42,imgs  1040] loss: 0.7368336  time: 0.938 s\n",
      "[epoch 42,imgs  1080] loss: 0.7407744  time: 0.935 s\n",
      "[epoch 42,imgs  1120] loss: 0.7362382  time: 0.953 s\n",
      "[epoch 42,imgs  1160] loss: 0.7404998  time: 0.936 s\n",
      "[epoch 42,imgs  1200] loss: 0.7365742  time: 0.936 s\n",
      "[epoch 43,imgs    40] loss: 0.7426146  time: 1.337 s\n",
      "[epoch 43,imgs    80] loss: 0.7402243  time: 0.937 s\n",
      "[epoch 43,imgs   120] loss: 0.7408181  time: 0.933 s\n",
      "[epoch 43,imgs   160] loss: 0.7395298  time: 0.935 s\n",
      "[epoch 43,imgs   200] loss: 0.7329298  time: 0.934 s\n",
      "[epoch 43,imgs   240] loss: 0.7408308  time: 0.932 s\n",
      "[epoch 43,imgs   280] loss: 0.7388141  time: 0.934 s\n",
      "[epoch 43,imgs   320] loss: 0.7393290  time: 0.933 s\n",
      "[epoch 43,imgs   360] loss: 0.7398217  time: 0.933 s\n",
      "[epoch 43,imgs   400] loss: 0.7386432  time: 0.933 s\n",
      "[epoch 43,imgs   440] loss: 0.7367775  time: 0.934 s\n",
      "[epoch 43,imgs   480] loss: 0.7337241  time: 0.933 s\n",
      "[epoch 43,imgs   520] loss: 0.7419088  time: 0.933 s\n",
      "[epoch 43,imgs   560] loss: 0.7384576  time: 0.935 s\n",
      "[epoch 43,imgs   600] loss: 0.7381662  time: 0.934 s\n",
      "[epoch 43,imgs   640] loss: 0.7392780  time: 0.935 s\n",
      "[epoch 43,imgs   680] loss: 0.7415045  time: 0.935 s\n",
      "[epoch 43,imgs   720] loss: 0.7386639  time: 0.953 s\n",
      "[epoch 43,imgs   760] loss: 0.7361606  time: 0.935 s\n",
      "[epoch 43,imgs   800] loss: 0.7408150  time: 0.935 s\n",
      "[epoch 43,imgs   840] loss: 0.7389788  time: 0.934 s\n",
      "[epoch 43,imgs   880] loss: 0.7413810  time: 0.935 s\n",
      "[epoch 43,imgs   920] loss: 0.7438353  time: 0.940 s\n",
      "[epoch 43,imgs   960] loss: 0.7402333  time: 0.935 s\n",
      "[epoch 43,imgs  1000] loss: 0.7390395  time: 0.938 s\n",
      "[epoch 43,imgs  1040] loss: 0.7380122  time: 0.935 s\n",
      "[epoch 43,imgs  1080] loss: 0.7396082  time: 0.936 s\n",
      "[epoch 43,imgs  1120] loss: 0.7387362  time: 0.959 s\n",
      "[epoch 43,imgs  1160] loss: 0.7362405  time: 0.956 s\n",
      "[epoch 43,imgs  1200] loss: 0.7339162  time: 0.934 s\n",
      "[epoch 44,imgs    40] loss: 0.7398131  time: 1.313 s\n",
      "[epoch 44,imgs    80] loss: 0.7409382  time: 0.934 s\n",
      "[epoch 44,imgs   120] loss: 0.7361796  time: 0.948 s\n",
      "[epoch 44,imgs   160] loss: 0.7424074  time: 0.941 s\n",
      "[epoch 44,imgs   200] loss: 0.7443293  time: 0.937 s\n",
      "[epoch 44,imgs   240] loss: 0.7374511  time: 0.943 s\n",
      "[epoch 44,imgs   280] loss: 0.7340702  time: 0.942 s\n",
      "[epoch 44,imgs   320] loss: 0.7395873  time: 0.940 s\n",
      "[epoch 44,imgs   360] loss: 0.7409794  time: 0.936 s\n",
      "[epoch 44,imgs   400] loss: 0.7378576  time: 0.937 s\n",
      "[epoch 44,imgs   440] loss: 0.7386234  time: 0.936 s\n",
      "[epoch 44,imgs   480] loss: 0.7395930  time: 0.932 s\n",
      "[epoch 44,imgs   520] loss: 0.7379515  time: 0.938 s\n",
      "[epoch 44,imgs   560] loss: 0.7353812  time: 0.937 s\n",
      "[epoch 44,imgs   600] loss: 0.7390607  time: 0.937 s\n",
      "[epoch 44,imgs   640] loss: 0.7435818  time: 0.938 s\n",
      "[epoch 44,imgs   680] loss: 0.7358704  time: 0.939 s\n",
      "[epoch 44,imgs   720] loss: 0.7388690  time: 0.937 s\n",
      "[epoch 44,imgs   760] loss: 0.7379525  time: 0.950 s\n",
      "[epoch 44,imgs   800] loss: 0.7328348  time: 0.938 s\n",
      "[epoch 44,imgs   840] loss: 0.7428297  time: 0.938 s\n",
      "[epoch 44,imgs   880] loss: 0.7382615  time: 0.955 s\n",
      "[epoch 44,imgs   920] loss: 0.7373148  time: 0.941 s\n",
      "[epoch 44,imgs   960] loss: 0.7387524  time: 0.939 s\n",
      "[epoch 44,imgs  1000] loss: 0.7406613  time: 0.938 s\n",
      "[epoch 44,imgs  1040] loss: 0.7387157  time: 0.938 s\n",
      "[epoch 44,imgs  1080] loss: 0.7370103  time: 0.941 s\n",
      "[epoch 44,imgs  1120] loss: 0.7408496  time: 0.935 s\n",
      "[epoch 44,imgs  1160] loss: 0.7396635  time: 0.941 s\n",
      "[epoch 44,imgs  1200] loss: 0.7366949  time: 0.939 s\n",
      "[epoch 45,imgs    40] loss: 0.7392172  time: 1.321 s\n",
      "[epoch 45,imgs    80] loss: 0.7378775  time: 0.936 s\n",
      "[epoch 45,imgs   120] loss: 0.7365758  time: 0.939 s\n",
      "[epoch 45,imgs   160] loss: 0.7400002  time: 0.936 s\n",
      "[epoch 45,imgs   200] loss: 0.7405887  time: 0.934 s\n",
      "[epoch 45,imgs   240] loss: 0.7374442  time: 0.937 s\n",
      "[epoch 45,imgs   280] loss: 0.7396739  time: 0.936 s\n",
      "[epoch 45,imgs   320] loss: 0.7408096  time: 0.936 s\n",
      "[epoch 45,imgs   360] loss: 0.7415123  time: 0.936 s\n",
      "[epoch 45,imgs   400] loss: 0.7431995  time: 0.937 s\n",
      "[epoch 45,imgs   440] loss: 0.7408323  time: 0.936 s\n",
      "[epoch 45,imgs   480] loss: 0.7393641  time: 0.936 s\n",
      "[epoch 45,imgs   520] loss: 0.7406340  time: 0.935 s\n",
      "[epoch 45,imgs   560] loss: 0.7398682  time: 0.938 s\n",
      "[epoch 45,imgs   600] loss: 0.7404718  time: 0.940 s\n",
      "[epoch 45,imgs   640] loss: 0.7345058  time: 0.936 s\n",
      "[epoch 45,imgs   680] loss: 0.7400218  time: 0.938 s\n",
      "[epoch 45,imgs   720] loss: 0.7371868  time: 0.938 s\n",
      "[epoch 45,imgs   760] loss: 0.7395995  time: 0.935 s\n",
      "[epoch 45,imgs   800] loss: 0.7361444  time: 0.939 s\n",
      "[epoch 45,imgs   840] loss: 0.7352760  time: 0.937 s\n",
      "[epoch 45,imgs   880] loss: 0.7407860  time: 0.947 s\n",
      "[epoch 45,imgs   920] loss: 0.7393718  time: 0.940 s\n",
      "[epoch 45,imgs   960] loss: 0.7417915  time: 0.937 s\n",
      "[epoch 45,imgs  1000] loss: 0.7427499  time: 0.933 s\n",
      "[epoch 45,imgs  1040] loss: 0.7370829  time: 0.935 s\n",
      "[epoch 45,imgs  1080] loss: 0.7394364  time: 0.938 s\n",
      "[epoch 45,imgs  1120] loss: 0.7397943  time: 0.946 s\n",
      "[epoch 45,imgs  1160] loss: 0.7389081  time: 0.936 s\n",
      "[epoch 45,imgs  1200] loss: 0.7387452  time: 0.958 s\n",
      "[epoch 46,imgs    40] loss: 0.7355208  time: 1.411 s\n",
      "[epoch 46,imgs    80] loss: 0.7362743  time: 0.934 s\n",
      "[epoch 46,imgs   120] loss: 0.7377740  time: 0.936 s\n",
      "[epoch 46,imgs   160] loss: 0.7380151  time: 0.936 s\n",
      "[epoch 46,imgs   200] loss: 0.7379612  time: 0.934 s\n",
      "[epoch 46,imgs   240] loss: 0.7413626  time: 0.934 s\n",
      "[epoch 46,imgs   280] loss: 0.7403589  time: 0.934 s\n",
      "[epoch 46,imgs   320] loss: 0.7373685  time: 0.936 s\n",
      "[epoch 46,imgs   360] loss: 0.7353958  time: 0.935 s\n",
      "[epoch 46,imgs   400] loss: 0.7394985  time: 0.934 s\n",
      "[epoch 46,imgs   440] loss: 0.7417421  time: 0.932 s\n",
      "[epoch 46,imgs   480] loss: 0.7358908  time: 0.935 s\n",
      "[epoch 46,imgs   520] loss: 0.7346233  time: 0.940 s\n",
      "[epoch 46,imgs   560] loss: 0.7375688  time: 0.935 s\n",
      "[epoch 46,imgs   600] loss: 0.7370807  time: 0.937 s\n",
      "[epoch 46,imgs   640] loss: 0.7418725  time: 0.935 s\n",
      "[epoch 46,imgs   680] loss: 0.7352802  time: 0.934 s\n",
      "[epoch 46,imgs   720] loss: 0.7385137  time: 0.936 s\n",
      "[epoch 46,imgs   760] loss: 0.7380497  time: 0.946 s\n",
      "[epoch 46,imgs   800] loss: 0.7386141  time: 0.938 s\n",
      "[epoch 46,imgs   840] loss: 0.7412804  time: 0.934 s\n",
      "[epoch 46,imgs   880] loss: 0.7349830  time: 0.935 s\n",
      "[epoch 46,imgs   920] loss: 0.7405072  time: 0.935 s\n",
      "[epoch 46,imgs   960] loss: 0.7355077  time: 0.938 s\n",
      "[epoch 46,imgs  1000] loss: 0.7330241  time: 0.936 s\n",
      "[epoch 46,imgs  1040] loss: 0.7333685  time: 0.938 s\n",
      "[epoch 46,imgs  1080] loss: 0.7402734  time: 0.937 s\n",
      "[epoch 46,imgs  1120] loss: 0.7373112  time: 0.934 s\n",
      "[epoch 46,imgs  1160] loss: 0.7429917  time: 0.937 s\n",
      "[epoch 46,imgs  1200] loss: 0.7429132  time: 0.933 s\n",
      "[epoch 47,imgs    40] loss: 0.7345574  time: 1.341 s\n",
      "[epoch 47,imgs    80] loss: 0.7395036  time: 0.934 s\n",
      "[epoch 47,imgs   120] loss: 0.7418626  time: 0.933 s\n",
      "[epoch 47,imgs   160] loss: 0.7377871  time: 0.934 s\n",
      "[epoch 47,imgs   200] loss: 0.7356296  time: 0.934 s\n",
      "[epoch 47,imgs   240] loss: 0.7426827  time: 0.937 s\n",
      "[epoch 47,imgs   280] loss: 0.7371393  time: 0.933 s\n",
      "[epoch 47,imgs   320] loss: 0.7413138  time: 0.935 s\n",
      "[epoch 47,imgs   360] loss: 0.7396736  time: 0.934 s\n",
      "[epoch 47,imgs   400] loss: 0.7365894  time: 0.935 s\n",
      "[epoch 47,imgs   440] loss: 0.7381329  time: 0.933 s\n",
      "[epoch 47,imgs   480] loss: 0.7402442  time: 0.949 s\n",
      "[epoch 47,imgs   520] loss: 0.7340023  time: 0.944 s\n",
      "[epoch 47,imgs   560] loss: 0.7404701  time: 0.934 s\n",
      "[epoch 47,imgs   600] loss: 0.7401345  time: 0.936 s\n",
      "[epoch 47,imgs   640] loss: 0.7384642  time: 0.937 s\n",
      "[epoch 47,imgs   680] loss: 0.7370450  time: 0.943 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 47,imgs   720] loss: 0.7388843  time: 0.935 s\n",
      "[epoch 47,imgs   760] loss: 0.7396377  time: 0.934 s\n",
      "[epoch 47,imgs   800] loss: 0.7401860  time: 0.934 s\n",
      "[epoch 47,imgs   840] loss: 0.7391266  time: 0.936 s\n",
      "[epoch 47,imgs   880] loss: 0.7341388  time: 0.937 s\n",
      "[epoch 47,imgs   920] loss: 0.7405112  time: 0.936 s\n",
      "[epoch 47,imgs   960] loss: 0.7405133  time: 0.939 s\n",
      "[epoch 47,imgs  1000] loss: 0.7383658  time: 0.937 s\n",
      "[epoch 47,imgs  1040] loss: 0.7370595  time: 0.993 s\n",
      "[epoch 47,imgs  1080] loss: 0.7390565  time: 0.968 s\n",
      "[epoch 47,imgs  1120] loss: 0.7350224  time: 0.939 s\n",
      "[epoch 47,imgs  1160] loss: 0.7368152  time: 0.934 s\n",
      "[epoch 47,imgs  1200] loss: 0.7416509  time: 0.935 s\n",
      "[epoch 48,imgs    40] loss: 0.7354754  time: 1.332 s\n",
      "[epoch 48,imgs    80] loss: 0.7356527  time: 0.934 s\n",
      "[epoch 48,imgs   120] loss: 0.7402956  time: 0.936 s\n",
      "[epoch 48,imgs   160] loss: 0.7396505  time: 0.939 s\n",
      "[epoch 48,imgs   200] loss: 0.7313358  time: 0.934 s\n",
      "[epoch 48,imgs   240] loss: 0.7323834  time: 0.935 s\n",
      "[epoch 48,imgs   280] loss: 0.7378069  time: 0.934 s\n",
      "[epoch 48,imgs   320] loss: 0.7376521  time: 0.936 s\n",
      "[epoch 48,imgs   360] loss: 0.7403949  time: 0.937 s\n",
      "[epoch 48,imgs   400] loss: 0.7411624  time: 0.932 s\n",
      "[epoch 48,imgs   440] loss: 0.7390152  time: 0.931 s\n",
      "[epoch 48,imgs   480] loss: 0.7391680  time: 0.941 s\n",
      "[epoch 48,imgs   520] loss: 0.7387538  time: 0.944 s\n",
      "[epoch 48,imgs   560] loss: 0.7378898  time: 0.938 s\n",
      "[epoch 48,imgs   600] loss: 0.7420726  time: 0.936 s\n",
      "[epoch 48,imgs   640] loss: 0.7350660  time: 0.936 s\n",
      "[epoch 48,imgs   680] loss: 0.7378044  time: 0.939 s\n",
      "[epoch 48,imgs   720] loss: 0.7350325  time: 0.934 s\n",
      "[epoch 48,imgs   760] loss: 0.7379171  time: 0.935 s\n",
      "[epoch 48,imgs   800] loss: 0.7383778  time: 0.936 s\n",
      "[epoch 48,imgs   840] loss: 0.7426355  time: 0.935 s\n",
      "[epoch 48,imgs   880] loss: 0.7428225  time: 0.935 s\n",
      "[epoch 48,imgs   920] loss: 0.7390189  time: 0.936 s\n",
      "[epoch 48,imgs   960] loss: 0.7414864  time: 0.935 s\n",
      "[epoch 48,imgs  1000] loss: 0.7385562  time: 0.936 s\n",
      "[epoch 48,imgs  1040] loss: 0.7366040  time: 0.935 s\n",
      "[epoch 48,imgs  1080] loss: 0.7351214  time: 0.935 s\n",
      "[epoch 48,imgs  1120] loss: 0.7393973  time: 0.935 s\n",
      "[epoch 48,imgs  1160] loss: 0.7375491  time: 0.934 s\n",
      "[epoch 48,imgs  1200] loss: 0.7313773  time: 0.941 s\n",
      "[epoch 49,imgs    40] loss: 0.7420045  time: 1.334 s\n",
      "[epoch 49,imgs    80] loss: 0.7410151  time: 0.934 s\n",
      "[epoch 49,imgs   120] loss: 0.7352521  time: 0.937 s\n",
      "[epoch 49,imgs   160] loss: 0.7435788  time: 0.946 s\n",
      "[epoch 49,imgs   200] loss: 0.7374565  time: 0.937 s\n",
      "[epoch 49,imgs   240] loss: 0.7412794  time: 0.935 s\n",
      "[epoch 49,imgs   280] loss: 0.7397954  time: 0.934 s\n",
      "[epoch 49,imgs   320] loss: 0.7363414  time: 0.937 s\n",
      "[epoch 49,imgs   360] loss: 0.7358292  time: 0.936 s\n",
      "[epoch 49,imgs   400] loss: 0.7376516  time: 0.935 s\n",
      "[epoch 49,imgs   440] loss: 0.7396050  time: 0.935 s\n",
      "[epoch 49,imgs   480] loss: 0.7380544  time: 0.934 s\n",
      "[epoch 49,imgs   520] loss: 0.7385810  time: 0.947 s\n",
      "[epoch 49,imgs   560] loss: 0.7422891  time: 0.937 s\n",
      "[epoch 49,imgs   600] loss: 0.7358184  time: 0.938 s\n",
      "[epoch 49,imgs   640] loss: 0.7382710  time: 0.936 s\n",
      "[epoch 49,imgs   680] loss: 0.7355421  time: 0.936 s\n",
      "[epoch 49,imgs   720] loss: 0.7363588  time: 0.936 s\n",
      "[epoch 49,imgs   760] loss: 0.7397889  time: 0.936 s\n",
      "[epoch 49,imgs   800] loss: 0.7324843  time: 0.934 s\n",
      "[epoch 49,imgs   840] loss: 0.7374969  time: 0.938 s\n",
      "[epoch 49,imgs   880] loss: 0.7384421  time: 0.942 s\n",
      "[epoch 49,imgs   920] loss: 0.7376335  time: 0.937 s\n",
      "[epoch 49,imgs   960] loss: 0.7427786  time: 0.938 s\n",
      "[epoch 49,imgs  1000] loss: 0.7350881  time: 0.937 s\n",
      "[epoch 49,imgs  1040] loss: 0.7391280  time: 0.937 s\n",
      "[epoch 49,imgs  1080] loss: 0.7367894  time: 0.939 s\n",
      "[epoch 49,imgs  1120] loss: 0.7432360  time: 0.937 s\n",
      "[epoch 49,imgs  1160] loss: 0.7366374  time: 0.947 s\n",
      "[epoch 49,imgs  1200] loss: 0.7349039  time: 0.940 s\n",
      "[epoch 50,imgs    40] loss: 0.7366613  time: 1.375 s\n",
      "[epoch 50,imgs    80] loss: 0.7410957  time: 0.936 s\n",
      "[epoch 50,imgs   120] loss: 0.7351862  time: 0.940 s\n",
      "[epoch 50,imgs   160] loss: 0.7355965  time: 0.935 s\n",
      "[epoch 50,imgs   200] loss: 0.7362170  time: 0.937 s\n",
      "[epoch 50,imgs   240] loss: 0.7414358  time: 0.952 s\n",
      "[epoch 50,imgs   280] loss: 0.7421417  time: 0.936 s\n",
      "[epoch 50,imgs   320] loss: 0.7340201  time: 0.959 s\n",
      "[epoch 50,imgs   360] loss: 0.7349313  time: 0.957 s\n",
      "[epoch 50,imgs   400] loss: 0.7329007  time: 0.955 s\n",
      "[epoch 50,imgs   440] loss: 0.7345281  time: 0.966 s\n",
      "[epoch 50,imgs   480] loss: 0.7339513  time: 0.937 s\n",
      "[epoch 50,imgs   520] loss: 0.7354574  time: 0.938 s\n",
      "[epoch 50,imgs   560] loss: 0.7383066  time: 0.948 s\n",
      "[epoch 50,imgs   600] loss: 0.7399250  time: 0.937 s\n",
      "[epoch 50,imgs   640] loss: 0.7372578  time: 0.937 s\n",
      "[epoch 50,imgs   680] loss: 0.7428194  time: 0.937 s\n",
      "[epoch 50,imgs   720] loss: 0.7397289  time: 0.941 s\n",
      "[epoch 50,imgs   760] loss: 0.7366901  time: 0.943 s\n",
      "[epoch 50,imgs   800] loss: 0.7412940  time: 0.939 s\n",
      "[epoch 50,imgs   840] loss: 0.7364444  time: 0.937 s\n",
      "[epoch 50,imgs   880] loss: 0.7343699  time: 1.008 s\n",
      "[epoch 50,imgs   920] loss: 0.7413310  time: 0.989 s\n",
      "[epoch 50,imgs   960] loss: 0.7456552  time: 0.942 s\n",
      "[epoch 50,imgs  1000] loss: 0.7376113  time: 0.938 s\n",
      "[epoch 50,imgs  1040] loss: 0.7339808  time: 0.937 s\n",
      "[epoch 50,imgs  1080] loss: 0.7361155  time: 0.937 s\n",
      "[epoch 50,imgs  1120] loss: 0.7415791  time: 0.933 s\n",
      "[epoch 50,imgs  1160] loss: 0.7424811  time: 0.934 s\n",
      "[epoch 50,imgs  1200] loss: 0.7363216  time: 0.941 s\n",
      "[epoch 51,imgs    40] loss: 0.7341968  time: 1.354 s\n",
      "[epoch 51,imgs    80] loss: 0.7344170  time: 0.939 s\n",
      "[epoch 51,imgs   120] loss: 0.7369399  time: 0.953 s\n",
      "[epoch 51,imgs   160] loss: 0.7353932  time: 0.941 s\n",
      "[epoch 51,imgs   200] loss: 0.7378936  time: 0.937 s\n",
      "[epoch 51,imgs   240] loss: 0.7382811  time: 0.945 s\n",
      "[epoch 51,imgs   280] loss: 0.7384357  time: 0.937 s\n",
      "[epoch 51,imgs   320] loss: 0.7370923  time: 0.945 s\n",
      "[epoch 51,imgs   360] loss: 0.7388227  time: 0.934 s\n",
      "[epoch 51,imgs   400] loss: 0.7374336  time: 0.933 s\n",
      "[epoch 51,imgs   440] loss: 0.7353895  time: 0.931 s\n",
      "[epoch 51,imgs   480] loss: 0.7357457  time: 0.935 s\n",
      "[epoch 51,imgs   520] loss: 0.7419758  time: 0.932 s\n",
      "[epoch 51,imgs   560] loss: 0.7354895  time: 0.935 s\n",
      "[epoch 51,imgs   600] loss: 0.7345951  time: 0.933 s\n",
      "[epoch 51,imgs   640] loss: 0.7385672  time: 0.934 s\n",
      "[epoch 51,imgs   680] loss: 0.7399521  time: 0.936 s\n",
      "[epoch 51,imgs   720] loss: 0.7388232  time: 0.935 s\n",
      "[epoch 51,imgs   760] loss: 0.7379464  time: 0.934 s\n",
      "[epoch 51,imgs   800] loss: 0.7393625  time: 0.933 s\n",
      "[epoch 51,imgs   840] loss: 0.7364377  time: 0.934 s\n",
      "[epoch 51,imgs   880] loss: 0.7363008  time: 0.934 s\n",
      "[epoch 51,imgs   920] loss: 0.7404405  time: 0.933 s\n",
      "[epoch 51,imgs   960] loss: 0.7385355  time: 0.933 s\n",
      "[epoch 51,imgs  1000] loss: 0.7415298  time: 0.934 s\n",
      "[epoch 51,imgs  1040] loss: 0.7387505  time: 0.935 s\n",
      "[epoch 51,imgs  1080] loss: 0.7395331  time: 0.934 s\n",
      "[epoch 51,imgs  1120] loss: 0.7390559  time: 0.936 s\n",
      "[epoch 51,imgs  1160] loss: 0.7375614  time: 0.933 s\n",
      "[epoch 51,imgs  1200] loss: 0.7383017  time: 0.932 s\n",
      "[epoch 52,imgs    40] loss: 0.7401377  time: 1.318 s\n",
      "[epoch 52,imgs    80] loss: 0.7435701  time: 0.958 s\n",
      "[epoch 52,imgs   120] loss: 0.7414234  time: 0.938 s\n",
      "[epoch 52,imgs   160] loss: 0.7391522  time: 0.937 s\n",
      "[epoch 52,imgs   200] loss: 0.7385182  time: 0.934 s\n",
      "[epoch 52,imgs   240] loss: 0.7400562  time: 0.947 s\n",
      "[epoch 52,imgs   280] loss: 0.7376333  time: 0.943 s\n",
      "[epoch 52,imgs   320] loss: 0.7392495  time: 0.934 s\n",
      "[epoch 52,imgs   360] loss: 0.7381695  time: 0.943 s\n",
      "[epoch 52,imgs   400] loss: 0.7396233  time: 0.934 s\n",
      "[epoch 52,imgs   440] loss: 0.7427894  time: 0.935 s\n",
      "[epoch 52,imgs   480] loss: 0.7415759  time: 0.941 s\n",
      "[epoch 52,imgs   520] loss: 0.7375590  time: 0.935 s\n",
      "[epoch 52,imgs   560] loss: 0.7418246  time: 0.943 s\n",
      "[epoch 52,imgs   600] loss: 0.7379025  time: 0.939 s\n",
      "[epoch 52,imgs   640] loss: 0.7400612  time: 0.944 s\n",
      "[epoch 52,imgs   680] loss: 0.7370294  time: 0.935 s\n",
      "[epoch 52,imgs   720] loss: 0.7416976  time: 0.935 s\n",
      "[epoch 52,imgs   760] loss: 0.7375754  time: 0.935 s\n",
      "[epoch 52,imgs   800] loss: 0.7378845  time: 0.941 s\n",
      "[epoch 52,imgs   840] loss: 0.7370713  time: 0.935 s\n",
      "[epoch 52,imgs   880] loss: 0.7363361  time: 0.935 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 52,imgs   920] loss: 0.7324858  time: 0.934 s\n",
      "[epoch 52,imgs   960] loss: 0.7394415  time: 0.935 s\n",
      "[epoch 52,imgs  1000] loss: 0.7337574  time: 0.935 s\n",
      "[epoch 52,imgs  1040] loss: 0.7328513  time: 0.935 s\n",
      "[epoch 52,imgs  1080] loss: 0.7419710  time: 0.932 s\n",
      "[epoch 52,imgs  1120] loss: 0.7423900  time: 0.936 s\n",
      "[epoch 52,imgs  1160] loss: 0.7411221  time: 0.936 s\n",
      "[epoch 52,imgs  1200] loss: 0.7394798  time: 0.935 s\n",
      "[epoch 53,imgs    40] loss: 0.7365831  time: 1.357 s\n",
      "[epoch 53,imgs    80] loss: 0.7435033  time: 0.939 s\n",
      "[epoch 53,imgs   120] loss: 0.7405713  time: 0.935 s\n",
      "[epoch 53,imgs   160] loss: 0.7389740  time: 0.935 s\n",
      "[epoch 53,imgs   200] loss: 0.7417123  time: 0.933 s\n",
      "[epoch 53,imgs   240] loss: 0.7344328  time: 0.935 s\n",
      "[epoch 53,imgs   280] loss: 0.7354688  time: 0.938 s\n",
      "[epoch 53,imgs   320] loss: 0.7428561  time: 0.942 s\n",
      "[epoch 53,imgs   360] loss: 0.7411804  time: 0.949 s\n",
      "[epoch 53,imgs   400] loss: 0.7386680  time: 0.935 s\n",
      "[epoch 53,imgs   440] loss: 0.7395324  time: 0.935 s\n",
      "[epoch 53,imgs   480] loss: 0.7385581  time: 0.946 s\n",
      "[epoch 53,imgs   520] loss: 0.7432315  time: 0.939 s\n",
      "[epoch 53,imgs   560] loss: 0.7398896  time: 0.942 s\n",
      "[epoch 53,imgs   600] loss: 0.7403571  time: 0.940 s\n",
      "[epoch 53,imgs   640] loss: 0.7333039  time: 0.934 s\n",
      "[epoch 53,imgs   680] loss: 0.7355265  time: 0.933 s\n",
      "[epoch 53,imgs   720] loss: 0.7403967  time: 0.934 s\n",
      "[epoch 53,imgs   760] loss: 0.7385117  time: 0.937 s\n",
      "[epoch 53,imgs   800] loss: 0.7365964  time: 0.935 s\n",
      "[epoch 53,imgs   840] loss: 0.7377666  time: 0.934 s\n",
      "[epoch 53,imgs   880] loss: 0.7373342  time: 0.933 s\n",
      "[epoch 53,imgs   920] loss: 0.7410089  time: 0.934 s\n",
      "[epoch 53,imgs   960] loss: 0.7369642  time: 0.935 s\n",
      "[epoch 53,imgs  1000] loss: 0.7404557  time: 0.935 s\n",
      "[epoch 53,imgs  1040] loss: 0.7394215  time: 0.934 s\n",
      "[epoch 53,imgs  1080] loss: 0.7352008  time: 0.933 s\n",
      "[epoch 53,imgs  1120] loss: 0.7380303  time: 0.932 s\n",
      "[epoch 53,imgs  1160] loss: 0.7390516  time: 0.933 s\n",
      "[epoch 53,imgs  1200] loss: 0.7419068  time: 0.950 s\n",
      "[epoch 54,imgs    40] loss: 0.7371274  time: 1.319 s\n",
      "[epoch 54,imgs    80] loss: 0.7332830  time: 0.936 s\n",
      "[epoch 54,imgs   120] loss: 0.7433646  time: 0.936 s\n",
      "[epoch 54,imgs   160] loss: 0.7373607  time: 0.935 s\n",
      "[epoch 54,imgs   200] loss: 0.7369743  time: 0.935 s\n",
      "[epoch 54,imgs   240] loss: 0.7403975  time: 0.933 s\n",
      "[epoch 54,imgs   280] loss: 0.7425511  time: 0.935 s\n",
      "[epoch 54,imgs   320] loss: 0.7393279  time: 0.934 s\n",
      "[epoch 54,imgs   360] loss: 0.7325291  time: 0.935 s\n",
      "[epoch 54,imgs   400] loss: 0.7368394  time: 0.933 s\n",
      "[epoch 54,imgs   440] loss: 0.7370208  time: 0.948 s\n",
      "[epoch 54,imgs   480] loss: 0.7379137  time: 0.938 s\n",
      "[epoch 54,imgs   520] loss: 0.7422907  time: 0.938 s\n",
      "[epoch 54,imgs   560] loss: 0.7331100  time: 0.939 s\n",
      "[epoch 54,imgs   600] loss: 0.7356759  time: 0.937 s\n",
      "[epoch 54,imgs   640] loss: 0.7424315  time: 0.936 s\n",
      "[epoch 54,imgs   680] loss: 0.7399263  time: 0.935 s\n",
      "[epoch 54,imgs   720] loss: 0.7372914  time: 0.936 s\n",
      "[epoch 54,imgs   760] loss: 0.7374815  time: 0.937 s\n",
      "[epoch 54,imgs   800] loss: 0.7402844  time: 0.942 s\n",
      "[epoch 54,imgs   840] loss: 0.7384065  time: 0.935 s\n",
      "[epoch 54,imgs   880] loss: 0.7379900  time: 0.936 s\n",
      "[epoch 54,imgs   920] loss: 0.7345620  time: 0.936 s\n",
      "[epoch 54,imgs   960] loss: 0.7383656  time: 0.937 s\n",
      "[epoch 54,imgs  1000] loss: 0.7383562  time: 0.935 s\n",
      "[epoch 54,imgs  1040] loss: 0.7362725  time: 0.935 s\n",
      "[epoch 54,imgs  1080] loss: 0.7445596  time: 0.934 s\n",
      "[epoch 54,imgs  1120] loss: 0.7370905  time: 0.937 s\n",
      "[epoch 54,imgs  1160] loss: 0.7433241  time: 0.937 s\n",
      "[epoch 54,imgs  1200] loss: 0.7323264  time: 0.935 s\n",
      "[epoch 55,imgs    40] loss: 0.7327207  time: 1.322 s\n",
      "[epoch 55,imgs    80] loss: 0.7392565  time: 0.937 s\n",
      "[epoch 55,imgs   120] loss: 0.7383165  time: 0.934 s\n",
      "[epoch 55,imgs   160] loss: 0.7414813  time: 0.934 s\n",
      "[epoch 55,imgs   200] loss: 0.7348121  time: 0.935 s\n",
      "[epoch 55,imgs   240] loss: 0.7307686  time: 0.934 s\n",
      "[epoch 55,imgs   280] loss: 0.7380189  time: 0.940 s\n",
      "[epoch 55,imgs   320] loss: 0.7388219  time: 0.940 s\n",
      "[epoch 55,imgs   360] loss: 0.7401139  time: 0.936 s\n",
      "[epoch 55,imgs   400] loss: 0.7349238  time: 0.934 s\n",
      "[epoch 55,imgs   440] loss: 0.7379034  time: 0.936 s\n",
      "[epoch 55,imgs   480] loss: 0.7361736  time: 0.935 s\n",
      "[epoch 55,imgs   520] loss: 0.7393814  time: 0.938 s\n",
      "[epoch 55,imgs   560] loss: 0.7375341  time: 0.935 s\n",
      "[epoch 55,imgs   600] loss: 0.7433706  time: 0.937 s\n",
      "[epoch 55,imgs   640] loss: 0.7363331  time: 0.936 s\n",
      "[epoch 55,imgs   680] loss: 0.7392479  time: 0.936 s\n",
      "[epoch 55,imgs   720] loss: 0.7404283  time: 0.938 s\n",
      "[epoch 55,imgs   760] loss: 0.7363985  time: 0.938 s\n",
      "[epoch 55,imgs   800] loss: 0.7371911  time: 0.934 s\n",
      "[epoch 55,imgs   840] loss: 0.7384533  time: 0.937 s\n",
      "[epoch 55,imgs   880] loss: 0.7445764  time: 0.939 s\n",
      "[epoch 55,imgs   920] loss: 0.7375607  time: 0.936 s\n",
      "[epoch 55,imgs   960] loss: 0.7412398  time: 0.938 s\n",
      "[epoch 55,imgs  1000] loss: 0.7386573  time: 0.941 s\n",
      "[epoch 55,imgs  1040] loss: 0.7377980  time: 0.934 s\n",
      "[epoch 55,imgs  1080] loss: 0.7429782  time: 0.936 s\n",
      "[epoch 55,imgs  1120] loss: 0.7384481  time: 0.936 s\n",
      "[epoch 55,imgs  1160] loss: 0.7394788  time: 0.937 s\n",
      "[epoch 55,imgs  1200] loss: 0.7337818  time: 0.937 s\n",
      "[epoch 56,imgs    40] loss: 0.7363749  time: 1.338 s\n",
      "[epoch 56,imgs    80] loss: 0.7337393  time: 0.935 s\n",
      "[epoch 56,imgs   120] loss: 0.7412729  time: 0.937 s\n",
      "[epoch 56,imgs   160] loss: 0.7399688  time: 0.934 s\n",
      "[epoch 56,imgs   200] loss: 0.7372687  time: 0.935 s\n",
      "[epoch 56,imgs   240] loss: 0.7383297  time: 0.937 s\n",
      "[epoch 56,imgs   280] loss: 0.7334703  time: 0.934 s\n",
      "[epoch 56,imgs   320] loss: 0.7344863  time: 0.936 s\n",
      "[epoch 56,imgs   360] loss: 0.7383184  time: 0.937 s\n",
      "[epoch 56,imgs   400] loss: 0.7403401  time: 0.935 s\n",
      "[epoch 56,imgs   440] loss: 0.7391750  time: 0.938 s\n",
      "[epoch 56,imgs   480] loss: 0.7354549  time: 0.938 s\n",
      "[epoch 56,imgs   520] loss: 0.7416607  time: 0.935 s\n",
      "[epoch 56,imgs   560] loss: 0.7401381  time: 0.939 s\n",
      "[epoch 56,imgs   600] loss: 0.7388375  time: 0.936 s\n",
      "[epoch 56,imgs   640] loss: 0.7460914  time: 0.948 s\n",
      "[epoch 56,imgs   680] loss: 0.7371787  time: 0.954 s\n",
      "[epoch 56,imgs   720] loss: 0.7387409  time: 0.936 s\n",
      "[epoch 56,imgs   760] loss: 0.7382926  time: 0.935 s\n",
      "[epoch 56,imgs   800] loss: 0.7373881  time: 0.937 s\n",
      "[epoch 56,imgs   840] loss: 0.7390469  time: 0.935 s\n",
      "[epoch 56,imgs   880] loss: 0.7360737  time: 0.936 s\n",
      "[epoch 56,imgs   920] loss: 0.7387000  time: 0.939 s\n",
      "[epoch 56,imgs   960] loss: 0.7391799  time: 0.936 s\n",
      "[epoch 56,imgs  1000] loss: 0.7393767  time: 0.934 s\n",
      "[epoch 56,imgs  1040] loss: 0.7398521  time: 0.936 s\n",
      "[epoch 56,imgs  1080] loss: 0.7406565  time: 0.936 s\n",
      "[epoch 56,imgs  1120] loss: 0.7362025  time: 0.935 s\n",
      "[epoch 56,imgs  1160] loss: 0.7385970  time: 0.939 s\n",
      "[epoch 56,imgs  1200] loss: 0.7401857  time: 0.935 s\n",
      "[epoch 57,imgs    40] loss: 0.7382922  time: 1.347 s\n",
      "[epoch 57,imgs    80] loss: 0.7318532  time: 0.935 s\n",
      "[epoch 57,imgs   120] loss: 0.7392394  time: 0.932 s\n",
      "[epoch 57,imgs   160] loss: 0.7443783  time: 0.939 s\n",
      "[epoch 57,imgs   200] loss: 0.7397375  time: 0.935 s\n",
      "[epoch 57,imgs   240] loss: 0.7407317  time: 0.937 s\n",
      "[epoch 57,imgs   280] loss: 0.7379086  time: 0.934 s\n",
      "[epoch 57,imgs   320] loss: 0.7396916  time: 0.935 s\n",
      "[epoch 57,imgs   360] loss: 0.7405761  time: 0.939 s\n",
      "[epoch 57,imgs   400] loss: 0.7392641  time: 0.934 s\n",
      "[epoch 57,imgs   440] loss: 0.7386653  time: 0.940 s\n",
      "[epoch 57,imgs   480] loss: 0.7371116  time: 0.939 s\n",
      "[epoch 57,imgs   520] loss: 0.7395132  time: 0.935 s\n",
      "[epoch 57,imgs   560] loss: 0.7371563  time: 0.935 s\n",
      "[epoch 57,imgs   600] loss: 0.7351799  time: 0.936 s\n",
      "[epoch 57,imgs   640] loss: 0.7410405  time: 0.935 s\n",
      "[epoch 57,imgs   680] loss: 0.7350044  time: 0.936 s\n",
      "[epoch 57,imgs   720] loss: 0.7376400  time: 0.937 s\n",
      "[epoch 57,imgs   760] loss: 0.7397640  time: 0.936 s\n",
      "[epoch 57,imgs   800] loss: 0.7342061  time: 0.936 s\n",
      "[epoch 57,imgs   840] loss: 0.7371565  time: 0.939 s\n",
      "[epoch 57,imgs   880] loss: 0.7341441  time: 0.939 s\n",
      "[epoch 57,imgs   920] loss: 0.7395700  time: 0.937 s\n",
      "[epoch 57,imgs   960] loss: 0.7384239  time: 0.938 s\n",
      "[epoch 57,imgs  1000] loss: 0.7386985  time: 0.958 s\n",
      "[epoch 57,imgs  1040] loss: 0.7366794  time: 0.938 s\n",
      "[epoch 57,imgs  1080] loss: 0.7382779  time: 0.936 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 57,imgs  1120] loss: 0.7394051  time: 0.937 s\n",
      "[epoch 57,imgs  1160] loss: 0.7365428  time: 0.938 s\n",
      "[epoch 57,imgs  1200] loss: 0.7410303  time: 0.936 s\n",
      "[epoch 58,imgs    40] loss: 0.7372298  time: 1.305 s\n",
      "[epoch 58,imgs    80] loss: 0.7405221  time: 0.937 s\n",
      "[epoch 58,imgs   120] loss: 0.7373906  time: 0.935 s\n",
      "[epoch 58,imgs   160] loss: 0.7342205  time: 0.936 s\n",
      "[epoch 58,imgs   200] loss: 0.7414857  time: 0.936 s\n",
      "[epoch 58,imgs   240] loss: 0.7353005  time: 0.936 s\n",
      "[epoch 58,imgs   280] loss: 0.7356502  time: 0.935 s\n",
      "[epoch 58,imgs   320] loss: 0.7353168  time: 0.934 s\n",
      "[epoch 58,imgs   360] loss: 0.7415955  time: 0.937 s\n",
      "[epoch 58,imgs   400] loss: 0.7419056  time: 0.931 s\n",
      "[epoch 58,imgs   440] loss: 0.7376432  time: 0.937 s\n",
      "[epoch 58,imgs   480] loss: 0.7407560  time: 0.938 s\n",
      "[epoch 58,imgs   520] loss: 0.7383026  time: 0.941 s\n",
      "[epoch 58,imgs   560] loss: 0.7401927  time: 0.935 s\n",
      "[epoch 58,imgs   600] loss: 0.7403374  time: 0.936 s\n",
      "[epoch 58,imgs   640] loss: 0.7376938  time: 0.936 s\n",
      "[epoch 58,imgs   680] loss: 0.7367811  time: 0.937 s\n",
      "[epoch 58,imgs   720] loss: 0.7419459  time: 0.940 s\n",
      "[epoch 58,imgs   760] loss: 0.7394102  time: 0.937 s\n",
      "[epoch 58,imgs   800] loss: 0.7375009  time: 0.935 s\n",
      "[epoch 58,imgs   840] loss: 0.7387999  time: 0.938 s\n",
      "[epoch 58,imgs   880] loss: 0.7371686  time: 0.937 s\n",
      "[epoch 58,imgs   920] loss: 0.7363876  time: 0.937 s\n",
      "[epoch 58,imgs   960] loss: 0.7414805  time: 0.936 s\n",
      "[epoch 58,imgs  1000] loss: 0.7425095  time: 0.935 s\n",
      "[epoch 58,imgs  1040] loss: 0.7390633  time: 0.936 s\n",
      "[epoch 58,imgs  1080] loss: 0.7399364  time: 0.942 s\n",
      "[epoch 58,imgs  1120] loss: 0.7378086  time: 0.941 s\n",
      "[epoch 58,imgs  1160] loss: 0.7346675  time: 0.939 s\n",
      "[epoch 58,imgs  1200] loss: 0.7412970  time: 0.938 s\n",
      "[epoch 59,imgs    40] loss: 0.7353150  time: 1.357 s\n",
      "[epoch 59,imgs    80] loss: 0.7341672  time: 0.939 s\n",
      "[epoch 59,imgs   120] loss: 0.7346497  time: 0.939 s\n",
      "[epoch 59,imgs   160] loss: 0.7380921  time: 0.937 s\n",
      "[epoch 59,imgs   200] loss: 0.7391972  time: 0.937 s\n",
      "[epoch 59,imgs   240] loss: 0.7333887  time: 0.938 s\n",
      "[epoch 59,imgs   280] loss: 0.7419402  time: 0.939 s\n",
      "[epoch 59,imgs   320] loss: 0.7403219  time: 0.935 s\n",
      "[epoch 59,imgs   360] loss: 0.7395850  time: 0.941 s\n",
      "[epoch 59,imgs   400] loss: 0.7339165  time: 0.932 s\n",
      "[epoch 59,imgs   440] loss: 0.7392092  time: 0.936 s\n",
      "[epoch 59,imgs   480] loss: 0.7390961  time: 0.938 s\n",
      "[epoch 59,imgs   520] loss: 0.7359217  time: 0.939 s\n",
      "[epoch 59,imgs   560] loss: 0.7402408  time: 0.938 s\n",
      "[epoch 59,imgs   600] loss: 0.7361395  time: 0.936 s\n",
      "[epoch 59,imgs   640] loss: 0.7353735  time: 0.937 s\n",
      "[epoch 59,imgs   680] loss: 0.7415257  time: 0.936 s\n",
      "[epoch 59,imgs   720] loss: 0.7370699  time: 0.938 s\n",
      "[epoch 59,imgs   760] loss: 0.7373648  time: 0.938 s\n",
      "[epoch 59,imgs   800] loss: 0.7345157  time: 0.938 s\n",
      "[epoch 59,imgs   840] loss: 0.7413963  time: 0.937 s\n",
      "[epoch 59,imgs   880] loss: 0.7353440  time: 0.938 s\n",
      "[epoch 59,imgs   920] loss: 0.7383513  time: 0.938 s\n",
      "[epoch 59,imgs   960] loss: 0.7345816  time: 0.945 s\n",
      "[epoch 59,imgs  1000] loss: 0.7424093  time: 0.938 s\n",
      "[epoch 59,imgs  1040] loss: 0.7351537  time: 0.941 s\n",
      "[epoch 59,imgs  1080] loss: 0.7365838  time: 0.938 s\n",
      "[epoch 59,imgs  1120] loss: 0.7380552  time: 0.940 s\n",
      "[epoch 59,imgs  1160] loss: 0.7385050  time: 0.939 s\n",
      "[epoch 59,imgs  1200] loss: 0.7406352  time: 0.941 s\n",
      "[epoch 60,imgs    40] loss: 0.7392028  time: 1.337 s\n",
      "[epoch 60,imgs    80] loss: 0.7404159  time: 0.938 s\n",
      "[epoch 60,imgs   120] loss: 0.7411034  time: 0.938 s\n",
      "[epoch 60,imgs   160] loss: 0.7419025  time: 0.938 s\n",
      "[epoch 60,imgs   200] loss: 0.7390489  time: 0.937 s\n",
      "[epoch 60,imgs   240] loss: 0.7353811  time: 0.935 s\n",
      "[epoch 60,imgs   280] loss: 0.7370772  time: 0.936 s\n",
      "[epoch 60,imgs   320] loss: 0.7366593  time: 0.935 s\n",
      "[epoch 60,imgs   360] loss: 0.7420186  time: 0.941 s\n",
      "[epoch 60,imgs   400] loss: 0.7408105  time: 0.933 s\n",
      "[epoch 60,imgs   440] loss: 0.7374037  time: 0.938 s\n",
      "[epoch 60,imgs   480] loss: 0.7350544  time: 0.937 s\n",
      "[epoch 60,imgs   520] loss: 0.7367700  time: 0.939 s\n",
      "[epoch 60,imgs   560] loss: 0.7392595  time: 0.936 s\n",
      "[epoch 60,imgs   600] loss: 0.7406995  time: 0.939 s\n",
      "[epoch 60,imgs   640] loss: 0.7370573  time: 0.939 s\n",
      "[epoch 60,imgs   680] loss: 0.7377687  time: 0.938 s\n",
      "[epoch 60,imgs   720] loss: 0.7398348  time: 0.937 s\n",
      "[epoch 60,imgs   760] loss: 0.7372400  time: 0.943 s\n",
      "[epoch 60,imgs   800] loss: 0.7420291  time: 0.938 s\n",
      "[epoch 60,imgs   840] loss: 0.7370713  time: 0.938 s\n",
      "[epoch 60,imgs   880] loss: 0.7361462  time: 0.939 s\n",
      "[epoch 60,imgs   920] loss: 0.7425023  time: 0.939 s\n",
      "[epoch 60,imgs   960] loss: 0.7380608  time: 0.939 s\n",
      "[epoch 60,imgs  1000] loss: 0.7335582  time: 0.946 s\n",
      "[epoch 60,imgs  1040] loss: 0.7384768  time: 0.939 s\n",
      "[epoch 60,imgs  1080] loss: 0.7360829  time: 0.940 s\n",
      "[epoch 60,imgs  1120] loss: 0.7380438  time: 0.944 s\n",
      "[epoch 60,imgs  1160] loss: 0.7381459  time: 0.939 s\n",
      "[epoch 60,imgs  1200] loss: 0.7369947  time: 0.947 s\n",
      "Extracting Features...\n",
      "tensor([32, 30, 23, 19, 47, 10, 46, 15, 39,  5, 45, 11, 38, 16, 30, 27])\n",
      "tensor([ 6, 48, 43, 32, 39, 20,  5, 43,  6, 32, 23, 34,  8, 18, 42, 12])\n",
      "tensor([30,  7, 23,  6, 16, 27, 40, 31, 29, 10, 21,  7, 15, 24, 32, 13])\n",
      "tensor([44, 22,  2, 39,  8,  5, 14, 37,  2, 36, 43,  1, 27, 39, 16, 25])\n",
      "tensor([ 2, 12, 20, 15,  2, 32,  7,  4, 49, 46, 34,  0, 30, 10, 35, 40])\n",
      "tensor([12, 38, 23,  2,  3, 37, 34, 40, 34, 21,  1, 36,  2, 36, 41, 10])\n",
      "tensor([38, 18, 33,  5,  8, 26, 17, 10,  1, 45,  8, 28, 11, 46, 41, 17])\n",
      "tensor([44, 24,  6, 26, 30, 26, 13, 23, 45, 33, 46, 46, 47, 29, 10, 49])\n",
      "tensor([20, 16,  0,  9, 15, 38, 41,  1, 27, 35, 23, 14, 23,  7, 16,  4])\n",
      "tensor([14,  9, 46, 28,  8, 27,  6, 47,  4, 15, 35, 44, 37, 10,  3,  5])\n",
      "tensor([36, 10, 21, 29,  5, 49, 39, 36, 11, 32, 17, 22, 44,  2, 36, 42])\n",
      "tensor([49, 41, 26, 10, 12,  6, 12,  4, 46, 15,  7, 24, 22, 37, 16, 24])\n",
      "tensor([10, 14, 32,  4, 36, 13, 45, 28, 19, 16, 17, 11, 37,  4,  0, 43])\n",
      "tensor([ 6, 10, 38, 22, 11, 34, 37, 41, 19, 13,  9, 45,  1, 44, 23,  3])\n",
      "tensor([ 7, 12, 27,  5, 42, 28, 12, 12,  1,  7, 13, 35, 48, 35, 35, 16])\n",
      "tensor([ 3, 26, 45, 26, 26, 33, 44, 41, 37,  9, 22, 43, 49,  5, 16, 47])\n",
      "tensor([44, 28, 29, 20, 11,  7, 45, 14, 34, 39, 48, 34, 38, 29, 35, 22])\n",
      "tensor([35,  7, 16, 19, 28, 29,  5,  4, 24,  0,  9, 20,  1, 12,  5, 42])\n",
      "tensor([31, 15, 37, 11, 38, 10, 40, 45,  3,  5, 21, 27, 15, 23, 19, 11])\n",
      "tensor([11, 26, 42,  0,  3, 29,  0, 30, 17, 32, 37,  3, 10, 10, 12, 17])\n",
      "tensor([ 0, 41, 35, 35,  4, 38, 22, 33, 11, 34, 39, 21,  1,  7,  1,  8])\n",
      "tensor([ 2, 48, 11, 48,  9,  4, 20, 24, 12, 38, 37,  5, 31, 43, 19, 19])\n",
      "tensor([41, 46, 19, 13, 37, 20, 18,  6, 22, 26, 37, 35, 46, 47, 35, 48])\n",
      "tensor([43, 26,  3, 13, 13, 39, 41, 27, 12, 28, 40,  9, 19, 36, 21, 28])\n",
      "tensor([48, 31, 34, 10, 21, 43,  0,  3,  3, 26, 38, 28, 45, 23, 10, 29])\n",
      "tensor([ 1, 11, 38, 40, 36, 46, 10, 38, 34, 28, 45, 38, 33, 30, 43, 19])\n",
      "tensor([32, 24, 29, 33, 16, 18, 17, 46, 36,  0, 11, 49,  7, 34, 26,  3])\n",
      "tensor([15, 49, 27,  8, 39, 42, 17, 31, 40,  1, 37, 39, 24,  4, 18, 20])\n",
      "tensor([27, 20, 44, 32, 35, 27, 19,  8, 19, 47, 36,  2, 33,  2, 44, 20])\n",
      "tensor([26, 44, 32, 39,  2, 19, 40, 49, 15, 31,  0, 37, 44,  0, 42, 49])\n",
      "tensor([34, 39, 37, 49, 46, 30, 32, 37, 16, 25, 10, 25, 15, 45, 24,  3])\n",
      "tensor([10, 19, 33, 43, 13, 36,  3,  8,  9, 42,  5, 13, 34, 21, 45, 33])\n",
      "tensor([44,  8, 32, 46, 40, 48, 15, 46, 26, 26, 42, 35, 14, 33, 10, 22])\n",
      "tensor([35, 36, 11,  6, 40, 31,  9,  9,  0, 19, 48, 41, 39, 45, 26, 42])\n",
      "tensor([25, 28, 23, 23, 27, 10, 49, 38, 39, 26, 13, 35,  5, 48, 38,  5])\n",
      "tensor([31, 13,  5, 30, 14,  3, 27, 46, 29, 45, 24, 14, 39,  8, 47, 24])\n",
      "tensor([25,  0, 24, 18, 16, 34, 27, 37, 37, 40,  0, 13,  6,  7, 37, 29])\n",
      "tensor([21, 32, 26,  1, 10, 23, 14, 39, 22, 27, 48, 27, 43, 44, 26,  7])\n",
      "tensor([33, 24, 28, 11, 18, 22,  1,  6, 34, 15, 27,  3,  9, 44, 18,  9])\n",
      "tensor([41,  2,  7,  0, 11, 42, 39, 37, 23, 18,  4, 29, 29,  3, 13, 38])\n",
      "tensor([15, 26, 39, 49, 25,  8, 39,  2,  2, 33, 44, 30, 14, 20, 17, 48])\n",
      "tensor([32, 10, 46,  7, 18, 34, 40, 49, 38, 10, 37, 33, 32, 43, 25,  1])\n",
      "tensor([32, 40, 18, 38, 36,  6, 28, 48, 24, 32, 28, 10,  9,  0, 36, 48])\n",
      "tensor([32, 23, 44,  3, 21,  0, 33, 19, 41, 43,  7, 15, 29, 18, 38,  6])\n",
      "tensor([49,  0, 46, 46,  9, 45, 41, 35, 43,  0,  5, 24,  6,  0, 43, 43])\n",
      "tensor([27,  4, 30, 32, 28, 41, 41, 30, 36, 47, 20, 21, 32, 47, 33, 34])\n",
      "tensor([25, 16, 39, 27, 15, 26, 28,  4, 38, 28, 13, 35, 42, 49, 25,  3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32,  7, 18, 36,  2, 20, 41, 41,  9, 47, 12, 12, 10, 44, 14, 31])\n",
      "tensor([26, 11, 39, 38, 15,  0, 19, 15, 37, 34, 28, 17,  4, 48, 10, 31])\n",
      "tensor([21, 14, 12,  9, 30, 13, 33, 23, 10,  9, 37, 14, 42, 14,  2,  9])\n",
      "tensor([33, 42, 22, 18, 36, 33, 34, 14, 26, 22, 33, 33, 20, 13, 23, 23])\n",
      "tensor([23, 16,  9, 41, 19, 44, 15, 20,  0,  1, 27, 46, 25, 16, 13, 10])\n",
      "tensor([44, 16,  3, 45, 30,  9, 35,  0, 40, 17, 46, 44, 46, 39,  1, 23])\n",
      "tensor([21,  7, 24, 28,  4,  5,  8, 26,  8, 22,  8, 46, 39, 38, 27, 11])\n",
      "tensor([25, 30, 43,  3, 44, 24, 38, 12, 28,  0, 17,  8, 43, 14, 15, 41])\n",
      "tensor([14, 27, 15, 48, 28, 48, 34, 42, 19, 38, 38, 34, 15, 46, 38, 27])\n",
      "tensor([11, 44, 43, 23, 24, 34, 14, 28, 33, 11, 38, 20,  6,  3, 27, 20])\n",
      "tensor([38,  7,  2, 45, 27, 43, 19, 35, 14, 15, 13,  4, 22, 18, 44,  9])\n",
      "tensor([22, 27, 19, 14, 34, 24,  1, 46, 12,  8,  7, 37, 10, 46, 45, 22])\n",
      "tensor([16, 38,  6,  8, 31,  3, 32, 49,  1, 35, 32, 19, 18, 20,  5,  9])\n",
      "tensor([18, 47,  4, 16,  7, 41,  0, 44,  4, 13,  0, 16, 49, 41, 22,  5])\n",
      "tensor([33, 15, 45, 15, 26, 38, 20, 20, 18, 46, 12, 14, 33, 19, 48, 16])\n",
      "tensor([16, 37, 17, 37,  5, 11, 37, 33, 10, 19, 31,  5, 27, 29, 26,  1])\n",
      "tensor([43, 14, 40, 17, 32, 13, 13, 25, 18, 34, 24, 40, 25, 49,  7, 30])\n",
      "tensor([44, 25, 48, 28, 11, 14, 11, 42, 11, 22, 23, 39, 13, 25,  1, 49])\n",
      "tensor([31, 14, 19,  7, 28, 35, 32, 42, 35, 49, 48, 47,  8, 28, 42,  3])\n",
      "tensor([44, 16, 11, 16,  7,  1, 29, 19, 18, 15,  1, 15, 24, 22, 23,  0])\n",
      "tensor([10, 10, 15,  4,  9, 46, 17, 31,  9, 13,  7,  9, 11, 12, 48, 36])\n",
      "tensor([21, 42, 41,  4, 34,  8, 33, 18, 18, 42, 30, 36, 29, 24, 49, 43])\n",
      "tensor([27, 45, 47, 38, 31,  3, 13,  5, 10,  6,  9, 45, 23, 44,  1, 15])\n",
      "tensor([27, 18, 16, 36, 32,  5, 16,  5, 49, 24, 31, 16, 41, 40, 42, 18])\n",
      "tensor([23, 34, 21, 11, 27, 12, 36, 30, 21, 40, 16, 29, 22, 14, 19, 48])\n",
      "tensor([45, 25, 32, 23, 19, 12, 30, 28, 27, 13,  3, 28, 34,  7, 16, 41])\n",
      "tensor([36, 32,  7, 38, 49, 31, 21,  6, 49, 17, 49, 24, 12,  3, 28,  2])\n",
      "tensor([17, 38, 15, 46, 19,  4, 33, 21, 35, 21, 15,  4, 46, 43,  5, 41])\n",
      "tensor([ 2, 11, 11, 45, 31, 47,  0, 28, 16, 44, 36, 10, 13, 20, 47, 27])\n",
      "tensor([37, 43,  8, 26, 10,  9,  6, 38,  0, 41,  5, 24, 24, 22, 43,  2])\n",
      "tensor([ 5, 20, 20, 22,  5, 42, 30, 29, 20, 42,  5, 45, 22,  6, 14, 26])\n",
      "tensor([11,  6,  7, 19, 10, 44, 14, 45, 12, 15, 33, 20, 35, 49, 12, 26])\n",
      "tensor([23, 24, 11, 13, 45, 22, 38, 35, 34, 41, 37, 39,  2, 33, 28,  6])\n",
      "tensor([43, 32, 24, 49, 33, 31, 25, 39, 20, 36, 11, 38, 15, 34, 10, 42])\n",
      "tensor([ 9, 21, 34, 23,  2, 37, 33, 16, 45, 36, 22, 32, 35, 31,  8, 42])\n",
      "tensor([25, 39, 46, 27, 27, 15, 43, 27,  5, 40, 34, 25, 26, 41, 26, 22])\n",
      "tensor([25, 34, 45, 41, 47,  5, 33, 38, 20, 15, 17, 20,  6, 48, 24, 37])\n",
      "tensor([45, 16,  4,  8, 20, 39, 35,  6, 48, 21, 14, 31, 36, 41, 36, 12])\n",
      "tensor([21, 44,  2, 41, 22, 27,  5, 27,  3, 27, 39, 32, 45,  8,  4, 37])\n",
      "tensor([44, 49, 17, 44, 45, 19, 21, 11, 18, 14, 49, 10, 39,  3, 23, 42])\n",
      "tensor([13, 44, 21, 35, 44, 17,  1, 26, 17, 47, 16,  2, 13, 29, 42, 41])\n",
      "tensor([23, 49, 25,  4, 35, 20, 32, 28, 26, 21, 47, 39,  4, 30, 11, 18])\n",
      "tensor([ 8, 23, 31, 46, 27, 27, 41, 13, 43, 11, 25, 27, 21, 36, 17,  8])\n",
      "tensor([34, 23, 25,  1, 20, 41, 12, 27, 48,  1, 11, 32, 11, 45, 30, 10])\n",
      "tensor([49, 26, 26, 26, 21, 29, 28, 37, 32, 42, 29, 14, 35, 26, 38,  5])\n",
      "tensor([34, 38, 48, 37, 49, 36, 16,  0, 28, 27, 31, 20, 21, 18, 28, 21])\n",
      "tensor([49, 42, 16, 39, 39, 10, 12,  3,  7, 40,  0, 34, 18, 10, 28, 22])\n",
      "tensor([11, 35, 17, 25, 16, 33, 49, 31,  7, 42, 48, 45, 13,  0,  3, 25])\n",
      "tensor([ 3,  0,  5, 45, 22,  6,  6, 43,  7, 34,  8, 11, 13, 36, 14,  9])\n",
      "tensor([31, 47, 18, 36,  2, 18, 49, 45, 13, 16,  0, 38,  2, 14,  2, 13])\n",
      "tensor([32, 28, 42,  3, 36, 41, 36, 38,  4, 22,  4, 19, 20, 47, 40, 16])\n",
      "tensor([10, 22, 41, 26,  2,  2, 30,  9, 34, 17, 45, 16, 47,  2,  0, 22])\n",
      "tensor([ 5,  1, 40,  8, 22, 15, 34, 22,  4, 36, 14,  3, 18, 49, 17, 38])\n",
      "tensor([24,  9, 41, 35, 17, 10, 31, 20, 42, 27, 46, 12, 46,  6, 19, 24])\n",
      "tensor([48, 16, 25, 45, 12, 25,  3, 39, 31, 15, 39, 18, 14, 25, 11, 18])\n",
      "tensor([ 2, 49, 14, 22, 21, 16, 36, 42, 32, 47,  9, 40, 32, 12, 22, 34])\n",
      "tensor([23, 48, 11, 25, 30, 28, 22, 47, 26, 28, 45, 27, 27, 31, 32, 27])\n",
      "tensor([ 0,  5, 48,  5, 12, 19, 10, 11, 35, 26, 47, 32,  5, 16,  1, 14])\n",
      "tensor([29, 31, 31, 43, 18, 49,  2, 29, 23, 18, 39, 13,  5, 37, 10, 12])\n",
      "tensor([38,  6,  4, 20, 48, 31, 13, 35, 10, 30, 15, 43, 31,  7, 28, 13])\n",
      "tensor([47,  8, 46, 29, 30,  7,  2, 46, 15, 48,  5, 12, 11, 25, 11, 30])\n",
      "tensor([29, 22, 15,  8, 25, 27,  9, 18,  5, 43,  7, 30, 26, 27,  5, 21])\n",
      "tensor([38,  8, 41,  5, 34,  4, 44, 13, 10, 18, 11, 34, 45, 36, 49, 46])\n",
      "tensor([24, 30, 24, 33, 10,  8, 24, 24, 11,  6,  9, 28, 18,  4, 18, 33])\n",
      "tensor([32, 39, 45, 28,  8,  7, 21, 39, 24,  8,  8,  4, 13, 11, 22, 19])\n",
      "tensor([37,  9,  4,  7, 21, 45, 28, 21,  8, 36, 45, 13, 27,  4, 40,  3])\n",
      "tensor([26, 10, 31, 49,  4, 35,  9, 11,  0, 11, 32, 37, 13,  3, 23,  9])\n",
      "tensor([ 0, 11, 36,  9,  0, 42, 25, 32,  3, 20, 17, 36, 11, 38, 25, 39])\n",
      "tensor([40,  4, 17, 35, 35, 13, 49, 43, 35, 21, 40, 36, 35, 39, 33,  7])\n",
      "tensor([35, 44, 37, 36, 16, 36,  3, 11, 30, 37, 49, 19, 14,  4, 39, 24])\n",
      "tensor([27, 14,  0, 31, 47, 43,  6, 24, 42, 38,  8, 29, 40,  1,  2, 31])\n",
      "tensor([23, 21, 20, 26, 32, 39, 37, 36, 45, 44, 21, 32, 21,  0, 47, 44])\n",
      "tensor([26, 45, 36, 32, 24, 26, 23, 31,  8, 16, 32, 16,  7, 30, 21, 33])\n",
      "tensor([13, 22, 24, 24, 41, 29,  0, 12, 20, 49, 43, 13, 34, 11,  1, 49])\n",
      "tensor([23, 45, 12, 33, 31,  4, 36, 37, 41, 18, 43, 45, 29, 35,  0, 27])\n",
      "tensor([18, 23, 44,  5, 16, 49, 24, 49, 35, 37, 27,  2, 49, 36, 36, 49])\n",
      "tensor([ 2, 25, 14, 29,  5,  7, 30, 41,  2, 46, 26, 23, 30, 31, 42, 37])\n",
      "tensor([ 9, 42, 20, 22, 36, 37, 21, 37, 12, 16, 33, 45, 30, 18,  0,  2])\n",
      "tensor([48,  3, 12, 45, 46, 39,  5, 22, 25, 10, 30,  2, 10, 25, 40,  6])\n",
      "tensor([32,  2, 40, 42, 23, 16, 10, 24, 24, 14,  0, 19, 45, 47, 15, 20])\n",
      "tensor([32, 38, 36,  4, 15, 10, 48, 10,  0, 16, 19, 11,  0,  1, 33, 32])\n",
      "tensor([17, 30,  0, 14, 16, 27, 36, 22, 16, 36, 44, 13,  5, 10, 24, 47])\n",
      "tensor([ 5, 43, 34,  5, 32,  5, 47, 42, 16,  1, 48, 24, 46, 46, 27, 33])\n",
      "tensor([ 8,  5, 36, 29, 11, 29,  8, 27, 21,  6,  5,  6, 29, 13, 14, 49])\n",
      "tensor([47, 19,  4,  1,  3, 29, 40, 23,  6, 32, 10,  1, 16, 45, 48, 38])\n",
      "tensor([31,  0,  4,  4, 29, 33, 35, 14,  2, 48, 31, 16, 32, 22, 34, 38])\n",
      "tensor([27,  8, 17, 37, 26, 15, 28, 34, 25, 24, 36, 11,  2, 33, 39, 27])\n",
      "tensor([18,  4,  5, 11,  7, 10, 41, 13, 43, 32, 48, 47, 24,  5,  7, 44])\n",
      "tensor([43, 44,  2, 28, 24, 49, 34, 20, 33,  9, 18, 41, 23, 26,  1, 25])\n",
      "tensor([43, 12, 40,  3, 26, 48, 32, 11, 16, 21, 11, 25, 30, 10,  6, 22])\n",
      "tensor([17, 39, 30, 32, 36, 32, 45, 33,  8, 38,  2, 16, 33, 12,  2, 13])\n",
      "tensor([22, 33,  1, 13, 32, 30, 11, 13, 13, 25, 25, 14, 18, 38, 47, 48])\n",
      "tensor([35, 29, 34, 40, 18, 22,  5, 25, 31,  3,  0, 38, 19,  3, 19, 41])\n",
      "tensor([18, 22, 18, 31, 30, 18, 26, 32,  6, 49, 30, 33, 34, 38, 47,  0])\n",
      "tensor([ 1, 13, 11,  9,  8, 31, 34, 27, 42, 12,  5, 38, 27, 43, 48, 12])\n",
      "tensor([48, 35, 14,  7,  6, 48, 26, 41, 25, 45,  7, 12, 14, 43, 30,  5])\n",
      "tensor([ 7, 29, 44, 23, 10,  6, 30, 32,  8, 15,  5, 39, 26, 10, 12, 11])\n",
      "tensor([ 3,  1,  5, 39, 19, 32, 40, 16, 49, 25, 38,  8, 17, 41, 48, 28])\n",
      "tensor([11,  5, 18, 13, 41, 49,  0, 38,  9, 15, 34, 36, 32,  8,  4, 24])\n",
      "tensor([25,  4, 45, 13, 40,  0, 24, 22, 27,  5, 17, 18, 46, 49, 12,  6])\n",
      "tensor([ 6,  6, 33, 43, 33, 20, 13,  4, 49, 43, 42, 17, 30, 30,  1, 44])\n",
      "tensor([18, 24, 15, 34, 27,  3,  0, 29, 16,  8, 21, 44, 13,  1, 30, 34])\n",
      "tensor([16,  9, 12, 38, 14, 19, 40, 15, 12, 43, 17, 14, 37, 47, 45,  6])\n",
      "tensor([11,  8,  5, 16, 48, 32,  7, 11,  4, 22, 47, 22, 15, 48, 31, 13])\n",
      "tensor([21,  2, 27, 34, 47, 48, 46, 35, 29, 17,  1,  0, 11, 18,  6, 45])\n",
      "tensor([47, 30, 23, 29, 38, 41, 16, 40, 18, 15, 10, 33, 35, 35, 31, 35])\n",
      "tensor([42, 23, 38, 40, 39,  9, 20,  3,  1,  0, 47, 33, 15, 45,  0, 28])\n",
      "tensor([ 3,  6, 39, 28, 32, 48, 32, 46, 28, 21, 24, 13, 37, 31, 17, 35])\n",
      "tensor([45, 30, 44, 27, 36, 45, 34, 14, 24, 44, 23, 32,  1, 14,  7,  2])\n",
      "tensor([47, 39,  1, 24, 32, 33, 45, 20,  5, 44, 16, 43, 34, 35, 44, 19])\n",
      "tensor([20, 38, 19, 11, 28, 35,  2, 23, 38, 16, 37, 31, 13, 35, 16, 47])\n",
      "tensor([46, 35, 23, 22, 10, 47, 18, 45, 47, 12, 33, 33, 15, 33,  2, 11])\n",
      "tensor([28,  5, 40,  9, 25, 24, 19, 42, 26, 40, 36, 23,  6, 18,  5,  7])\n",
      "tensor([24, 28, 41,  4, 45, 40, 36, 22,  9, 49, 16, 14, 25,  2, 43, 11])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15,  0, 48, 23, 20, 24,  8, 40, 29,  2, 38,  4,  6, 35,  6, 47])\n",
      "tensor([21, 39,  5, 16, 16,  0, 49, 29, 32,  8, 35, 32, 26, 45, 34, 46])\n",
      "tensor([11, 49, 23, 18,  0, 32, 12, 22, 48, 17,  2, 49, 34, 27, 21, 41])\n",
      "tensor([34, 38, 47,  9, 16,  8, 43, 27,  4,  6, 17, 32, 16, 36, 35,  1])\n",
      "tensor([49, 35,  0, 33, 16, 46, 24, 49,  2, 36, 21, 46, 48, 46, 15, 40])\n",
      "tensor([40, 46, 24, 27, 27, 10, 20,  0, 27, 33, 13, 44, 34, 23, 38, 33])\n",
      "tensor([27, 42, 36, 39, 35,  9, 17, 16, 49, 30, 39,  3, 41, 43, 40, 48])\n",
      "tensor([ 5, 14, 33, 24, 21, 12,  2, 31, 13, 41, 43, 30, 45, 48, 13,  1])\n",
      "tensor([48, 49, 26, 21, 17, 43, 21,  3, 47, 46, 27, 41, 13, 46, 21,  1])\n",
      "tensor([14, 36, 31, 24, 34, 31, 35, 39, 41, 17, 12, 10, 11, 41, 41, 10])\n",
      "tensor([ 7, 39, 21, 35, 35,  3, 28, 17,  6, 35, 34, 35,  6, 19,  1, 38])\n",
      "tensor([ 3,  3,  2, 25,  0,  6,  6, 40, 27, 38,  3, 43, 11, 10, 31, 34])\n",
      "tensor([14, 11, 33, 19, 18, 32, 26, 18,  9, 48, 49, 47, 23,  8, 18, 35])\n",
      "tensor([ 2,  4, 36, 17,  3, 42, 22, 28, 34, 40,  1, 47, 37,  6, 23, 22])\n",
      "tensor([45, 22, 46, 31,  6, 23, 49, 37, 11, 32, 21, 39, 37,  1,  7,  7])\n",
      "tensor([34, 38, 45,  0, 26, 45, 42, 21, 26, 46, 35, 46, 20, 33, 27,  5])\n",
      "tensor([40,  5, 25, 14,  3,  7, 21,  2, 19, 21, 14, 25, 25, 48, 16, 14])\n",
      "tensor([47,  0,  4, 33,  7, 33, 39, 33,  0, 28, 33, 12, 10, 33,  2, 11])\n",
      "tensor([ 0, 33, 19,  2,  2, 16,  3,  3, 12, 32, 41, 10, 10, 49, 21,  9])\n",
      "tensor([ 6, 17, 42,  2, 44, 47,  6, 19, 27, 36, 44, 38,  2, 39, 18, 48])\n",
      "tensor([38, 33, 39, 22,  5, 23, 22, 43,  4, 46, 21,  9, 16, 38, 25, 36])\n",
      "tensor([36, 11, 36,  7,  4,  0, 29, 19, 27,  7,  4, 39,  7, 19, 13, 34])\n",
      "tensor([33,  3, 27, 12, 16, 23, 44, 28, 26, 26, 41, 18,  8,  8,  8, 38])\n",
      "tensor([15, 22, 24, 34, 42, 34, 27, 20, 17, 27, 16, 22, 31, 17, 41, 30])\n",
      "tensor([42, 41, 35, 22, 17, 47, 23, 37, 20, 21, 24, 39,  6, 10, 27, 10])\n",
      "tensor([10, 38, 17, 27, 33, 49, 32, 34, 46, 31, 26, 13, 43, 26, 10,  3])\n",
      "tensor([27, 14, 26,  0,  7, 18, 13, 20, 45,  6, 48, 33, 27, 36, 11, 28])\n",
      "tensor([ 0, 22,  1,  9, 32,  4, 14,  9, 19, 33, 38, 46, 38, 26, 14,  7])\n",
      "tensor([47, 32, 31, 45,  0, 13, 34, 20, 10, 44, 28,  5, 49, 47, 11, 39])\n",
      "tensor([48,  0,  8, 22, 38, 39, 40, 25,  1, 23, 35, 40, 33,  7, 10,  8])\n",
      "tensor([ 6, 31, 46, 10, 27, 33, 28, 17, 46, 44, 45,  2, 34,  1, 25, 41])\n",
      "tensor([41, 20, 40, 30, 14,  5, 39, 10, 43,  2, 37, 29, 44,  7, 20, 19])\n",
      "tensor([13, 16, 32, 20, 38, 27, 21, 33, 42, 44, 45, 16, 32, 23, 27,  0])\n",
      "tensor([15, 17, 32, 33, 21, 49,  7, 15, 40, 41, 21, 37, 32, 29, 13, 21])\n",
      "tensor([42, 43, 15, 12, 38, 19, 41, 28,  1, 35, 12, 35, 22,  5, 34, 29])\n",
      "tensor([ 0,  6, 34, 18, 14, 16, 27, 17, 11, 32, 47, 33,  3, 17, 33, 49])\n",
      "tensor([13, 22, 10, 29, 26,  4, 24, 35, 33, 38, 17, 24, 49, 45,  2, 18])\n",
      "tensor([45, 34, 40, 34, 24, 32,  3, 18, 30,  3, 36, 48, 23, 48, 36, 23])\n",
      "tensor([47, 10, 12,  5, 14, 35, 20,  8, 17,  2, 38, 24, 37, 29, 49, 46])\n",
      "tensor([ 2, 32, 38,  2, 11, 39, 49, 14,  6, 29, 39, 29, 20, 41, 24, 12])\n",
      "tensor([15, 44,  7, 31, 18, 26,  6, 37, 36, 28, 44, 19, 34, 42, 26, 25])\n",
      "tensor([22, 12, 49, 30, 28, 32, 23, 11,  8, 44, 24, 29, 14, 41,  4, 26])\n",
      "tensor([44, 28, 20, 30, 39, 31, 48, 46, 15, 29, 14, 29, 29, 23, 25, 12])\n",
      "tensor([29, 40, 35,  1, 30, 30, 40,  4,  7, 42, 14, 39,  5, 33, 45, 15])\n",
      "tensor([35, 27, 27, 23, 23, 10, 12,  0, 20, 18, 29, 40, 20,  2, 40, 48])\n",
      "tensor([34,  5, 11, 30, 25,  2, 26, 32, 15, 29, 49, 37, 23, 30, 16, 46])\n",
      "tensor([27, 16,  2, 28, 49, 40,  2, 25, 26, 40, 16, 33, 44,  1, 10, 48])\n",
      "tensor([39, 48, 44,  9, 46, 10, 40,  5, 39, 33, 20, 21, 31, 23, 32,  8])\n",
      "tensor([20, 42, 10, 34, 19, 19, 29, 32, 21, 31, 28, 32, 19, 19, 19, 31])\n",
      "tensor([24,  2,  5, 24, 14, 35, 23,  9, 11, 38, 20, 45, 24, 11, 29, 43])\n",
      "tensor([ 1, 21,  3,  5,  1,  3, 30, 28, 18, 13, 45, 24, 46,  3, 36, 10])\n",
      "tensor([22, 44, 49, 27, 45,  2,  6, 43, 18,  5,  8,  2, 42, 47, 11, 21])\n",
      "tensor([ 3, 43, 48, 24, 35, 29,  3, 16, 31,  9,  3, 46,  5, 29, 11, 20])\n",
      "tensor([ 3, 48, 17, 14,  3, 23, 43, 24, 46, 15, 13, 21, 44, 12, 39, 33])\n",
      "tensor([33, 44, 48, 11, 41,  7, 26,  0, 34, 28, 31, 26, 21, 36, 38, 34])\n",
      "tensor([27, 45, 20, 43, 16, 23,  5, 35, 11, 24,  3, 41, 34, 35, 16, 41])\n",
      "tensor([ 7, 12, 41, 41, 28, 27,  2, 10,  9, 33, 38,  6, 17, 41, 36, 12])\n",
      "tensor([ 5, 42, 22, 15, 36, 33, 27, 37, 45, 46, 36, 45, 46, 31, 44, 12])\n",
      "tensor([22, 23, 29,  2, 38, 23, 20, 10, 29, 38,  9,  7, 16, 16,  7, 11])\n",
      "tensor([ 8,  7,  1, 39, 33, 17,  8, 15, 42,  9, 10, 33, 18,  1, 47, 32])\n",
      "tensor([14, 26, 15, 19,  5, 48, 48, 39,  5, 25, 20, 49, 43, 25, 40, 38])\n",
      "tensor([47, 22, 17, 41, 44, 17,  8, 12, 24, 27, 49,  3, 34, 41, 12, 13])\n",
      "tensor([46, 40, 13, 31, 12, 26, 49, 49, 30, 37,  3, 44, 10, 27, 11,  4])\n",
      "tensor([19, 21, 38,  0,  3, 30, 41, 44, 16, 29, 17, 46, 22,  4,  5, 21])\n",
      "tensor([11, 15, 23, 38, 44, 10, 15, 49, 49, 49,  5, 39,  1, 31,  0, 43])\n",
      "tensor([44,  2, 29, 38, 44, 38, 25, 25, 42, 15, 42, 36, 48, 15, 11, 28])\n",
      "tensor([11, 13, 45, 30, 48, 13, 48, 12, 13, 29, 17, 32, 34, 10, 37, 34])\n",
      "tensor([38, 43, 35, 49, 48, 30,  1, 48,  4, 36, 20, 20, 30, 15, 42, 40])\n",
      "tensor([26,  6, 22,  5, 15, 48,  0, 20, 11, 12, 49, 20, 10, 35,  9, 33])\n",
      "tensor([40, 21,  5, 20, 21, 45, 42, 19, 18, 14, 36, 19, 35, 29, 28, 24])\n",
      "tensor([ 5,  5, 19, 14, 27, 36, 17, 13,  4, 39, 48,  4, 11, 26, 28, 34])\n",
      "tensor([14,  1, 36, 16, 28,  0, 45, 38, 22,  3, 30,  6, 26, 43, 27, 47])\n",
      "tensor([39, 26, 39,  0, 31, 42, 11, 15,  9, 12, 15,  0, 30, 10, 37,  7])\n",
      "tensor([43, 33, 18,  7, 23, 39,  1, 36,  1, 11, 49,  3, 40, 14, 28, 25])\n",
      "tensor([12, 25, 14, 45, 41, 16, 20,  1, 29, 12, 19, 47, 11, 29, 46, 42])\n",
      "tensor([38, 26, 39, 39, 17, 26,  8, 10,  8, 49, 13, 45,  2, 49, 21, 36])\n",
      "tensor([35, 39, 14, 42,  4,  4, 43, 32, 16, 22, 21, 36, 42,  3,  0,  0])\n",
      "tensor([28, 41,  6, 38, 40,  0, 29, 48, 35, 23, 36, 49, 30, 41, 40, 32])\n",
      "tensor([46,  8, 30,  1, 22, 32, 40, 26, 49, 10, 49, 49, 37, 49, 15, 20])\n",
      "tensor([ 6, 27, 36, 14,  2,  1, 34, 27, 14,  6, 23, 23, 33,  2, 21, 39])\n",
      "tensor([45,  6, 43, 33,  0, 13, 47, 13, 12, 27, 11, 48, 34, 11,  1, 18])\n",
      "tensor([ 3, 22, 36, 10, 11, 35, 35, 12, 16, 17,  2, 12, 20, 36, 34, 31])\n",
      "tensor([ 7, 21,  0, 41,  0, 18, 34, 49,  4, 14, 10, 25, 39, 26, 19,  6])\n",
      "tensor([ 5, 21, 19, 41, 38, 12, 40, 22, 48, 33, 12,  3, 16, 48,  7, 38])\n",
      "tensor([ 3, 21, 43, 20, 35, 17, 45, 44,  9, 34, 14,  2, 11, 19,  5,  8])\n",
      "tensor([ 3, 35, 42, 29, 13, 39,  9,  1, 20, 25, 26, 42, 39, 12, 35, 14])\n",
      "tensor([39,  7, 32, 28,  2,  6,  2, 41, 43, 26, 46, 45,  1, 12, 27, 19])\n",
      "tensor([44, 45, 38,  1, 24,  9,  5, 25, 39, 45, 45, 35, 42, 21, 47, 19])\n",
      "tensor([ 8, 38, 16, 41, 47, 16, 26,  4, 31, 49, 49, 37, 42, 48, 12, 39])\n",
      "tensor([ 5, 28, 17, 15, 15, 25, 12,  0, 35,  3,  4, 32, 41, 26,  0, 10])\n",
      "tensor([37,  3, 34, 28, 31,  1, 45, 10, 29, 49,  4, 26, 41, 34, 22, 46])\n",
      "tensor([15, 27, 20, 24,  0, 28, 15, 32, 34,  0,  4, 17, 42, 13, 48,  5])\n",
      "tensor([21, 38, 37, 15, 25, 41, 18, 32, 17,  9, 33, 41, 49,  8, 18, 23])\n",
      "tensor([25, 41, 41,  2, 22, 11, 12, 34, 25, 29, 45, 26, 33, 49, 15, 38])\n",
      "tensor([ 2, 21,  9, 46, 26, 20, 46, 15, 19, 41,  6, 15, 20, 39, 28, 36])\n",
      "tensor([21, 46,  4, 46, 29, 12,  6, 49, 19, 14, 27, 22,  3, 40, 19, 36])\n",
      "tensor([31,  7,  8, 11, 37, 47, 34, 22, 49, 16, 26, 26,  7, 32,  9, 18])\n",
      "tensor([16,  0, 24, 34,  7,  1, 38, 32,  9, 33,  2,  3, 18, 36,  7,  3])\n",
      "tensor([32, 14,  4, 18,  2, 42, 42, 12, 21, 38, 46, 15, 15, 43, 23, 32])\n",
      "tensor([43, 41, 49, 49, 21, 42, 32, 41, 17,  3, 36, 19,  2, 10, 12,  6])\n",
      "tensor([48, 48,  5, 36,  3, 34,  9, 29, 27, 23, 20, 34, 32, 16, 21,  2])\n",
      "tensor([23,  9, 24, 36, 16, 17, 32, 49,  8, 35, 30, 35, 34, 46, 10, 38])\n",
      "tensor([36, 44, 12, 32, 43, 29, 11, 43, 16, 44, 28, 15, 36, 10, 43,  7])\n",
      "tensor([47,  8, 23, 49,  6, 37, 26, 22, 45, 45,  2, 23, 48, 16, 11, 37])\n",
      "tensor([38,  0,  7,  1, 16, 19,  4, 48, 11, 45, 23, 34, 20, 15, 19,  0])\n",
      "tensor([11, 16, 11, 24, 11, 48, 28, 34, 29, 24, 12, 35,  6, 23, 29, 15])\n",
      "tensor([20, 21,  7, 24,  7, 47, 11, 27, 49, 44, 27, 22,  4, 39,  5,  5])\n",
      "tensor([33, 15, 11, 11, 28, 13, 35, 27, 41, 36, 31, 42, 13, 24,  1, 25])\n",
      "tensor([38,  6, 43, 14, 32, 16, 30, 28, 34,  6, 36, 10, 43, 11, 47, 23])\n",
      "tensor([33, 13, 43, 17, 32, 14,  0, 17,  9,  7,  1, 44, 47,  9, 35, 38])\n",
      "tensor([45, 40, 35, 36, 27, 18, 36, 18, 29, 37, 21,  8,  0,  6, 26, 34])\n",
      "tensor([ 6, 32, 44, 33,  5, 21,  2, 20,  8, 49, 21, 26, 22, 37,  9, 24])\n",
      "tensor([47,  2, 12, 25, 10, 28, 39,  2, 44,  1, 34,  4, 30, 20, 46, 37])\n",
      "tensor([24, 22, 34, 31, 19, 17, 22, 26, 35, 26, 36, 16,  5,  4, 44, 40])\n",
      "tensor([16, 27, 39, 32, 45, 47, 10, 13, 28, 23, 40, 12,  5, 40, 13,  9])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19, 11, 32, 46, 45, 13, 21, 27, 23, 19, 19, 28, 16, 26,  7, 33])\n",
      "tensor([ 3, 24, 26, 25, 31,  7, 16, 36, 32,  6, 19, 38, 26, 33, 32, 30])\n",
      "tensor([36,  9, 11, 47, 46, 40,  0, 32, 45, 25, 13, 48, 42, 10, 17, 25])\n",
      "tensor([15, 20, 34,  1, 26, 38, 31, 36, 28,  9, 46, 15,  2,  9, 42, 48])\n",
      "tensor([23, 32, 13, 35, 19,  5, 19, 47, 24, 15, 16, 29, 37,  2, 38, 25])\n",
      "tensor([ 1, 47, 38, 29, 30, 47, 25, 11,  7, 46, 49, 30, 17, 23, 20, 40])\n",
      "tensor([39,  6, 19, 16, 44, 11, 32, 44, 14, 45, 20,  6, 32, 29, 12, 14])\n",
      "tensor([ 1, 22, 34, 29, 14, 13, 35,  1, 49, 23, 21, 29,  6, 11, 17, 20])\n",
      "tensor([ 0, 15, 15, 27, 18, 11, 39, 46,  6, 46, 38, 37, 31, 18, 16, 16])\n",
      "tensor([18,  3, 40, 39,  0, 31, 39,  0,  8, 25, 24, 34, 31, 29, 23, 37])\n",
      "tensor([21,  5, 42, 36, 39, 30, 25,  6, 40, 23,  3,  9, 19, 23, 43, 38])\n",
      "tensor([23, 38,  3, 30, 16, 18, 39,  2, 19, 23, 43, 45,  0, 16, 23, 45])\n",
      "tensor([30, 35,  7, 23, 14, 10, 11, 38, 29, 38, 35, 33, 17, 49, 45, 10])\n",
      "tensor([41, 46, 49, 29, 44, 40, 34, 37, 36,  6,  9, 42, 36, 35, 38,  7])\n",
      "tensor([15, 23, 31, 47, 25, 33, 30, 33, 13, 15,  5, 34, 11, 37, 12, 48])\n",
      "tensor([36, 34, 43, 30, 27, 12,  6, 18, 47, 14, 32,  1, 41, 20, 26, 38])\n",
      "tensor([23, 15, 43,  3,  2,  3,  5, 35, 26,  6, 36, 18,  3, 14, 15,  2])\n",
      "tensor([45, 35, 15, 15,  0,  2, 22, 42, 21, 29, 24, 39, 29, 49, 42,  8])\n",
      "tensor([ 7, 33, 42,  8, 33, 13, 44, 14, 17, 21, 14, 35,  3, 24, 25, 49])\n",
      "tensor([14, 23,  3, 27, 16, 24, 36,  0, 33, 16, 13, 20, 24, 22, 35, 36])\n",
      "tensor([ 7, 10,  0, 32, 14,  0, 46, 44, 24, 44, 30, 41, 35, 36, 31, 24])\n",
      "tensor([22, 35, 27, 43, 27, 20, 39, 45, 41, 40, 34, 35, 39, 37, 25, 24])\n",
      "tensor([49, 41, 13, 34, 10, 35,  1, 21, 12,  9,  2, 33, 14,  2, 30, 34])\n",
      "tensor([33, 16,  5, 45, 45, 34, 10,  7, 22, 27, 34, 12, 36, 31, 26, 26])\n",
      "tensor([ 5,  7, 14, 34, 40, 26,  5, 23, 38, 35,  2, 21, 42,  4, 46, 48])\n",
      "tensor([35, 26, 19, 40,  8, 39, 48, 33, 28, 15, 16,  1, 48, 18, 21, 10])\n",
      "tensor([ 6, 26,  7])\n"
     ]
    }
   ],
   "source": [
    "# cnn2fft\n",
    "# check PyTorch versions\n",
    "# import standard PyTorch modules\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pretrainedmodels\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard support\n",
    "\n",
    "# import torchvision module to handle image manipulation\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# calculate train time, writing train data to files etc.\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scipy\n",
    "import scipy.fft\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "#device = torch.device(\"cuda\")\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)     # On by default, leave it here for clarity\n",
    "# torch.cuda.current_device()\n",
    "\n",
    "# Helper class, help track loss, accuracy, epoch time, run time, \n",
    "# hyper-parameters etc. Also record to TensorBoard and write into csv, json\n",
    "\n",
    "# import modules to build RunBuilder and RunManager helper classes\n",
    "from collections  import OrderedDict\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "# Read in the hyper-parameters and return a Run namedtuple containing all the \n",
    "# combinations of hyper-parameters\n",
    "class RunBuilder():\n",
    "  @staticmethod\n",
    "  def get_runs(params):\n",
    "\n",
    "    Run = namedtuple('Run', params.keys())\n",
    "\n",
    "    runs = []\n",
    "    for v in product(*params.values()):\n",
    "      runs.append(Run(*v))\n",
    "    \n",
    "    return runs\n",
    "\n",
    "class RunManager():\n",
    "\n",
    "  def __init__(self):\n",
    "\n",
    "    # tracking every epoch count, loss, accuracy, time\n",
    "    self.epoch_count = 0\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "    \n",
    "    self.epoch_val_loss = 0\n",
    "    self.epoch_val_num_correct = 0\n",
    "    self.epoch_start_time = None\n",
    "\n",
    "    # tracking every run count, run data, hyper-params used, time\n",
    "    self.run_params = None\n",
    "    self.run_count = 0\n",
    "    self.run_data = []\n",
    "    self.run_start_time = None\n",
    "\n",
    "    # record model, loader and TensorBoard \n",
    "    self.network = None\n",
    "    self.loader = None\n",
    "    self.vloader = None\n",
    "    self.tb = None\n",
    "\n",
    "  # record the count, hyper-param, model, loader of each run\n",
    "  # record sample images and network graph to TensorBoard  \n",
    "  def begin_run(self, run, network, loader,vloader):\n",
    "\n",
    "    self.run_start_time = time.time()\n",
    "\n",
    "    self.run_params = run\n",
    "    self.run_count += 1\n",
    "\n",
    "    self.network = network\n",
    "    self.loader = loader\n",
    "    self.vloader = vloader\n",
    "    self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "    images, labels = next(iter(self.loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "    self.tb.add_image('images', grid)\n",
    "    self.tb.add_graph(self.network, images)\n",
    "\n",
    "  # when run ends, close TensorBoard, zero epoch count\n",
    "  def end_run(self):\n",
    "    self.tb.close()\n",
    "    self.epoch_count = 0\n",
    "\n",
    "  # zero epoch count, loss, accuracy, \n",
    "  def begin_epoch(self):\n",
    "    self.epoch_start_time = time.time()\n",
    "\n",
    "    self.epoch_count += 1\n",
    "    self.epoch_loss = 0\n",
    "    self.epoch_num_correct = 0\n",
    "\n",
    "  # \n",
    "  def end_epoch(self):\n",
    "    # calculate epoch duration and run duration(accumulate)\n",
    "    epoch_duration = time.time() - self.epoch_start_time\n",
    "    run_duration = time.time() - self.run_start_time\n",
    "\n",
    "    # record epoch loss and accuracy\n",
    "    loss = self.epoch_loss / len(self.loader.dataset)\n",
    "    accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "    \n",
    "    vloss = self.epoch_val_loss / len(self.vloader.dataset)\n",
    "    vaccuracy = self.epoch_val_num_correct / len(self.vloader.dataset)\n",
    "\n",
    "    # Record epoch loss and accuracy to TensorBoard \n",
    "    self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "    self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "    \n",
    "    # Record epoch loss and accuracy to TensorBoard \n",
    "    self.tb.add_scalar('vLoss', vloss, self.epoch_count)\n",
    "    self.tb.add_scalar('vAccuracy', vaccuracy, self.epoch_count)\n",
    "\n",
    "    # Record params to TensorBoard\n",
    "    for name, param in self.network.named_parameters():\n",
    "      self.tb.add_histogram(name, param, self.epoch_count)\n",
    "      self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "    \n",
    "    # Write into 'results' (OrderedDict) for all run related data\n",
    "    results = OrderedDict()\n",
    "    results[\"run\"] = self.run_count\n",
    "    results[\"epoch\"] = self.epoch_count\n",
    "    results[\"loss\"] = loss\n",
    "    results[\"val_loss\"] = self.epoch_val_loss\n",
    "    results[\"val_accuracy\"] = self.epoch_val_num_correct\n",
    "    results[\"accuracy\"] = accuracy\n",
    "    results[\"epoch duration\"] = epoch_duration\n",
    "    results[\"run duration\"] = run_duration\n",
    "\n",
    "    # Record hyper-params into 'results'\n",
    "    for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "    self.run_data.append(results)\n",
    "    df = pd.DataFrame.from_dict(self.run_data, orient = 'columns')\n",
    "\n",
    "    # display epoch information and show progress\n",
    "    clear_output(wait=True)\n",
    "    #display(df)\n",
    "\n",
    "  def track_vloss_vacc(self, loss, acc):\n",
    "    # multiply batch size so variety of batch sizes can be compared\n",
    "    self.epoch_val_loss = loss.item()\n",
    "    self.epoch_val_num_correct = acc\n",
    "    \n",
    "    \n",
    "    # accumulate loss of batch into entire epoch loss\n",
    "  def track_loss(self, loss):\n",
    "    # multiply batch size so variety of batch sizes can be compared\n",
    "    self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "  # accumulate number of corrects of batch into entire epoch num_correct\n",
    "  def track_num_correct(self, preds, labels):\n",
    "    self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def _get_num_correct(self, preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "  \n",
    "  # save end results of all runs into csv, json for further a\n",
    "  def save(self, fileName):\n",
    "\n",
    "    pd.DataFrame.from_dict(\n",
    "        self.run_data, \n",
    "        orient = 'columns',\n",
    "    ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "    with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "      json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(torch.cuda.get_device_properties(device),torch.cuda.set_device(device),torch.cuda.current_device())\n",
    "\n",
    "#Hyperparameters\n",
    "\n",
    "#input_size\n",
    "#num_classes = 50\n",
    "#learning_rate = 0.00005\n",
    "BATCH_SIZE = 32\n",
    "epochs = 1\n",
    "\n",
    "# put all hyper params into a OrderedDict, easily expandable\n",
    "params = OrderedDict(\n",
    "    exp='6',\n",
    "    lr = [0.0005],#,0.001,0.0001,0.00001], # 0.001\n",
    "    batch_size = [BATCH_SIZE], # 1000\n",
    "    shuffle = [True] # True,False\n",
    "    # Optimizer = [Adam,NAdam,RMSProp,Adamax,SGD,Adagrad,Adadelta]\n",
    ")\n",
    "\n",
    "TRAIN_DATA_PATH = \"./datax/\"+rep+\"/train/\"\n",
    "TEST_DATA_PATH = \"./datax/\"+rep+\"/test/\"\n",
    "\n",
    "transform = transforms.Compose([    \n",
    "    transforms.Resize(299), # preffered size for network\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True,  num_workers=4)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=16, shuffle=True,  num_workers=4)\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "\n",
    "#prepare model\n",
    "model_name = 'inceptionresnetv2' # could be fbresnet152 or inceptionresnetv2\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "\n",
    "model.last_linear = nn.Identity() #freeze the model\n",
    "#num_ftrs = model.last_linear.in_features\n",
    "#model.last_linear = nn.Linear(num_ftrs, 50)\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad =False\n",
    "    \n",
    "#num_ftrs = model.last_linear.in_features\n",
    "\n",
    "    # Here the size of each output sample is set to 2.\n",
    "    # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "#model.fc = nn.Linear(num_ftrs, 50)\n",
    "\n",
    "PATH = \"models/IRv2.pt\"\n",
    "\n",
    "torch.save(model,PATH)\n",
    "#model = torch.load(PATH)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "def train(model,loader,epochs=60):\n",
    "    model.to(device)\n",
    "    model.train()   \n",
    "    print('Training...')\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        model.train()\n",
    "        m.begin_epoch()\n",
    "        running_loss=0\n",
    "\n",
    "        for i,batch in enumerate(loader,0):\n",
    "                images = batch[0]\n",
    "                labels = batch[1]\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                preds = model(images)\n",
    "                loss = F.cross_entropy(preds, labels) # Adam, SGD, RSPROP\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = Variable(loss, requires_grad = True)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss+=loss.data\n",
    "\n",
    "                if i%10==9:\n",
    "                    end=time.time()\n",
    "                    #print ('[epoch %d,imgs %5d] time: %0.3f s'%(epoch+1,(i+1)*4,(end-start)))\n",
    "                    print ('[epoch %d,imgs %5d] loss: %.7f  time: %0.3f s'%(epoch+1,(i+1)*4,running_loss/100,(end-start)))\n",
    "                    #tb.add_scalar('Loss', loss, epoch+1)\n",
    "                    start=time.time()\n",
    "                    running_loss=0    \n",
    "    \n",
    "\n",
    "train(model,train_data_loader)\n",
    "\n",
    "\n",
    "print('Extracting Features...')\n",
    "feat,lbls = extract_features(model,train_data_loader)\n",
    "# randomforest, logisticregression, SVM , KNN, LD,  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49, 42, 24, 41, 13, 37,  2, 18, 14, 36,  0, 29, 44, 44, 27,  6])\n",
      "tensor([34, 26, 39,  4, 33, 37,  9, 30,  2, 40, 45, 38, 10,  7, 35, 31])\n",
      "tensor([11,  9, 19,  0, 36,  8,  7,  3, 11, 43, 28, 29, 33, 20, 33, 12])\n",
      "tensor([35,  3, 26, 45, 37, 10, 42, 37, 19, 37, 16, 22, 42, 32,  4,  0])\n",
      "tensor([38, 13, 26, 28, 27, 17, 10,  2, 19,  5,  7, 27, 18, 38, 48,  8])\n",
      "tensor([ 8, 11, 14, 48, 24, 35,  0,  5,  6, 41, 28, 43, 11, 14, 44, 36])\n",
      "tensor([16, 14,  6,  0, 47, 12, 44,  6,  7, 14,  7, 46, 44, 34, 47, 33])\n",
      "tensor([25, 24, 47, 45,  8,  7, 35, 45, 11,  6,  5, 18, 14,  1,  9, 24])\n",
      "tensor([10, 12, 39, 44, 20, 35, 38, 16,  2,  6, 41, 49, 35, 42, 35, 32])\n",
      "tensor([ 6, 16, 18, 15, 34, 45, 32, 29, 11, 32, 16, 31, 21, 24,  0, 13])\n",
      "tensor([48, 21, 32, 16,  3, 24, 45,  3,  5,  9, 37,  7, 39, 36, 42, 33])\n",
      "tensor([32, 18, 13, 34,  6,  6, 15, 29, 45, 45,  1, 37, 33, 45,  1, 19])\n",
      "tensor([21,  5, 28, 40,  7, 40, 29, 33, 39, 44, 37, 41, 32, 21, 37, 45])\n",
      "tensor([ 2,  2, 37,  7, 38, 26,  2,  0, 23, 11, 11, 22,  3, 27,  2, 49])\n",
      "tensor([25,  3, 14, 15, 12, 33, 19, 27, 49, 28,  0, 35, 28, 42, 49,  6])\n",
      "tensor([10, 39, 48,  0,  8, 41,  9, 30,  5, 48,  0, 49, 35,  3, 45, 38])\n",
      "tensor([11, 28, 10, 45, 13, 19,  2, 10,  7, 42, 17, 38,  4,  3, 39, 11])\n",
      "tensor([49, 22, 20, 41, 20, 34,  4,  2, 12, 20,  8, 34, 24, 31, 41, 14])\n",
      "tensor([12,  8, 38, 21, 35, 16,  9,  7, 12, 40, 27, 49, 12, 27, 29, 36])\n",
      "tensor([35, 10,  8, 42, 36, 18, 24, 36,  9, 24, 32, 40,  6, 23, 38,  5])\n",
      "tensor([34,  3,  2, 14, 36, 23, 38, 48, 32, 29, 39, 16, 36, 33, 27, 19])\n",
      "tensor([13, 19, 38, 15, 36, 32, 23,  4,  6,  2, 36, 39, 10, 23,  7, 42])\n",
      "tensor([33, 46,  4, 33, 10, 14, 12, 27,  1, 32, 15,  7, 42, 39, 29, 36])\n",
      "tensor([45, 49, 21, 32,  9, 42, 38, 27, 42, 38,  3, 18, 39, 32, 17, 11])\n",
      "tensor([48,  7, 11,  8, 46, 29, 43, 10, 11,  3, 12,  8,  7, 33, 19, 12])\n",
      "tensor([13, 14, 10, 37, 49,  3, 10, 33, 34, 18,  3, 27, 17, 34, 40,  1])\n",
      "tensor([48, 17, 45, 49, 26, 27,  2, 16,  6, 10, 23, 13, 11, 33, 20, 24])\n",
      "tensor([34, 46, 35, 33, 30, 15, 46,  2, 22, 12, 37, 21, 45, 35, 46, 40])\n",
      "tensor([44, 13, 29, 24, 27, 44, 35, 18, 24,  4, 28, 21, 42, 22, 32, 49])\n",
      "tensor([32,  7, 27, 10, 46, 24,  4, 41,  1, 17,  6, 18, 45, 23, 27, 23])\n",
      "tensor([23, 31, 41,  5, 28,  5, 37,  6, 36, 31,  1,  7, 26, 38, 11,  5])\n",
      "tensor([41, 18, 14, 12, 32, 41, 10,  4,  5, 19, 17, 38, 38, 38, 42, 14])\n",
      "tensor([45,  5, 37,  5,  5, 19,  9, 42,  1, 21, 17, 26,  5, 32, 35, 22])\n",
      "tensor([25, 40,  9, 15, 19, 13, 14, 37, 30, 35, 28, 27,  3,  3, 21, 23])\n",
      "tensor([45, 41, 35, 10, 29, 16, 45,  3, 36, 14,  6, 21, 44, 38, 22, 41])\n",
      "tensor([12, 32, 30, 26, 38, 22, 10, 28, 16, 15,  9, 48,  5, 32, 46, 30])\n",
      "tensor([20, 39,  6, 11, 17, 16,  5,  5, 28,  8, 37, 22,  2, 30,  7, 24])\n",
      "tensor([23,  4, 24, 34, 12, 21,  0, 19, 29, 22, 49,  6,  7, 22,  2, 40])\n",
      "tensor([28, 30,  2, 11, 10, 28, 49, 45,  0,  1, 34, 36, 38, 16, 21, 11])\n",
      "tensor([20, 34, 14, 15, 40,  2, 26, 35, 29, 36, 36, 33,  8, 11,  0, 28])\n",
      "tensor([23, 47, 11, 25, 38,  1, 36, 37, 10, 35, 30, 31,  6, 29, 44, 30])\n",
      "tensor([26, 34, 37, 36,  1,  7,  8, 10, 41, 43, 35, 38, 49, 22,  6, 42])\n",
      "tensor([ 9, 31, 35, 25, 10, 40, 10, 16, 12, 29, 19, 15, 26,  7,  2, 31])\n",
      "tensor([32, 40, 34,  7, 22, 27, 35,  4,  5,  8,  1, 34, 31, 11, 36, 32])\n",
      "tensor([15, 22, 25, 38, 24, 13,  5, 35, 27, 25, 13, 13, 33,  3, 14, 23])\n",
      "tensor([47, 29, 22, 11,  8,  5, 48, 37, 48, 34, 33, 19, 34, 49, 49, 17])\n",
      "tensor([25, 37, 23, 46, 15,  5,  6, 25, 31, 48, 22, 13, 24, 17, 37, 12])\n",
      "tensor([16, 20, 20, 17, 38, 30, 40, 42,  6,  4,  4, 19, 12, 43, 43, 40])\n",
      "tensor([20, 48, 30, 22, 41,  7, 40,  0,  9,  4, 43,  1, 18, 33, 45, 11])\n",
      "tensor([ 2, 37, 40, 10,  6, 11,  3,  9, 20, 31, 24, 42, 23, 32, 41,  9])\n",
      "tensor([29,  0, 32,  0, 37, 30, 29,  8, 39, 35, 15, 44, 19, 41, 20, 21])\n",
      "tensor([15, 40, 32, 42, 39, 27, 47, 30, 23, 31, 30,  2,  4, 26, 43, 36])\n",
      "tensor([ 0, 14, 31, 10,  8, 39, 49, 49, 34, 43, 16,  8, 24, 30, 40, 20])\n",
      "tensor([ 6, 30, 11, 18,  3, 35, 33, 11, 36, 21, 12, 45,  4, 16,  1, 19])\n",
      "tensor([ 2,  3, 17, 39, 26, 44, 24, 34, 41, 34, 37, 15, 27, 37, 31, 25])\n",
      "tensor([39,  6, 32, 19,  0, 38,  2, 23, 14, 37, 36, 17, 26, 14, 27, 19])\n",
      "tensor([12, 49, 19, 29, 45, 46, 27,  9, 40, 34, 27,  4, 32, 45, 21,  5])\n",
      "tensor([43, 39, 27, 16, 23,  6, 36, 41, 26, 37, 40, 21, 44, 38,  4, 10])\n",
      "tensor([41, 25, 27, 44, 36, 19, 34, 32, 18, 39, 23,  4, 27,  7, 12, 19])\n",
      "tensor([17, 31, 16, 38, 29,  0, 43, 39, 13, 10,  2, 35,  3, 40, 47, 42])\n",
      "tensor([36, 27, 36, 42,  1, 47, 42, 44, 28, 18, 42, 29, 11,  6, 14, 27])\n",
      "tensor([39, 40,  9, 10, 45, 39, 36, 43,  5,  2, 16, 26, 21, 39, 28, 46])\n",
      "tensor([18,  3, 11, 11,  3, 33, 29,  1,  2, 36,  9, 32, 28, 25, 25, 35])\n",
      "tensor([49, 15,  3, 18, 24, 18, 36, 38, 10, 48, 39, 10, 28,  0, 22, 15])\n",
      "tensor([24, 30, 36, 36, 42, 26,  6, 23,  9,  5, 20, 30, 17, 42, 20, 39])\n",
      "tensor([49, 16,  3, 23, 18, 29, 45, 10, 29, 16, 12, 22, 24, 43, 34,  1])\n",
      "tensor([ 0, 30, 33, 35,  8, 49, 13, 39, 38, 47,  6, 49, 39, 49, 17,  5])\n",
      "tensor([13, 12, 27, 33, 46,  3, 36, 41, 34,  1,  3, 43, 36,  5,  0, 33])\n",
      "tensor([46, 24, 34, 30, 41, 38,  5,  6, 13, 39, 36, 14,  3,  3, 21, 11])\n",
      "tensor([25, 21, 48, 20, 16,  9,  8, 29, 32, 21,  6, 16, 41,  4, 18,  9])\n",
      "tensor([ 3, 16, 10, 46, 26,  8,  3, 18,  4, 49, 49, 10, 17, 10, 30, 29])\n",
      "tensor([31,  8, 23, 13, 41,  9, 19,  7, 16, 26,  2, 39, 31, 23,  5,  4])\n",
      "tensor([11, 45, 36,  8, 33, 28, 30, 41,  6, 47, 14, 35, 36, 38,  2, 46])\n",
      "tensor([31,  6,  9, 12, 40, 26, 10, 46,  8, 14, 42, 21, 35, 16, 43, 18])\n",
      "tensor([ 6, 38, 19, 36,  0, 26, 46, 20,  7, 34, 14, 16, 35, 17, 46, 20])\n",
      "tensor([12, 31, 37, 43, 24, 10,  2, 30, 27, 38, 23, 14, 23, 28, 17, 26])\n",
      "tensor([21, 14, 21, 42, 31, 17, 47,  5, 11, 49, 25, 37, 34, 31,  0, 26])\n",
      "tensor([ 1, 23, 46, 26, 45, 46, 43, 38, 24, 45, 31, 17, 26,  8, 16, 26])\n",
      "tensor([38,  1, 44, 34, 10, 45, 16,  7,  6,  5, 30, 12,  2, 34, 22, 17])\n",
      "tensor([ 6,  7, 39, 43, 17, 13, 26, 32, 29, 35, 28, 49,  7, 40, 34, 21])\n",
      "tensor([31, 10, 11, 16, 15, 25, 33,  3, 44,  7,  7,  5, 46, 43, 26, 15])\n",
      "tensor([37, 19, 40, 35, 22, 16, 32, 39, 45, 39, 36, 12, 34, 11, 28,  3])\n",
      "tensor([20, 46,  6, 35, 18, 25, 26, 39, 19, 35, 43,  4, 31,  3, 23, 44])\n",
      "tensor([42, 41, 39, 44, 20, 45, 48, 11, 16, 45, 24, 44, 45, 14, 20, 28])\n",
      "tensor([ 1, 39,  2, 31, 27, 41, 42, 13,  2, 37, 36,  2, 38, 44, 40, 27])\n",
      "tensor([ 2,  4, 20, 41, 34, 46,  8, 19, 43, 17, 40, 37, 48, 30, 44, 39])\n",
      "tensor([34, 43, 47, 45, 44,  4,  3, 24,  0, 46,  9, 26,  6, 22, 13, 21])\n",
      "tensor([41, 23,  0, 17, 41,  0, 49,  3, 27,  0, 34,  1,  9, 42, 46, 13])\n",
      "tensor([19,  5, 32, 47, 19, 15,  5,  7,  1, 24,  1, 13,  2, 17, 36,  3])\n",
      "tensor([47, 48, 49, 33, 15, 15, 15, 15,  8,  9, 15, 30, 49, 30, 38, 16])\n",
      "tensor([ 0, 44, 42, 11, 13, 23, 45, 39, 18, 14,  1, 28, 10, 42, 44, 45])\n",
      "tensor([15,  8, 14,  9, 23, 35, 36, 11,  8,  1, 33, 38, 32, 34, 26, 33])\n",
      "tensor([ 7, 15, 16, 27, 35, 41,  3, 42,  2, 15, 12, 15, 33, 20, 12, 12])\n",
      "tensor([29, 38, 13,  7, 37, 30,  2,  1,  3, 45, 48, 16, 19,  2, 49, 43])\n",
      "tensor([14,  1, 20, 12, 27, 46, 23, 10, 32, 13, 34, 18, 45,  0, 23, 21])\n",
      "tensor([22, 19, 39, 32, 32, 30, 46, 44, 30, 39, 20,  3, 34,  2, 49, 34])\n",
      "tensor([ 1, 24, 22, 14,  8, 14, 10, 23, 22,  0, 25,  9, 27,  2, 46, 44])\n",
      "tensor([32, 16, 12,  2, 38, 39,  8, 28, 45,  3, 29, 48, 19, 11, 44,  3])\n",
      "tensor([25,  3, 10, 18, 17, 33, 43, 35, 48,  0, 44, 42,  6, 46, 11, 38])\n",
      "tensor([18, 38, 37, 39,  8,  8, 30,  3,  6, 31, 31, 45, 33,  0,  6,  6])\n",
      "tensor([17, 38, 35, 24, 39, 41, 18,  1, 38, 29, 23, 45,  0, 43, 34, 42])\n",
      "tensor([28,  3, 45,  3,  1, 32, 25, 38, 27, 32, 44, 38, 40, 44, 29, 27])\n",
      "tensor([ 4,  2,  2,  1, 22, 27, 27, 31, 37, 43, 33, 16,  4, 49,  6,  8])\n",
      "tensor([39,  8, 12, 20, 40, 27, 26, 49, 36, 33, 19,  8, 12, 26, 30, 35])\n",
      "tensor([19, 10, 25,  1, 21, 24, 35,  6, 18, 43, 41,  0, 22, 33,  5, 21])\n",
      "tensor([36, 13, 16, 10,  5, 20,  6, 36,  7, 11, 16, 37, 18, 44, 34, 19])\n",
      "tensor([15, 13,  9, 22, 39, 21, 32, 14, 44, 47, 40, 10, 47, 16, 16, 39])\n",
      "tensor([46, 22,  4, 47, 36, 37, 29, 26, 42,  4, 32, 29, 16, 46, 47, 16])\n",
      "tensor([ 0, 20, 33, 36, 34,  9, 10, 27, 37, 15, 35, 15, 38,  0, 35, 46])\n",
      "tensor([ 8,  3, 31, 15, 17, 42, 10, 13,  2, 25, 10,  0, 35, 17, 48, 11])\n",
      "tensor([25, 42, 18, 10, 36, 46, 41, 31, 11,  5, 38, 30, 25, 29, 33, 24])\n",
      "tensor([ 8,  4,  1, 23,  3, 16,  9, 29, 14, 27, 37, 36, 19, 39, 28, 48])\n",
      "tensor([31, 22, 48, 41, 22,  4, 43,  4, 13,  2, 18, 36, 39, 33, 48,  4])\n",
      "tensor([43, 22, 43, 39,  5, 13, 27, 16, 37, 31,  5,  7, 21, 16, 48, 27])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([15, 23, 14, 48, 48, 33,  3, 28, 26, 35, 44, 43,  4, 12, 34, 29])\n",
      "tensor([47, 23,  0,  7, 47, 11,  0, 36, 12, 10, 44, 26, 24, 32, 45, 10])\n",
      "tensor([37, 27, 21,  9, 29, 33, 40, 42,  2, 26,  1, 48, 28, 46, 38, 18])\n",
      "tensor([38,  0, 46, 23, 38, 40, 46,  3, 14, 39,  6, 32,  0,  0, 48, 46])\n",
      "tensor([11, 33, 24, 14, 24, 44, 33,  5, 42, 48, 36, 28, 20, 41, 20,  3])\n",
      "tensor([37, 21, 18, 15, 31,  1, 22, 15, 32, 36,  9, 11, 11, 27, 21, 26])\n",
      "tensor([44, 32, 38, 24,  7,  7, 41, 43, 41, 46, 30, 44, 25, 31, 30, 32])\n",
      "tensor([48, 49, 13, 22, 42, 19, 43, 46,  9,  1, 33, 12, 29,  6, 28, 23])\n",
      "tensor([13, 48, 22, 44, 37,  5, 10, 48, 20, 13, 24, 38, 45, 13, 17, 22])\n",
      "tensor([38, 23, 13, 10,  2, 39, 18,  5, 24, 23,  0, 20, 44,  4,  8, 38])\n",
      "tensor([27, 14, 42, 33,  8,  4, 39, 12, 46, 27, 24, 19, 28,  7, 12, 49])\n",
      "tensor([45, 34,  5, 18, 25, 11, 41, 46, 49, 39, 23, 10, 49, 31, 17, 30])\n",
      "tensor([46,  0,  1, 32, 26, 48, 11, 23, 22, 32, 20, 21, 16, 13, 36, 49])\n",
      "tensor([46, 49,  6, 35, 14, 36, 23, 20, 33, 28, 10, 32, 41, 35, 45, 37])\n",
      "tensor([34, 48, 45, 37, 36, 17, 41, 40, 24, 31, 18,  3,  9, 10, 45, 47])\n",
      "tensor([38, 45, 27, 10, 40, 22, 25, 12, 12, 43, 16, 30,  4, 49, 45, 33])\n",
      "tensor([44, 13, 34, 42, 41, 23, 10, 48, 33, 45, 13, 41, 19, 13,  8, 12])\n",
      "tensor([37, 33, 14, 46, 21, 25, 25, 46,  5,  2, 49, 34, 43, 24, 48, 15])\n",
      "tensor([35, 47, 28, 24, 18, 46, 25, 44,  6, 17,  3, 36,  1, 37, 16, 22])\n",
      "tensor([29,  9, 32,  0, 13, 15, 28, 28, 22, 24,  2,  4, 16,  4, 33, 16])\n",
      "tensor([ 1, 27,  4, 33, 30, 14, 33, 26, 33, 29,  9, 48, 30,  1,  7, 12])\n",
      "tensor([20, 41, 17, 17, 19, 16, 25,  8, 38, 18, 32, 25, 36, 24, 46, 40])\n",
      "tensor([25, 49, 23, 14, 36, 20, 45, 24, 16, 13, 28, 25, 39,  5, 39, 11])\n",
      "tensor([38, 31, 42, 10,  2, 23, 27, 45, 28, 49, 16, 38, 32, 20, 40, 26])\n",
      "tensor([32, 17, 25, 24, 31, 49,  1,  9,  1, 43, 34, 45, 38, 45, 14,  5])\n",
      "tensor([48,  3, 25, 39, 47, 18, 33, 20, 46, 41, 30, 18,  0, 38, 10, 18])\n",
      "tensor([18,  3,  1, 27,  4, 45, 15, 26,  0, 23, 31, 22, 10, 26, 48,  3])\n",
      "tensor([34,  0, 12, 15,  1, 10,  7, 11, 19,  1, 37, 28, 48, 11, 27, 14])\n",
      "tensor([28, 47, 43, 45, 29, 11, 14, 20, 32,  2, 28, 49, 38, 37, 45, 11])\n",
      "tensor([35, 27, 28, 27, 41,  2,  6, 14, 29, 36, 15, 10, 22, 44, 14, 40])\n",
      "tensor([47, 38,  9,  4, 39, 24, 33, 38, 29,  6, 49,  9,  5, 21, 22, 20])\n",
      "tensor([14, 45, 39, 29, 11,  2, 41, 41, 33, 17, 41, 11, 38, 10, 27, 40])\n",
      "tensor([25,  1, 11, 36,  4, 21, 11, 12, 46,  5,  1, 25, 39, 34, 35, 10])\n",
      "tensor([22, 36, 41, 41,  9, 14, 12, 10, 14, 11, 28, 36, 38, 15, 11, 31])\n",
      "tensor([42, 11, 17, 46, 43,  5, 47, 29,  5,  7,  7, 18, 26, 24, 24, 25])\n",
      "tensor([44, 34,  9, 28, 10, 22, 30, 26, 34, 33,  5, 31, 13,  1, 28, 29])\n",
      "tensor([36, 14,  6,  0, 42,  2, 37, 14, 24, 36, 26, 15, 11, 40,  5, 49])\n",
      "tensor([49, 12, 44, 16, 49,  4,  5, 38, 20, 33, 49, 18,  9, 24, 36, 44])\n",
      "tensor([21, 23, 32, 26, 27, 36, 35,  6, 22, 25, 26, 48, 12, 12,  0, 30])\n",
      "tensor([30,  0, 18, 24, 48, 35, 34, 35, 32, 30, 11, 14, 21,  4, 46, 42])\n",
      "tensor([26,  5, 49, 19, 26, 29, 36, 41, 15, 14, 39, 47, 21,  3, 10, 14])\n",
      "tensor([45, 42, 46, 13, 35,  9,  0, 34, 32, 24,  3, 39, 42, 48, 34,  7])\n",
      "tensor([ 2, 25, 15, 17, 46, 31, 45,  6, 26,  5, 42, 41,  8, 49, 49, 31])\n",
      "tensor([33, 27,  3, 13, 47, 36, 19, 33, 14, 26, 36, 21, 12, 44, 20, 43])\n",
      "tensor([27, 40, 26, 21, 39, 26, 27, 40, 16, 17,  6, 47,  6, 28, 14, 35])\n",
      "tensor([23,  7, 19, 38, 31, 39,  8, 28,  2, 43, 28, 28, 21, 24,  1,  2])\n",
      "tensor([42, 30, 11, 11, 42,  5, 41, 33, 11, 19, 35, 35, 35,  6,  2, 44])\n",
      "tensor([13, 36, 36, 13,  4,  1,  3, 13, 49, 29, 27,  5, 24, 34, 32, 16])\n",
      "tensor([ 0,  8,  0, 40, 38, 16, 13,  3, 27, 22, 12, 42, 49, 15, 28, 32])\n",
      "tensor([31, 25,  2, 10, 32, 47,  2, 35, 33,  0, 13, 20, 21, 38, 37, 36])\n",
      "tensor([37, 33, 33,  4, 34, 15, 12,  3, 20, 21,  1,  5, 33, 26, 36, 27])\n",
      "tensor([20, 16, 25, 36, 13, 26, 34, 24, 10, 36,  9, 33, 10, 17, 26, 43])\n",
      "tensor([45, 29, 48, 16, 22, 45, 48,  7, 19, 29, 32, 34, 22, 18, 43, 20])\n",
      "tensor([15, 23, 34,  9, 43, 37, 39, 16,  9, 26, 11,  4, 44,  2,  1, 41])\n",
      "tensor([45, 21, 31, 27, 44, 40,  2, 47, 21, 47, 37, 42, 20, 23,  0, 15])\n",
      "tensor([ 8, 34, 32, 27,  3,  0, 32, 18, 43, 36, 18, 26,  5,  8, 32,  6])\n",
      "tensor([ 0,  7, 19, 12, 20, 41, 30, 22, 44, 44, 16, 40, 38, 47,  9,  6])\n",
      "tensor([47, 19, 11, 42,  2,  5, 48, 14, 47, 11, 31,  7,  9, 35, 23, 43])\n",
      "tensor([ 0,  5, 45, 45,  5, 34, 48, 31, 26, 16, 35, 23, 13,  3, 42, 11])\n",
      "tensor([ 8, 21, 40, 16, 48, 15, 37, 39, 31, 12, 34, 29, 26,  9, 43, 22])\n",
      "tensor([12, 19, 32, 20, 19, 11,  3, 24, 44,  8,  2, 42, 29, 21,  4, 20])\n",
      "tensor([31, 47, 38, 31, 27,  4, 18, 43, 28, 34, 49, 18, 14, 40, 35, 22])\n",
      "tensor([45, 32, 20, 41,  3, 17, 22, 17, 32, 40, 32, 47, 31, 33,  5, 39])\n",
      "tensor([49, 25,  2, 14, 40, 31, 18, 25, 36, 41, 47, 32, 32, 45, 46, 21])\n",
      "tensor([48, 38,  2, 38,  2, 27, 47, 19, 10, 28, 44, 44, 39, 43, 33, 23])\n",
      "tensor([45,  4, 24,  0, 44, 30, 38, 14, 34, 22, 49, 46, 25, 11, 36, 34])\n",
      "tensor([18,  5,  4, 19, 49, 19,  7,  5, 35, 20,  9, 40, 30,  2, 41, 16])\n",
      "tensor([ 8,  3, 23, 49, 44,  1, 34, 45, 28, 46, 16,  3, 44, 14,  5,  5])\n",
      "tensor([35, 27, 37, 23, 10, 13, 44, 28, 48, 12, 16, 33, 43, 29,  3, 18])\n",
      "tensor([45, 46, 33, 42, 32, 21, 35, 15, 48, 41,  2, 18, 15, 16, 45, 21])\n",
      "tensor([ 9, 33, 22, 10, 30,  7, 22, 49, 43, 33,  9, 30, 45, 21, 43,  2])\n",
      "tensor([12, 38, 18, 36, 27, 40, 38, 27, 26, 30, 48,  2, 14, 48,  6, 23])\n",
      "tensor([13,  7, 19, 26, 34, 34, 12, 49, 15,  5, 31, 33, 21, 35,  0,  0])\n",
      "tensor([29, 38, 36, 21, 13, 17, 11, 30, 43, 45, 38,  1,  2, 38, 11, 34])\n",
      "tensor([15, 16, 34,  0, 19,  7, 19, 46, 11, 35, 36, 47,  5, 13, 15, 25])\n",
      "tensor([ 9, 45, 44, 20, 27,  6, 17,  8, 34,  4, 48,  4, 24, 48, 10, 10])\n",
      "tensor([ 4, 24,  8, 15, 11, 25, 47, 24, 12, 49, 45, 44, 33, 49, 21, 11])\n",
      "tensor([18, 35, 38,  8, 29, 39,  5, 16, 33, 15,  2, 10, 27, 28, 19, 26])\n",
      "tensor([ 0, 49, 27, 23, 10, 40,  5, 21,  3, 23, 47, 33, 37, 11, 15, 12])\n",
      "tensor([48, 19,  5, 23, 32, 47, 20, 33, 45, 35,  0,  5,  4,  0, 39, 45])\n",
      "tensor([49, 38, 13, 11, 19, 47, 40, 45, 27, 45,  4, 49, 10, 37, 23, 45])\n",
      "tensor([37, 21, 29, 33, 47, 27, 48,  6, 42, 20, 42, 12, 18, 16,  1, 41])\n",
      "tensor([25,  1,  3,  1,  9, 28, 41,  0, 29, 16, 21, 29, 47, 29, 27, 37])\n",
      "tensor([34, 16, 34, 48, 48, 15, 43, 28, 32,  5, 36,  1,  0,  8, 32, 22])\n",
      "tensor([27, 43, 27, 22, 21, 49, 15, 35, 33, 30, 23, 28, 25, 38, 41, 18])\n",
      "tensor([36, 27,  0, 36, 17, 24, 46, 24, 22, 18, 32, 19, 25, 38, 22, 30])\n",
      "tensor([38, 44,  9, 44,  6, 38, 33, 35, 36, 34,  9, 45, 16, 16,  5, 21])\n",
      "tensor([39, 35, 19, 35, 16, 47, 26,  4, 31, 17, 49, 13, 33, 43, 17, 48])\n",
      "tensor([39, 30, 43,  9, 43, 49,  0, 38, 13, 37,  6, 32, 32, 33,  8,  3])\n",
      "tensor([13, 34, 27, 12, 48, 47, 18,  1, 47, 26, 48, 28, 20, 49, 12, 42])\n",
      "tensor([ 4, 42, 35, 23, 23,  2, 36,  0, 39, 47, 19, 48, 16, 11, 15, 48])\n",
      "tensor([ 4, 32, 27, 44, 12, 21, 14, 26, 29, 37, 21,  1, 10, 33, 45, 10])\n",
      "tensor([40,  7, 24, 41, 31, 44, 45, 46, 13, 21, 49, 48, 34, 34, 41, 12])\n",
      "tensor([42, 11, 20, 21, 16, 22, 17, 10, 30, 22, 34, 24, 41, 49, 48,  7])\n",
      "tensor([47, 44, 21, 19, 20, 10, 30, 22, 35, 20, 40, 38,  7, 38, 38,  9])\n",
      "tensor([42, 48, 47, 26, 39, 27, 16, 32, 21,  7, 33, 22, 46, 10,  0, 13])\n",
      "tensor([48, 19,  6, 25, 16, 14, 32, 46,  9, 36, 43, 27, 49, 37,  2,  5])\n",
      "tensor([35, 20, 32,  0, 41,  5, 35,  6, 24, 36,  7, 31,  4, 14, 47, 23])\n",
      "tensor([30, 34, 47, 43, 13, 23, 41, 23, 41,  1, 30, 38,  3, 27, 24, 45])\n",
      "tensor([24,  6,  7, 20,  4,  6, 14, 13, 13, 13, 35, 13, 36, 43, 18,  7])\n",
      "tensor([20, 47,  9,  7,  9,  9, 31, 40, 24, 11, 23, 13, 32, 41,  9, 26])\n",
      "tensor([ 0, 12, 47, 13, 29, 31,  2, 22, 11, 26,  3,  4,  4, 45, 13, 38])\n",
      "tensor([ 2, 26, 35, 28, 10, 34,  8, 11, 21, 16, 14,  5, 43, 39,  2, 18])\n",
      "tensor([46, 47, 45, 44, 19, 30, 15,  6, 49, 15, 16, 15, 47, 29, 34, 34])\n",
      "tensor([49, 49, 14, 39, 48, 19, 16, 25, 18, 22, 29, 49, 14, 26, 40, 14])\n",
      "tensor([39, 13, 27, 17, 35,  8, 26, 33, 34, 28, 18,  1, 15, 38,  1, 15])\n",
      "tensor([47, 13, 38, 25, 38, 44, 43, 36, 21, 15, 12, 30, 37, 49, 40, 43])\n",
      "tensor([40,  0, 42, 34, 41,  3, 17, 46, 12, 20,  5,  0, 49, 23, 45, 29])\n",
      "tensor([40, 33, 46, 24, 41, 22, 33, 35, 47, 25,  5, 38,  8, 16, 49, 46])\n",
      "tensor([ 1, 36, 43,  1, 19, 35,  1, 17, 13, 12, 20, 19, 20, 15, 31,  6])\n",
      "tensor([23, 26, 37,  3, 15, 42, 49, 21, 22,  9, 28, 30, 45,  6, 42,  0])\n",
      "tensor([27,  2, 43,  8, 41, 22,  7, 36, 24, 49, 10, 11, 37, 25, 19,  4])\n",
      "tensor([23, 22, 11, 29, 22, 30, 49, 48, 45, 38, 14, 39, 17, 32, 27, 39])\n",
      "tensor([22, 42, 34, 13, 21, 26,  0, 25, 32,  2,  3, 11, 16, 46, 23, 35])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16, 22,  6, 42, 13, 35, 32, 16, 47, 10, 36, 28, 20, 46, 33, 32])\n",
      "tensor([40, 12, 24, 11, 41, 27, 41, 24, 39, 40, 11, 36, 21, 28, 11, 39])\n",
      "tensor([27, 31,  5,  1,  1, 35, 16, 40, 40,  2,  5, 11, 32, 49,  9, 48])\n",
      "tensor([44, 46,  0, 21,  8,  1,  8, 19, 22, 12, 15, 26, 25, 23, 47, 13])\n",
      "tensor([31, 20, 28,  5, 17, 16, 29, 45, 31,  7, 49, 16, 43, 45, 12, 22])\n",
      "tensor([28,  4, 24, 27, 46,  8, 28, 11, 39,  9, 16, 41, 18, 12, 12, 34])\n",
      "tensor([10,  7, 41, 28, 45, 29, 27, 24, 24, 21, 21, 30,  6, 36, 46, 41])\n",
      "tensor([42, 30, 30, 15,  7, 32, 18,  0, 27, 19,  8, 16, 16, 12, 32,  9])\n",
      "tensor([32, 10, 39, 30, 13, 36, 35, 37, 48, 23, 35, 15, 23, 32, 15, 18])\n",
      "tensor([ 3,  0, 43, 29, 16, 35,  0, 43, 38, 12, 46, 18, 16, 25, 20, 22])\n",
      "tensor([10, 45, 26,  2,  8, 11, 10, 35, 32, 29, 41, 47, 35, 42, 40, 19])\n",
      "tensor([ 1, 28,  7, 36, 22, 14, 10, 25, 19, 13, 44, 19,  6,  0, 10, 35])\n",
      "tensor([ 6,  3, 17, 31,  6, 44, 13, 44, 27, 25, 25, 31, 26, 32, 23, 23])\n",
      "tensor([10, 19, 30, 48, 15, 29, 20,  7, 32, 19, 36, 20, 31, 24, 46, 32])\n",
      "tensor([16, 41, 48, 27, 33, 35, 40, 32, 43, 10, 40, 13,  3, 29, 18, 26])\n",
      "tensor([ 0, 28, 20,  1, 10, 31, 17, 31, 33, 28, 20, 15, 43, 39, 26, 27])\n",
      "tensor([30, 38, 23, 36,  8, 15, 45, 32, 18, 40, 18, 44, 35, 32, 29, 38])\n",
      "tensor([47,  1, 41,  3,  5, 22, 15,  4, 37,  7, 48, 34, 31, 14, 18, 43])\n",
      "tensor([49, 12, 25, 37, 34, 40,  3, 27, 19, 35,  3, 48, 15, 16, 47, 36])\n",
      "tensor([15, 33,  0, 29, 33, 48,  4, 14, 44, 25,  1, 26, 41, 35,  4, 11])\n",
      "tensor([ 7,  5, 19,  5, 41,  3, 19, 49, 37,  3, 44, 30,  3, 19, 29, 38])\n",
      "tensor([20, 21,  7, 24, 26, 14, 45, 35, 21, 46, 34, 28, 41,  3, 23, 15])\n",
      "tensor([23, 12,  0,  8, 33, 34,  2, 28, 16, 37, 13,  1, 48, 14, 23, 39])\n",
      "tensor([22, 26, 20, 33,  7, 13, 42, 24,  2, 35, 49, 38,  8, 37, 46, 18])\n",
      "tensor([19, 15, 21, 11, 20, 10, 34,  3,  9, 26, 12, 47,  7, 23,  0, 14])\n",
      "tensor([12, 38, 13, 17, 30, 23, 21, 49,  9, 37, 15, 32,  0, 23, 15,  8])\n",
      "tensor([26, 24,  5,  7, 16, 40, 30, 29, 47, 44, 10, 44, 24, 29, 34, 31])\n",
      "tensor([30, 25, 44, 17, 43,  7, 36, 33, 21, 30, 46,  5, 16, 33, 27, 39])\n",
      "tensor([22, 49,  5, 12, 28, 20, 26,  8, 32, 34, 15, 34,  2, 10,  5, 30])\n",
      "tensor([32,  4, 28, 39, 41, 11,  1, 22, 13,  5, 39, 15, 25, 39,  5, 26])\n",
      "tensor([ 6, 43, 27,  1, 33, 16, 36, 18, 24, 21, 49, 24, 12, 20, 20, 36])\n",
      "tensor([ 5, 13, 48, 30, 15, 20, 11, 44, 25, 21, 15, 42, 12, 30, 17, 11])\n",
      "tensor([49, 15, 15, 42, 15,  9, 26, 29, 14, 36, 11, 39, 29, 12, 17, 19])\n",
      "tensor([28, 43, 25, 14, 41,  7,  5, 25, 34, 21, 26,  6, 14, 46, 27,  8])\n",
      "tensor([17, 14, 20, 39, 48, 34, 35, 17, 35,  0, 28, 38,  4,  0, 22, 36])\n",
      "tensor([29, 33, 48, 11,  7, 42, 34, 18, 36, 14, 42, 10, 20, 26, 32, 39])\n",
      "tensor([22, 48, 47, 39, 17, 11, 27, 10, 45, 32, 27,  0,  2, 25, 49,  6])\n",
      "tensor([13, 49, 40, 33, 32,  3, 23, 43, 26, 34, 33, 49, 24,  6, 30, 32])\n",
      "tensor([16, 11, 47, 44, 27,  4, 43, 40, 31,  1, 44, 24, 18, 27, 32, 24])\n",
      "tensor([ 2, 14, 43, 47,  1, 48,  1, 11, 33,  2, 20, 11, 12,  4, 35, 18])\n",
      "tensor([25, 27,  8, 49, 26,  7, 41,  4, 17,  8, 34, 17, 22, 48,  7, 43])\n",
      "tensor([27, 47, 26, 16, 11, 27, 18, 23,  1, 47, 38,  0, 38, 35, 35,  4])\n",
      "tensor([15, 49, 49, 18, 36, 23,  7,  8, 33, 25, 43, 48, 32, 28, 41,  1])\n",
      "tensor([28, 11, 23,  5, 34,  6, 49, 33,  3, 37, 28,  6, 14, 14, 49, 13])\n",
      "tensor([ 2, 29,  0,  5, 39, 25, 20, 26, 10, 45, 16, 14,  9, 16,  0, 46])\n",
      "tensor([29, 38, 34,  5, 22, 23, 15, 17, 22, 46, 12,  6, 27, 35, 40, 18])\n",
      "tensor([37, 13, 39, 11, 47, 38,  3, 27, 43,  9, 40, 31, 11, 19, 18,  7])\n",
      "tensor([25,  1, 23, 27, 25, 44, 35, 15,  5, 16, 25, 19, 35, 11, 41,  8])\n",
      "tensor([ 5,  5, 26, 29, 11, 12, 11,  2, 44, 24,  9, 15, 19, 10, 43, 19])\n",
      "tensor([ 7, 14, 16, 15, 34, 45, 21, 39, 46, 46, 23, 28, 21, 29, 15, 25])\n",
      "tensor([ 5, 21,  0, 41, 11, 14, 23, 23, 14, 13, 38, 49, 29, 24, 48, 49])\n",
      "tensor([12, 47,  0, 23, 35, 15, 22, 45, 12, 21, 33, 11, 18, 10,  5, 21])\n",
      "tensor([45, 34, 26, 12,  9, 24, 33, 26, 39, 48, 32, 11, 11, 29,  8, 11])\n",
      "tensor([ 2, 35, 20, 46, 42, 49, 20, 23, 13, 32,  2, 24, 18, 39, 38,  3])\n",
      "tensor([39, 39,  7,  7, 16, 34, 15,  8, 28, 31, 32, 16, 26, 40, 11, 48])\n",
      "tensor([ 5,  4, 13, 46, 24, 44, 23, 20,  6, 15, 33, 43, 42,  1, 33, 41])\n",
      "tensor([35,  6,  4, 21, 38, 26,  7, 16, 23, 33, 17, 28, 17, 25,  0,  0])\n",
      "tensor([17, 26,  0, 30, 18, 27, 21, 14, 32, 24, 23, 41,  6, 42, 36, 32])\n",
      "tensor([38,  5, 45,  0, 39, 31, 21, 23, 45, 12, 46, 44, 21, 20, 24, 11])\n",
      "tensor([46, 39,  3, 32, 23, 34, 13,  1, 23, 13, 45, 32, 35, 38, 41,  3])\n",
      "tensor([21, 48,  9, 35, 42, 40, 16, 33,  0, 19,  0, 30, 17, 21, 17, 25])\n",
      "tensor([36, 31,  5, 14, 12, 46, 13, 17, 25, 46, 11, 24, 42, 34, 32, 10])\n",
      "tensor([ 9, 48, 28, 34, 31,  9, 25,  0, 33, 44, 46, 46, 31, 10, 42,  9])\n",
      "tensor([46, 48, 39, 16, 36, 25, 38, 35, 29,  6, 16,  7, 37, 11,  3, 16])\n",
      "tensor([13, 35,  6, 31,  8, 31, 49,  2, 41,  2,  2, 34,  7, 35, 26, 23])\n",
      "tensor([49, 34, 32, 27,  2, 38, 39, 38,  7,  7,  2, 41, 12,  6,  7, 40])\n",
      "tensor([26, 25, 27, 36, 40, 16,  0, 49, 37, 47, 22, 23,  2, 24,  2,  5])\n",
      "tensor([ 5, 34, 17,  3, 13, 18,  8, 11, 16,  6, 38, 34, 41, 40, 38, 30])\n",
      "tensor([24, 26, 49, 22, 22, 49, 10, 12, 11, 44,  5,  4,  3,  0, 26, 20])\n",
      "tensor([26, 33, 22, 43, 32, 36, 18, 16, 26, 18, 10,  5, 17, 29, 19, 28])\n",
      "tensor([27, 19,  2, 10, 14, 10,  4, 49, 45, 22,  5, 40, 40, 18, 36, 34])\n",
      "tensor([14, 27,  2,  6, 20, 11, 21, 49, 10, 34,  8, 26, 21, 34, 40,  7])\n",
      "tensor([27, 21, 20, 17, 14, 47, 24, 14, 37, 31,  2, 32,  2, 17, 49, 29])\n",
      "tensor([17, 29, 41,  7, 39, 48, 24, 22,  2, 10,  9, 45, 28, 31, 34, 21])\n",
      "tensor([20, 32, 15])\n"
     ]
    }
   ],
   "source": [
    "feat,lbls = extract_features(model,train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([39, 43, 41, 36, 12, 37, 46, 46, 32, 12, 40, 46,  5, 14, 33, 31])\n",
      "tensor([37, 49, 10, 19, 25, 49, 22, 49, 21,  1, 26, 16, 24, 49,  1, 10])\n",
      "tensor([ 7, 26,  6, 42,  3, 49, 23, 23,  1, 14, 28,  7, 49,  8, 39, 29])\n",
      "tensor([27, 37, 12, 40, 30, 49, 21, 32, 21, 17,  2, 48, 43, 49, 47, 23])\n",
      "tensor([38, 47, 22,  4,  3, 17, 35,  0,  2, 21, 43, 30, 41, 12,  5, 10])\n",
      "tensor([21, 23, 27, 37, 39,  6, 49,  1,  5,  3,  6,  6, 34, 44, 42, 38])\n",
      "tensor([11, 30, 13, 26, 44, 20, 22, 32, 42, 33, 47, 23, 42,  7, 10, 32])\n",
      "tensor([21,  1,  0,  1, 21, 21, 40, 19, 18, 29, 25, 43, 25, 17, 13, 45])\n",
      "tensor([29, 34, 36, 48, 42, 40, 32, 10,  8, 29, 23, 15, 44, 33, 35, 22])\n",
      "tensor([47, 48,  0,  1, 38, 30, 25, 48,  7, 20, 46, 31,  8, 21, 43, 43])\n",
      "tensor([36,  2, 35, 36, 30,  5, 19, 17,  0, 24, 30, 28,  7, 26, 33, 34])\n",
      "tensor([15, 24, 17,  0, 29, 43, 46, 34, 47, 14, 21, 23, 27,  8,  2, 47])\n",
      "tensor([10, 44, 22, 12, 39, 36,  1, 41, 19, 32, 24, 31, 24,  8, 45,  3])\n",
      "tensor([45, 15, 38, 19, 30, 28, 12, 41, 32, 49,  6, 44, 44,  5, 11, 16])\n",
      "tensor([12, 16, 45,  6, 16, 26, 35, 16,  0, 28, 37, 26, 25,  6, 16, 15])\n",
      "tensor([29,  6, 14, 35, 33, 22, 34, 34, 33,  5, 48, 38, 10, 14, 36, 45])\n",
      "tensor([ 2,  3, 42, 40, 21, 20,  0, 48, 20, 20, 11, 25, 35,  1, 33, 14])\n",
      "tensor([26, 46,  6,  5,  1, 33, 29, 49, 10,  6, 27, 11, 14, 10, 11, 37])\n",
      "tensor([43, 39, 41, 15, 12, 17, 47, 31, 28, 21,  6, 11, 16, 28, 40, 48])\n",
      "tensor([13, 48, 44, 42, 38, 45,  5, 39, 20,  0, 37, 42, 14, 11, 28, 43])\n",
      "tensor([43, 44, 29, 47, 25, 19,  4, 27, 40, 15,  6, 14, 11, 17, 17, 31])\n",
      "tensor([47,  8, 30, 39, 29, 30, 21, 32, 36, 12,  8, 25, 17, 15, 48, 19])\n",
      "tensor([10, 22, 28, 22, 48, 24, 31, 20, 48, 16,  2, 21, 19,  6, 43, 24])\n",
      "tensor([30, 46,  4, 11,  5,  0, 36, 36, 14, 45, 18, 47, 12, 27,  6,  9])\n",
      "tensor([27, 49,  2, 16, 46, 48, 45, 42,  1, 22,  9, 37, 41, 22, 30, 39])\n",
      "tensor([13,  1, 12,  3, 37, 29,  6, 15, 32, 26, 27, 46, 19,  3, 33, 15])\n",
      "tensor([21, 17, 11, 22, 32, 38,  4, 22,  5, 38,  0, 26, 14, 12, 35,  4])\n",
      "tensor([49, 34, 28, 32, 24, 21, 36, 39, 42, 11, 17, 33, 17,  5, 40, 17])\n",
      "tensor([45, 27, 35, 30, 46, 37, 30, 27, 34, 29, 24, 20, 20, 23, 18,  4])\n",
      "tensor([10,  7,  9, 16, 49,  4, 36,  4, 24, 25, 48, 16, 21, 15, 40, 26])\n",
      "tensor([44, 12, 34, 20, 29, 15, 18, 27,  4, 12,  9, 44,  0, 42, 24,  5])\n",
      "tensor([41, 45, 39,  4, 35, 33, 38, 38, 13,  5,  6, 34, 10,  2, 39, 46])\n",
      "tensor([41, 32,  2, 26, 47, 16, 40, 37, 19, 32,  8, 22, 44, 37, 32, 41])\n",
      "tensor([27, 24,  5, 14,  4, 24, 48, 19, 46, 28, 39,  8, 48, 39,  9, 43])\n",
      "tensor([49, 47, 36, 19, 13, 42, 13,  7,  0, 38, 48, 39, 28, 27, 36, 26])\n",
      "tensor([45, 30, 49,  7, 25, 23, 21,  4, 32, 39,  3, 12, 36, 43, 29,  5])\n",
      "tensor([11, 23, 14,  5, 16,  7,  2, 14,  3, 18, 10, 10, 26, 14, 10,  2])\n",
      "tensor([49,  5, 45, 36, 33, 23, 40, 17, 15, 41, 11,  4, 42, 11, 32, 24])\n",
      "tensor([ 1, 15, 16, 46, 29, 24, 38, 49, 35,  1,  3, 20, 26,  3, 27, 10])\n",
      "tensor([31, 16, 33,  9, 17, 31, 16, 31, 39, 20,  0, 24, 42,  4, 40, 42])\n",
      "tensor([ 6, 44, 15, 44, 16, 47,  6, 36, 28, 23,  7,  7, 33, 27, 38, 22])\n",
      "tensor([ 5, 47, 44, 25,  0, 25, 29, 38, 38,  8, 15,  1,  3, 48, 31, 36])\n",
      "tensor([24, 26, 11, 34, 26, 42, 23, 47, 45, 20, 14, 13, 41, 29,  7, 15])\n",
      "tensor([23, 49, 37,  3, 33, 30, 34, 44, 34, 20, 18, 39, 13, 39, 44, 27])\n",
      "tensor([18, 24, 24, 12, 14, 32, 18, 39, 24, 35, 38, 30, 26, 31, 33, 27])\n",
      "tensor([ 4, 36, 21, 41, 40, 39,  2, 13, 31, 11, 10, 23,  7, 45,  0,  0])\n",
      "tensor([19, 48, 33, 33,  1, 44, 33, 45, 40, 46, 21, 13, 10, 13, 26, 30])\n",
      "tensor([ 8, 18, 16, 31,  4, 48, 31, 41, 20, 35, 41, 46, 38, 28, 15,  8])\n",
      "tensor([34, 39, 13, 22, 18,  2, 20,  5, 15,  9, 14, 16,  5, 38, 33,  3])\n",
      "tensor([47,  7, 29, 16, 48,  0, 36, 27, 19, 14,  5, 37, 19, 35, 44, 36])\n",
      "tensor([22, 25, 45, 46, 24, 36, 25, 36, 11, 22, 42, 34, 32, 19, 33, 47])\n",
      "tensor([49, 11, 13, 30, 40, 32, 17, 20,  4, 36, 36, 27, 21, 33, 11, 33])\n",
      "tensor([25, 38,  8, 11, 12, 10, 12, 11, 38,  2, 42, 35, 37,  7, 31, 21])\n",
      "tensor([19,  2, 32,  7,  5,  7, 15, 18, 10, 49, 46,  5, 16, 26, 19, 42])\n",
      "tensor([ 6, 31, 18, 39, 44, 32,  9,  1, 48, 30, 27, 36, 13,  4,  7, 37])\n",
      "tensor([ 3, 25,  9, 11, 45, 29, 11, 24, 44, 23, 41, 21, 35,  3, 23, 36])\n",
      "tensor([33, 27, 13, 22,  7, 36, 14, 36, 21,  7, 14, 26,  1,  4, 49,  2])\n",
      "tensor([47, 32, 22, 12, 10, 45, 27, 35, 23, 10,  9,  0, 26, 15, 31, 25])\n",
      "tensor([42, 23, 30, 15,  4, 48, 27, 15,  0, 13, 23, 17, 26, 26, 29, 23])\n",
      "tensor([38,  3, 20, 19, 30,  0, 38,  6, 21,  6, 38, 44, 14, 46,  2, 20])\n",
      "tensor([49,  5,  6, 25, 13,  0, 26,  9, 39, 35,  6, 34,  3, 14, 20, 14])\n",
      "tensor([25, 36,  7, 33, 44, 41, 26, 36, 12, 35,  4, 48, 41, 46, 19,  3])\n",
      "tensor([19,  3, 25, 36, 12, 27,  9, 38, 33,  5, 28, 16,  6, 43, 36, 28])\n",
      "tensor([37,  1, 45, 35, 34, 10, 32, 14,  8, 16, 45, 10, 37, 41, 20, 32])\n",
      "tensor([ 1,  3, 15, 33, 23,  5, 20, 38, 48, 33, 26, 35, 18, 16, 47, 39])\n",
      "tensor([ 1, 31, 45, 41, 35, 36, 44, 16, 32, 23, 14, 37,  8, 24, 48, 32])\n",
      "tensor([ 7,  0,  6, 24,  6,  5, 22, 19,  4, 27, 36, 28, 17,  2, 39,  5])\n",
      "tensor([23,  0, 25, 35, 47, 45, 32, 43, 49, 28, 23, 44, 41, 10,  8, 20])\n",
      "tensor([48, 44, 11, 21, 24,  1,  3, 49, 34,  4, 26,  2,  0, 26,  9, 24])\n",
      "tensor([26, 42, 47, 34, 36, 28, 14, 21,  7, 36,  2,  8, 13, 49, 26, 22])\n",
      "tensor([43, 17, 43, 24, 16,  3, 49, 18, 45, 40, 34,  7, 40, 19, 32, 48])\n",
      "tensor([40, 32, 17, 32, 21, 24, 11, 32, 10, 23, 40, 13,  3, 14, 17, 28])\n",
      "tensor([15, 49, 45, 19, 37, 19, 28, 15, 41,  9, 39, 46,  2, 29, 12,  5])\n",
      "tensor([38, 11, 49, 20, 24, 38, 19, 43, 20, 29, 21, 10, 10, 33,  9, 27])\n",
      "tensor([11, 30, 30, 27, 20, 22, 11, 11, 38, 16, 47, 27, 36,  0, 15, 18])\n",
      "tensor([25,  2, 33, 28, 19, 34,  3, 46,  8, 18, 27, 37,  6, 42, 12, 32])\n",
      "tensor([14, 48,  6, 32, 30,  3,  1, 47, 49, 11, 20, 37, 29, 34,  0, 30])\n",
      "tensor([48,  5, 11, 26, 49,  8, 15, 40, 32, 22, 39, 18, 14, 10, 45, 38])\n",
      "tensor([34, 12, 17,  0, 41, 16, 18,  9, 45, 44, 22, 35, 15,  2, 18, 49])\n",
      "tensor([37, 41,  8, 12, 42, 40, 40, 21,  8, 27, 18, 31, 35, 13,  1, 33])\n",
      "tensor([22, 27, 38, 34, 21, 15, 21,  2, 27, 25, 34, 32, 45, 19, 37, 35])\n",
      "tensor([32,  5, 19, 29, 34,  0, 25, 47, 49, 40, 45,  1, 28, 19, 32, 31])\n",
      "tensor([10, 12, 47, 17, 35, 37, 10, 46, 48, 49, 34, 39, 31, 32,  8, 14])\n",
      "tensor([16, 15, 49, 44, 44, 37, 34, 22,  2, 49, 27, 44,  7, 12,  5,  9])\n",
      "tensor([15, 31, 42, 27, 15,  7,  2, 15, 34, 38, 16, 32, 27, 16, 35, 36])\n",
      "tensor([31, 23,  0, 29, 48, 33, 10, 11,  3,  8, 16, 38, 21,  5, 41, 29])\n",
      "tensor([ 0, 25, 30,  4,  3, 34, 22, 10, 35, 21, 20,  4,  6, 35, 15, 25])\n",
      "tensor([25, 32, 49,  8,  9,  6,  9, 34, 19, 10, 39, 40, 12, 11, 44, 10])\n",
      "tensor([46, 43,  6,  5, 13, 33, 28, 20, 43, 28, 21, 48, 21, 31, 44,  9])\n",
      "tensor([41, 26, 10, 32, 16,  5, 13, 18, 23, 44, 26, 30, 43,  5, 16, 29])\n",
      "tensor([38, 43, 29, 13, 35,  4,  6, 13, 32,  1, 17, 41, 42,  8, 14, 39])\n",
      "tensor([ 0, 36, 42, 22, 16, 35, 24, 28, 36, 20, 19, 29, 33, 14, 18, 34])\n",
      "tensor([42, 13, 13, 13, 45, 15, 15, 23, 22, 22,  7, 28,  2,  1, 43, 24])\n",
      "tensor([23, 28,  2, 47, 41, 48, 30, 28,  4, 35, 48, 48, 43, 33, 36, 38])\n",
      "tensor([48, 40, 32,  9,  0,  2, 35, 27,  7,  8, 44, 37, 37,  9, 24, 11])\n",
      "tensor([20,  1, 11, 25, 18, 18, 11, 40, 23, 22, 35,  4, 31, 45,  4, 34])\n",
      "tensor([35, 31, 26, 38, 43,  7, 45,  9, 19, 45,  9, 49, 40, 29,  2, 26])\n",
      "tensor([12, 49, 10, 33, 20, 42, 30, 10,  2, 18, 36, 11,  6, 27,  6,  7])\n",
      "tensor([44,  6, 11, 17, 22, 38, 21, 40, 34, 48, 42, 18, 20,  5, 37,  3])\n",
      "tensor([45, 33, 37, 46,  2, 43, 40, 38, 20, 16, 41, 26, 47,  1, 36, 21])\n",
      "tensor([14,  7,  3,  5, 40,  9, 38, 29, 15,  5, 39,  3, 34, 30, 29, 45])\n",
      "tensor([48, 46, 35, 13, 41, 33,  0, 39, 43, 15, 34, 34, 46, 22, 24, 26])\n",
      "tensor([ 2, 47, 38, 38,  1, 35,  3,  1, 24, 49, 27, 48, 42, 33, 40, 46])\n",
      "tensor([46, 27, 12,  9, 47, 10, 12, 25, 28, 38,  9,  1,  2, 48, 38, 47])\n",
      "tensor([45, 31, 40, 27, 43, 36, 38, 46,  3, 16, 14, 34, 44, 26,  9, 41])\n",
      "tensor([ 3, 37, 10, 27, 18, 18, 37, 45, 22, 15, 28,  5, 30, 38, 11, 21])\n",
      "tensor([39, 12,  1, 44, 13, 26, 27,  5, 33, 40, 24, 46, 32, 29, 49, 43])\n",
      "tensor([11, 47, 35,  0, 41,  3, 28, 39, 10, 34, 32, 23, 28, 41, 33,  4])\n",
      "tensor([ 8, 25, 43, 13, 20, 49, 16, 13, 13, 12, 32, 42,  2, 16, 37, 23])\n",
      "tensor([23, 33, 19, 15, 45, 18, 23,  2, 16, 44, 33, 12, 38, 17, 33, 11])\n",
      "tensor([34,  2, 41, 30, 16,  7, 24, 33, 20, 14,  0,  0, 20,  0, 15, 48])\n",
      "tensor([36,  3, 43,  9, 44, 15, 34, 28,  7, 23, 38, 16, 38, 48, 13, 17])\n",
      "tensor([10, 36, 22,  8,  6, 37, 11, 11, 38, 18, 45, 24, 45, 14, 35, 47])\n",
      "tensor([12, 35, 10, 12, 39,  3,  2, 24, 11,  7, 19, 24, 29, 19,  5, 26])\n",
      "tensor([16, 17, 43,  3,  4, 40, 19, 12, 14, 44, 29, 24, 25, 31,  9, 46])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 11, 35, 32, 28, 26, 24, 35, 24, 45, 41, 43,  3, 41])\n"
     ]
    }
   ],
   "source": [
    "#feat,lbls = extract_features(model,train_data_loader)\n",
    "test_feat,test_lbls = extract_features(model,test_data_loader)\n",
    "lbls = flatten_list(lbls)\n",
    "test_lbls  =flatten_list(test_lbls) # flatting the lbls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4835, 1854)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lbls),len(test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 1536), 4835, (1854, 1536), 1854)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape,len(lbls),test_feat.shape,len(test_lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Without FFT\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cat_feat_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6d3a43ffd77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train-Without FFT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_feat_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlbls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msvm_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_feat_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVM Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_lbls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cat_feat_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Train-Without FFT')\n",
    "#SVM\n",
    "svm = SVC(kernel='linear').fit(cat_feat_train,lbls)\n",
    "svm_preds = svm.predict(cat_feat_test)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_lbls, svm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Without FFT\n",
      "SVM Accuracy: 0.44983818770226536\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Train-Without FFT')\n",
    "#SVM\n",
    "svm_preds = SVC(kernel='linear').fit(feat,lbls).predict(test_feat)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_lbls, svm_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 4608), (1854, 4608))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save np network features and labels\n",
    "# Use pickle for serialization or np.save for saving np objects. two options\n",
    "\n",
    "\n",
    "\n",
    "i = 0 #video index 4797\n",
    "j = 0 # neuron index 1000\n",
    "\n",
    "def hstft(S1):\n",
    "    S21, S22 = np.split(S1,2)  # 500+500\n",
    "    S311, S312 = np.split(S21,2) # 500    \n",
    "    S321, S322 = np.split(S22,2) # 500\n",
    "    #S1.shape,S21.shape,S22.shape,S311.shape,S312.shape,S321.shape,S322.shape    \n",
    "    return np.concatenate((S1,S21,S22,S311,S312,S321,S322))\n",
    "\n",
    "def alpha(features):\n",
    "    A = np.zeros((len(features),4608))\n",
    "    for i,f in enumerate(features):\n",
    "        h = scipy.fft.fft(f)    \n",
    "        #print(f.shape,h.shape)\n",
    "        #print(h.shape)\n",
    "        h = hstft(h)\n",
    "        #print(h.shape)\n",
    "        A[i,:] = h.real\n",
    "    return A\n",
    "\n",
    "train_alpha = alpha(feat)\n",
    "test_alpha = alpha(test_feat)\n",
    "train_alpha.shape,test_alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4835, 4608), (4835,), (1854, 4608), (1854,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_alpha\n",
    "Y = lbls\n",
    "test_x = test_alpha\n",
    "test_y = test_lbls\n",
    "X.shape,Y.shape,test_x.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.4250269687162891\n",
      "KNN Accuracy: 0.24110032362459546\n",
      "RF Accuracy: 0.37540453074433655\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#SVM\n",
    "clf = SVC(kernel='linear').fit(X,Y)\n",
    "preds = clf.predict(test_x)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_y, preds))\n",
    "\n",
    "#KNN\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3).fit(X,Y)\n",
    "knn_preds = knn_clf.predict(test_x)\n",
    "print(\"KNN Accuracy:\",metrics.accuracy_score(test_y, knn_preds))\n",
    "\n",
    "#Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100).fit(X,Y)\n",
    "rf_preds = rf_clf.predict(test_x)\n",
    "print(\"RF Accuracy:\",metrics.accuracy_score(test_y, rf_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4835, 2048)\n",
      "(1854, 2048)\n",
      "(4835, 1536)\n",
      "(1854, 1536)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "trainpath = '/home/muhammadbsheikh/workspace/projects/mmaction/mmaction2/train_ucf50_feature.pkl'\n",
    "testpath = '/home/muhammadbsheikh/workspace/projects/mmaction/mmaction2/test_ucf50_feature.pkl'\n",
    "\n",
    "objects = []\n",
    "trainfile =  open(trainpath, \"rb\")\n",
    "testfile =  open(testpath, \"rb\")\n",
    "train_features = np.array(pickle.load(trainfile))\n",
    "test_features = np.array(pickle.load(testfile))\n",
    "        \n",
    "\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "print(feat.shape)\n",
    "print(test_feat.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "#SVM\n",
    "clf = SVC(kernel='linear').fit(train_features,Y)\n",
    "preds = clf.predict(test_features)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa1300ad3a0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4835, 3584)\n",
      "(1854, 3584)\n"
     ]
    }
   ],
   "source": [
    "#concatenation\n",
    "cat_feat_train = np.concatenate((feat,train_features),axis=1)\n",
    "print(cat_feat_train.shape)\n",
    "cat_feat_test = np.concatenate((test_feat,test_features),axis=1)\n",
    "print(cat_feat_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13960472, 0.13407686, 0.33689857, ..., 0.21496059, 0.05287648,\n",
       "       0.48585725], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[0]\n",
    "feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 395.37982 25.827038\n",
      "0.0 390.06732 20.99894\n",
      "0.0 2.862825 0.22669546\n",
      "0.0 1.9608401 0.22682524\n"
     ]
    }
   ],
   "source": [
    "print(np.min(train_features),np.max(train_features),np.mean(train_features))\n",
    "print(np.min(test_features),np.max(test_features),np.mean(test_features))\n",
    "print(np.min(feat),np.max(feat),np.mean(feat))\n",
    "print(np.min(test_feat),np.max(test_feat),np.mean(test_feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureNormalize(X, epsilon=1e-8):\n",
    "    X_norm = np.copy(X)\n",
    "    mu = np.zeros((X.shape[1]))\n",
    "    sigma = np.zeros((X.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        mu[i] = np.mean(X[:, i])\n",
    "        sigma[i] = np.std(X[:, i], ddof=1)\n",
    "        # print (sigma)\n",
    "        if sigma[i] == 0:\n",
    "            sigma[i] = epsilon\n",
    "        X_norm[:, i] = (X[:, i] - float(mu[i]))/float(sigma[i])\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4835, 1854)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_features, x,y = featureNormalize(train_features) #normalize 0 to 1\n",
    "n_test_features, x,y = featureNormalize(test_features) #normalize 0 to 1\n",
    "n_feat, x,y =featureNormalize(feat)\n",
    "n_test_feat, x,y = featureNormalize(test_feat)\n",
    "len(n_train_features),len(n_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0479612 11.530963 3.3038354e-09\n",
      "-4.7070427 43.03488 1.4660042e-08\n",
      "-1.9778609 15.0546055 5.2598376e-10\n",
      "-1.9798017 12.134659 -9.644765e-10\n"
     ]
    }
   ],
   "source": [
    "print(np.min(n_train_features),np.max(n_train_features),np.mean(n_train_features))\n",
    "print(np.min(n_test_features),np.max(n_test_features),np.mean(n_test_features))\n",
    "print(np.min(n_feat),np.max(n_feat),np.mean(n_feat))\n",
    "print(np.min(n_test_feat),np.max(n_test_feat),np.mean(n_test_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Without FFT\n",
      "SVM Accuracy: 0.019956850053937433\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Train-Without FFT')\n",
    "#SVM\n",
    "svm = SVC(kernel='linear').fit(cat_feat_train,lbls)\n",
    "svm_preds = svm.predict(cat_feat_test)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_lbls, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Without FFT\n",
      "SVM Accuracy: 0.019417475728155338\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Train-Without FFT')\n",
    "#SVM\n",
    "svm = SVC(kernel='poly').fit(cat_feat_train,lbls)\n",
    "svm_preds = svm.predict(cat_feat_test)\n",
    "print(\"SVM Accuracy:\",metrics.accuracy_score(test_lbls, svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4835, 3584]), torch.Size([1854, 3584]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cat_feat_train = torch.from_numpy(cat_feat_train)\n",
    "t_cat_feat_test = torch.from_numpy(cat_feat_test)\n",
    "t_cat_feat_train.shape,t_cat_feat_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4835, 3584])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer = nn.Linear(3584,50)\n",
    "output = F.log_softmax(t_cat_feat_train,dim=1)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([43, 11,  5, 35, 10, 30, 24, 23, 26,  2, 28, 41,  6,  5, 16,  6])\n"
     ]
    }
   ],
   "source": [
    "for i,batch in enumerate(train_data_loader,0):\n",
    "    print(batch[1])\n",
    "    break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying fc layer and softmax"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0239f972e8efcc00ec9fa7a595c90a818e30a75607d9e34132d6cc1dc8c76e26"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
